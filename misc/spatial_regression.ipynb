{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ipavlopoulos/paremia/blob/main/spatial_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DxN2dSJWea_L"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!gdown 1X2nRkVB54gHv9YwNLEP_tLZQ2oPYgyZS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sayings = pd.read_csv(\"sayings_wcoords.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MwOaNuDCpdZs"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!gdown 1hWC-H6ZObb71O6xcF_BvmQ4zbji_bhYn # the BERT embedded texts\n",
    "\n",
    "sayings_embedded = pd.read_pickle(\"sayings_embeddings.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ir7b9tUjqKSL"
   },
   "outputs": [],
   "source": [
    "# adding the BERT embedding per text into our original dataframe\n",
    "\n",
    "sayings[\"bert\"] = sayings_embedded.bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xUS4wpzBqP4k"
   },
   "outputs": [],
   "source": [
    "# drop the duplicates\n",
    "sayings = sayings[~sayings.text.duplicated(keep=False)]\n",
    "\n",
    "# keeping ones whose area is not located\n",
    "sayings_unk = sayings[sayings.place==\"Άδηλου τόπου\"]\n",
    "sayings = sayings[sayings.place!=\"Άδηλου τόπου\"]\n",
    "\n",
    "# distinguish ones not **geo**located\n",
    "sayings_no_ll = sayings[(sayings.lat.isna())|(sayings.lon.isna())]\n",
    "sayings = sayings[(sayings.lat.notna())&(sayings.lon.notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9UVlyMaf9Ms",
    "outputId": "b5e42fbf-a0c8-4762-ab40-65583cf91356"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"text\": sayings.text, \n",
    "    \"area\": sayings.area, \n",
    "    \"lat\": sayings.lat, \n",
    "    \"lon\": sayings.lon, \n",
    "    \"representation\":sayings.bert\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>area</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Απο Μαρθιού και Σεπτεβριού ίσα τα μερονύχτια</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[0.01300588995218277, -0.7646797895431519, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Απου πνιγεί και σκοτωθή, κακού θανατου πάει</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[-0.037213459610939026, -0.12144553661346436, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Αυτός δεν ξέρει να ρετσινώνη το δοξάρι</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[-0.36768558621406555, -0.19501501321792603, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Η καλή δουλειά άργιο έχει κ' η κακή περγέλιο έχει</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[-1.0229626893997192, -0.33663713932037354, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Κάθε μία κατσούνα σύρνει ομπρός τζη</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[0.7727544903755188, -1.060009479522705, 0.310...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119265</th>\n",
       "      <td>Φεύγα λέρα 'π τόν γιακά</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[-0.8613376021385193, 0.06331253051757812, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119266</th>\n",
       "      <td>Φκιάντσ' κατ' δ'λειές ούτι τα σ'κκλιά δε τ'ς τρων</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[0.5728021264076233, 0.0991407260298729, 0.764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119267</th>\n",
       "      <td>Χαμπ'λα – χαμπ'λά τα μάτια κι σφούγγα τα κουμμ...</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[-0.3265528976917267, 0.3534873425960541, 1.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119268</th>\n",
       "      <td>Χουρίς υτία κι' αφουρμή χάρους ψυχή δεν παίρνει</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[-0.3150862157344818, -0.23113000392913818, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119269</th>\n",
       "      <td>Ψώραβ' γίδα τ' νουρά σκαπάν'</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[-0.2331009954214096, -0.14128278195858002, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98047 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text    area        lat   \n",
       "0            Απο Μαρθιού και Σεπτεβριού ίσα τα μερονύχτια   Κρήτη  35.308495  \\\n",
       "1             Απου πνιγεί και σκοτωθή, κακού θανατου πάει   Κρήτη  35.308495   \n",
       "2                  Αυτός δεν ξέρει να ρετσινώνη το δοξάρι   Κρήτη  35.308495   \n",
       "3       Η καλή δουλειά άργιο έχει κ' η κακή περγέλιο έχει   Κρήτη  35.308495   \n",
       "4                     Κάθε μία κατσούνα σύρνει ομπρός τζη   Κρήτη  35.308495   \n",
       "...                                                   ...     ...        ...   \n",
       "119265                            Φεύγα λέρα 'π τόν γιακά  Ημαθία  40.517038   \n",
       "119266  Φκιάντσ' κατ' δ'λειές ούτι τα σ'κκλιά δε τ'ς τρων  Ημαθία  40.517038   \n",
       "119267  Χαμπ'λα – χαμπ'λά τα μάτια κι σφούγγα τα κουμμ...  Ημαθία  40.517038   \n",
       "119268    Χουρίς υτία κι' αφουρμή χάρους ψυχή δεν παίρνει  Ημαθία  40.517038   \n",
       "119269                       Ψώραβ' γίδα τ' νουρά σκαπάν'  Ημαθία  40.517038   \n",
       "\n",
       "              lon                                     representation  \n",
       "0       24.463342  [0.01300588995218277, -0.7646797895431519, 0.9...  \n",
       "1       24.463342  [-0.037213459610939026, -0.12144553661346436, ...  \n",
       "2       24.463342  [-0.36768558621406555, -0.19501501321792603, 1...  \n",
       "3       24.463342  [-1.0229626893997192, -0.33663713932037354, 0....  \n",
       "4       24.463342  [0.7727544903755188, -1.060009479522705, 0.310...  \n",
       "...           ...                                                ...  \n",
       "119265  22.180720  [-0.8613376021385193, 0.06331253051757812, -0....  \n",
       "119266  22.180720  [0.5728021264076233, 0.0991407260298729, 0.764...  \n",
       "119267  22.180720  [-0.3265528976917267, 0.3534873425960541, 1.10...  \n",
       "119268  22.180720  [-0.3150862157344818, -0.23113000392913818, 1....  \n",
       "119269  22.180720  [-0.2331009954214096, -0.14128278195858002, 0....  \n",
       "\n",
       "[98047 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Επτάνησος 7947\n",
      "Αχαΐα 7167\n",
      "Αμοργός 7081\n",
      "Κύπρος 5687\n",
      "Ήπειρος 5617\n",
      "Κρήτη 4785\n",
      "Θράκη 4444\n",
      "Αρκαδία 4202\n",
      "Λακωνία 3836\n",
      "Μικρά Ασία 3757\n",
      "Πόντος 3631\n",
      "Νάξος 3158\n",
      "Ιωάννινα 2652\n",
      "Μακεδονία 2359\n",
      "Κεφαλληνία 2232\n",
      "Ρόδος 2096\n",
      "Αιτωλία 2075\n",
      "Κάρπαθος 1560\n",
      "Σκύρος 1535\n",
      "Θεσπρωτία 1497\n",
      "Ανατολική Θράκη 1367\n",
      "Εύβοια 1109\n",
      "Λέσβος 1043\n",
      "Μεσσηνία 981\n",
      "Κοζάνη 952\n",
      "Άνδρος 766\n",
      "Αδριανούπολη 693\n",
      "Σέρρες 672\n",
      "Σάμος 640\n",
      "Φιλιππούπολη 602\n",
      "Κορινθία 590\n",
      "Χίος 546\n",
      "Ρούμελη 545\n",
      "Αργολίδα 509\n",
      "Νίσυρος 482\n",
      "Μάνη 481\n",
      "Καστελλόριζο (Μεγίστη) 466\n",
      "Ιθάκη 423\n",
      "Ημαθία 386\n",
      "Θεσσαλία 367\n",
      "Θήρα (Σαντορίνη) 347\n",
      "Κάλυμνος 328\n",
      "Λάρισα 318\n",
      "Αθήνα 313\n",
      "Καστοριά 312\n",
      "Σύμη 252\n",
      "Πήλιο 248\n",
      "Κέρκυρα 220\n",
      "Παξοί 217\n",
      "Λευκάδα 211\n",
      "Λήμνος 208\n",
      "Μήλος 198\n",
      "Σίφνος 185\n",
      "Κύθνος 181\n",
      "Ακαρνανία 166\n",
      "Κως 164\n",
      "Καρδίτσα 158\n",
      "Καππαδοκία 155\n",
      "Δαρδανέλλια (Ελλήσποντος) 151\n",
      "Λέρος 148\n",
      "Σύρος 131\n",
      "Αιτωλοακαρνανία 124\n",
      "Βοιωτία 120\n",
      "Ίμβρος 118\n",
      "Ικαρία 118\n",
      "Τήνος 110\n",
      "Τήλος 109\n",
      "Ανάφη 109\n",
      "Ηλεία 99\n",
      "Ζάκυνθος 98\n",
      "Παρνασσός 89\n",
      "Πρέβεζα 82\n",
      "Κύθηρα 81\n",
      "Αττική 77\n",
      "Νάουσα 77\n",
      "Βόρειος Ήπειρος 76\n",
      "Ανδρίτσαινα Ολυμπίου 70\n",
      "Σμύρνη 66\n",
      "Τριφυλία 64\n",
      "Λαμία 61\n",
      "Ευρυτανία 60\n",
      "Ολυμπία 60\n",
      "Σέριφος 58\n",
      "Άγιον Όρος 55\n",
      "Πάρος 53\n",
      "Πελοπόννησος 41\n",
      "Πέλλα 38\n",
      "Φωκίδα 33\n",
      "Κίμωλος 32\n",
      "Μάλγαρα 30\n",
      "Κέα 29\n",
      "Ανατολική Κρήτη 27\n",
      "Κωνσταντινούπολη 27\n",
      "Χαλκιδική 27\n",
      "Στερεά Ελλάδα 20\n",
      "Φθιώτιδα 18\n",
      "Μύκονος 15\n",
      "Τρίκαλα 15\n",
      "Σπέτσες 13\n",
      "Ναυπακτία 11\n",
      "Κυκλάδες 10\n",
      "Ελασσόνα 10\n",
      "Σαμοθράκη 10\n",
      "Θάσος 7\n",
      "Αίγινα 7\n",
      "Θεσσαλονίκη 7\n",
      "Αλβανία 4\n",
      "Άργος 4\n",
      "Άρτα 4\n",
      "Λεπενού Αιτωλοακαρνανίας (επαρχία Βάλτου) 3\n",
      "Σκόπελος 2\n",
      "Πάτμος 2\n",
      "Φλώρινα 2\n",
      "Σκιάθος 2\n",
      "Δυτική Κρήτη 1\n",
      "Ναύπακτος 1\n",
      "Κάσος 1\n",
      "Μαγνησία 1\n",
      "Δυτική Μάνη 1\n",
      "Φολέγανδρος 1\n",
      "Κουφονήσια 1\n",
      "Αιγαίο 1\n",
      "Σαλαμίνα 1\n",
      "Αστυπάλαια 1\n",
      "Καλλίπολη 1\n",
      "Ροδόπη 1\n",
      "Βουλγαρία 1\n",
      "Πιερία 1\n"
     ]
    }
   ],
   "source": [
    "area_counts = df.area.value_counts()\n",
    "for area, count in area_counts.items():\n",
    "    print(area, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area\n",
       "Επτάνησος    7947\n",
       "Αχαΐα        7167\n",
       "Αμοργός      7081\n",
       "Κύπρος       5687\n",
       "Ήπειρος      5617\n",
       "             ... \n",
       "Ίμβρος        118\n",
       "Ικαρία        118\n",
       "Τήνος         110\n",
       "Τήλος         109\n",
       "Ανάφη         109\n",
       "Name: count, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_counts_gt_100 = area_counts[area_counts >= 100]\n",
    "area_counts_gt_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>area</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Απο Μαρθιού και Σεπτεβριού ίσα τα μερονύχτια</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[0.01300588995218277, -0.7646797895431519, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Απου πνιγεί και σκοτωθή, κακού θανατου πάει</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[-0.037213459610939026, -0.12144553661346436, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Αυτός δεν ξέρει να ρετσινώνη το δοξάρι</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[-0.36768558621406555, -0.19501501321792603, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Η καλή δουλειά άργιο έχει κ' η κακή περγέλιο έχει</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[-1.0229626893997192, -0.33663713932037354, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Κάθε μία κατσούνα σύρνει ομπρός τζη</td>\n",
       "      <td>Κρήτη</td>\n",
       "      <td>35.308495</td>\n",
       "      <td>24.463342</td>\n",
       "      <td>[0.7727544903755188, -1.060009479522705, 0.310...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119265</th>\n",
       "      <td>Φεύγα λέρα 'π τόν γιακά</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[-0.8613376021385193, 0.06331253051757812, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119266</th>\n",
       "      <td>Φκιάντσ' κατ' δ'λειές ούτι τα σ'κκλιά δε τ'ς τρων</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[0.5728021264076233, 0.0991407260298729, 0.764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119267</th>\n",
       "      <td>Χαμπ'λα – χαμπ'λά τα μάτια κι σφούγγα τα κουμμ...</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[-0.3265528976917267, 0.3534873425960541, 1.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119268</th>\n",
       "      <td>Χουρίς υτία κι' αφουρμή χάρους ψυχή δεν παίρνει</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[-0.3150862157344818, -0.23113000392913818, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119269</th>\n",
       "      <td>Ψώραβ' γίδα τ' νουρά σκαπάν'</td>\n",
       "      <td>Ημαθία</td>\n",
       "      <td>40.517038</td>\n",
       "      <td>22.180720</td>\n",
       "      <td>[-0.2331009954214096, -0.14128278195858002, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96357 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text    area        lat   \n",
       "0            Απο Μαρθιού και Σεπτεβριού ίσα τα μερονύχτια   Κρήτη  35.308495  \\\n",
       "1             Απου πνιγεί και σκοτωθή, κακού θανατου πάει   Κρήτη  35.308495   \n",
       "2                  Αυτός δεν ξέρει να ρετσινώνη το δοξάρι   Κρήτη  35.308495   \n",
       "3       Η καλή δουλειά άργιο έχει κ' η κακή περγέλιο έχει   Κρήτη  35.308495   \n",
       "4                     Κάθε μία κατσούνα σύρνει ομπρός τζη   Κρήτη  35.308495   \n",
       "...                                                   ...     ...        ...   \n",
       "119265                            Φεύγα λέρα 'π τόν γιακά  Ημαθία  40.517038   \n",
       "119266  Φκιάντσ' κατ' δ'λειές ούτι τα σ'κκλιά δε τ'ς τρων  Ημαθία  40.517038   \n",
       "119267  Χαμπ'λα – χαμπ'λά τα μάτια κι σφούγγα τα κουμμ...  Ημαθία  40.517038   \n",
       "119268    Χουρίς υτία κι' αφουρμή χάρους ψυχή δεν παίρνει  Ημαθία  40.517038   \n",
       "119269                       Ψώραβ' γίδα τ' νουρά σκαπάν'  Ημαθία  40.517038   \n",
       "\n",
       "              lon                                     representation  \n",
       "0       24.463342  [0.01300588995218277, -0.7646797895431519, 0.9...  \n",
       "1       24.463342  [-0.037213459610939026, -0.12144553661346436, ...  \n",
       "2       24.463342  [-0.36768558621406555, -0.19501501321792603, 1...  \n",
       "3       24.463342  [-1.0229626893997192, -0.33663713932037354, 0....  \n",
       "4       24.463342  [0.7727544903755188, -1.060009479522705, 0.310...  \n",
       "...           ...                                                ...  \n",
       "119265  22.180720  [-0.8613376021385193, 0.06331253051757812, -0....  \n",
       "119266  22.180720  [0.5728021264076233, 0.0991407260298729, 0.764...  \n",
       "119267  22.180720  [-0.3265528976917267, 0.3534873425960541, 1.10...  \n",
       "119268  22.180720  [-0.3150862157344818, -0.23113000392913818, 1....  \n",
       "119269  22.180720  [-0.2331009954214096, -0.14128278195858002, 0....  \n",
       "\n",
       "[96357 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100 = df[df['area'].isin(area_counts_gt_100.index)]\n",
    "df_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77085 19272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_100, test_size=0.20, random_state=2023, shuffle=True, stratify=df_100.area)\n",
    "\n",
    "print(df_train.shape[0], df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "EiA8z1_4pPIy"
   },
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "\n",
    "def degeocode(geocoded_areas, predictions, target_col=\"area\"):\n",
    "    classes = []\n",
    "    # find the nearest geocoded area to the prediction in 2d \n",
    "    for p in predictions:\n",
    "        dists = geocoded_areas.apply(lambda r: geopy.distance.geodesic( (r.lat, r.lon), (p[0], p[1])).km, axis=1)\n",
    "        classes.append(geocoded_areas.iloc[dists.argmin()][target_col])\n",
    "    return classes\n",
    "\n",
    "def km_distance(geocodes, gold_locs, pred_ll, target_col=\"area\"):\n",
    "    dists = []\n",
    "    for g, p in zip(gold_locs, pred_ll):\n",
    "        gold_lat, gold_lon = geocodes[geocodes[target_col]==g][[\"lat\", \"lon\"]].values[0]\n",
    "        dists.append(geopy.distance.geodesic( (gold_lat, gold_lon), (p[0], p[1])).km)\n",
    "    return pd.Series(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ao6E0y_0a7ML"
   },
   "source": [
    "# Benchmarking TFIDF vs BERT representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Longitude and Latitude Using BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "4q2HbqYvZK1M",
    "outputId": "3f66319a-e16e-4cbd-dd94-b056ed0c62fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesRegressor(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "import numpy as np\n",
    "\n",
    "# fitting with BERT representations\n",
    "\n",
    "train_embeddings = np.vstack(df_train['representation'].values)\n",
    "\n",
    "bert_geo_model = ExtraTreesRegressor(n_jobs=-1)\n",
    "bert_geo_model.fit(train_embeddings, df_train[[\"lat\", \"lon\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19272, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[38.315234  , 24.14368619],\n",
       "       [37.87179153, 24.05741488],\n",
       "       [38.0949787 , 23.98080029],\n",
       "       ...,\n",
       "       [38.29457012, 23.95972373],\n",
       "       [38.24641475, 23.4517718 ],\n",
       "       [38.42692352, 23.91574865]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embeddings = np.vstack(df_test['representation'].values)\n",
    "bert_geo_predictions = bert_geo_model.predict(test_embeddings)\n",
    "print(bert_geo_predictions.shape)\n",
    "bert_geo_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.30085205, 1.61153067])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.mean_absolute_error(bert_geo_predictions, df_test[['lat', 'lon']].values, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Area Using BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_area_model = ExtraTreesClassifier(n_jobs=-1)\n",
    "bert_area_model.fit(train_embeddings, df_train.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Επτάνησος', 'Αχαΐα', 'Αμοργός', ..., 'Επτάνησος', 'Αμοργός',\n",
       "       'Αμοργός'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_area_predictions = bert_area_model.predict(test_embeddings)\n",
    "bert_area_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                   Άνδρος       0.01      0.09      0.02        22\n",
      "                  Ήπειρος       0.14      0.10      0.12      1553\n",
      "                   Ίμβρος       0.00      0.00      0.00         2\n",
      "             Αδριανούπολη       0.03      0.14      0.05        28\n",
      "                    Αθήνα       0.03      0.22      0.06         9\n",
      "                  Αιτωλία       0.01      0.05      0.02        93\n",
      "          Αιτωλοακαρνανία       0.00      0.00      0.00         5\n",
      "                Ακαρνανία       0.00      0.00      0.00         2\n",
      "                  Αμοργός       0.26      0.10      0.15      3594\n",
      "                    Ανάφη       0.00      0.00      0.00         2\n",
      "          Ανατολική Θράκη       0.03      0.14      0.04        49\n",
      "                 Αργολίδα       0.03      0.21      0.05        14\n",
      "                  Αρκαδία       0.07      0.12      0.09       488\n",
      "                    Αχαΐα       0.37      0.14      0.20      3709\n",
      "                  Βοιωτία       0.00      0.00      0.00         0\n",
      "Δαρδανέλλια (Ελλήσποντος)       0.00      0.00      0.00         4\n",
      "                Επτάνησος       0.43      0.13      0.20      5186\n",
      "                   Εύβοια       0.00      0.05      0.01        22\n",
      "                   Ημαθία       0.01      0.10      0.02        10\n",
      "         Θήρα (Σαντορίνη)       0.03      0.20      0.05        10\n",
      "                Θεσπρωτία       0.07      0.35      0.11        57\n",
      "                 Θεσσαλία       0.04      0.20      0.07        15\n",
      "                    Θράκη       0.05      0.08      0.06       502\n",
      "                    Ιθάκη       0.00      0.00      0.00        15\n",
      "                   Ικαρία       0.00      0.00      0.00         3\n",
      "                 Ιωάννινα       0.02      0.15      0.04        89\n",
      "                 Κάλυμνος       0.00      0.00      0.00         4\n",
      "                 Κάρπαθος       0.02      0.29      0.03        17\n",
      "                  Κέρκυρα       0.00      0.00      0.00        11\n",
      "               Καππαδοκία       0.00      0.00      0.00         1\n",
      "                 Καρδίτσα       0.00      0.00      0.00         6\n",
      "   Καστελλόριζο (Μεγίστη)       0.08      0.78      0.14         9\n",
      "                 Καστοριά       0.00      0.00      0.00         4\n",
      "               Κεφαλληνία       0.02      0.12      0.03        69\n",
      "                   Κοζάνη       0.02      0.12      0.04        33\n",
      "                 Κορινθία       0.02      0.12      0.03        16\n",
      "                    Κρήτη       0.07      0.12      0.09       529\n",
      "                      Κως       0.12      0.50      0.20         8\n",
      "                   Κύθνος       0.00      0.00      0.00         3\n",
      "                   Κύπρος       0.33      0.20      0.25      1855\n",
      "                   Λάρισα       0.03      0.50      0.06         4\n",
      "                    Λέρος       0.03      0.20      0.06         5\n",
      "                   Λέσβος       0.00      0.06      0.01        17\n",
      "                   Λήμνος       0.00      0.00      0.00         1\n",
      "                  Λακωνία       0.11      0.27      0.16       310\n",
      "                  Λευκάδα       0.00      0.00      0.00         8\n",
      "                     Μάνη       0.01      0.12      0.02         8\n",
      "                    Μήλος       0.03      0.11      0.04         9\n",
      "                Μακεδονία       0.04      0.26      0.07        76\n",
      "                 Μεσσηνία       0.02      0.27      0.04        15\n",
      "               Μικρά Ασία       0.03      0.09      0.04       202\n",
      "                    Νάξος       0.07      0.29      0.11       156\n",
      "                  Νίσυρος       0.00      0.00      0.00         7\n",
      "                    Πήλιο       0.00      0.00      0.00         1\n",
      "                    Παξοί       0.00      0.00      0.00         2\n",
      "                   Πόντος       0.08      0.21      0.11       264\n",
      "                  Ρούμελη       0.02      0.22      0.03         9\n",
      "                    Ρόδος       0.10      0.59      0.17        73\n",
      "                    Σάμος       0.02      0.29      0.03         7\n",
      "                   Σέρρες       0.03      0.80      0.06         5\n",
      "                   Σίφνος       0.00      0.00      0.00         0\n",
      "                   Σκύρος       0.02      0.23      0.03        22\n",
      "                     Σύμη       0.02      1.00      0.04         1\n",
      "                    Σύρος       0.00      0.00      0.00         1\n",
      "                    Τήλος       0.00      0.00      0.00         0\n",
      "                    Τήνος       0.00      0.00      0.00         2\n",
      "             Φιλιππούπολη       0.00      0.00      0.00        11\n",
      "                     Χίος       0.01      0.12      0.02         8\n",
      "\n",
      "                 accuracy                           0.14     19272\n",
      "                macro avg       0.04      0.15      0.05     19272\n",
      "             weighted avg       0.29      0.14      0.17     19272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(bert_area_predictions, df_test.area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Longitude and Latitude Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "p4-K-MxXZzyq",
    "outputId": "df688d74-2403-4bad-dd55-f32cb381bfef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, ExtraTreesRegressor(n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, ExtraTreesRegressor(n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                ('clf', ExtraTreesRegressor(n_jobs=-1))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_geo_model = Pipeline([('vect', TfidfVectorizer()), ('clf', ExtraTreesRegressor(n_jobs=-1))])\n",
    "tfidf_geo_model.fit(df_train.text, df_train[[\"lat\", \"lon\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19272, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[35.54673696, 24.02474015],\n",
       "       [35.5131379 , 24.0196923 ],\n",
       "       [38.44058325, 23.82627652],\n",
       "       ...,\n",
       "       [37.51528616, 23.36989779],\n",
       "       [38.12503569, 23.04225614],\n",
       "       [37.49078676, 23.31028232]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_geo_predictions = tfidf_geo_model.predict(df_test.text.values)\n",
    "print(tfidf_geo_predictions.shape)\n",
    "tfidf_geo_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.12543337, 1.485604  ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(tfidf_geo_predictions, df_test[['lat', 'lon']].values, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Area Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, ExtraTreesClassifier(n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, ExtraTreesClassifier(n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_jobs=-1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                ('clf', ExtraTreesClassifier(n_jobs=-1))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_area_model = Pipeline([('vect', TfidfVectorizer()), ('clf', ExtraTreesClassifier(n_jobs=-1))])\n",
    "tfidf_area_model.fit(df_train.text, df_train.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Κύπρος', 'Κύπρος', 'Πόντος', ..., 'Λακωνία', 'Αχαΐα', 'Αχαΐα'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_area_predictions = tfidf_area_model.predict(df_test.text)\n",
    "tfidf_area_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                   Άνδρος       0.18      0.26      0.21       104\n",
      "                  Ήπειρος       0.32      0.18      0.23      2006\n",
      "                   Ίμβρος       0.00      0.00      0.00         6\n",
      "             Αδριανούπολη       0.10      0.18      0.13        76\n",
      "                    Αθήνα       0.06      0.13      0.09        30\n",
      "                  Αιτωλία       0.36      0.36      0.36       423\n",
      "          Αιτωλοακαρνανία       0.04      0.08      0.05        13\n",
      "                Ακαρνανία       0.00      0.00      0.00         7\n",
      "                  Αμοργός       0.53      0.31      0.39      2459\n",
      "                    Ανάφη       0.00      0.00      0.00        12\n",
      "          Ανατολική Θράκη       0.10      0.14      0.12       196\n",
      "                 Αργολίδα       0.12      0.24      0.16        49\n",
      "                  Αρκαδία       0.18      0.18      0.18       839\n",
      "                    Αχαΐα       0.40      0.27      0.32      2124\n",
      "                  Βοιωτία       0.04      0.11      0.06         9\n",
      "Δαρδανέλλια (Ελλήσποντος)       0.03      0.06      0.04        18\n",
      "                Επτάνησος       0.62      0.38      0.47      2631\n",
      "                   Εύβοια       0.04      0.09      0.05        86\n",
      "                   Ημαθία       0.03      0.06      0.04        33\n",
      "         Θήρα (Σαντορίνη)       0.12      0.18      0.14        44\n",
      "                Θεσπρωτία       0.14      0.23      0.18       189\n",
      "                 Θεσσαλία       0.05      0.12      0.08        32\n",
      "                    Θράκη       0.24      0.26      0.25       829\n",
      "                    Ιθάκη       0.07      0.16      0.10        37\n",
      "                   Ικαρία       0.04      0.17      0.07         6\n",
      "                 Ιωάννινα       0.09      0.13      0.11       391\n",
      "                 Κάλυμνος       0.06      0.21      0.09        19\n",
      "                 Κάρπαθος       0.22      0.50      0.31       138\n",
      "                  Κέρκυρα       0.07      0.14      0.09        21\n",
      "               Καππαδοκία       0.03      1.00      0.06         1\n",
      "                 Καρδίτσα       0.06      0.11      0.08        19\n",
      "   Καστελλόριζο (Μεγίστη)       0.13      0.48      0.20        25\n",
      "                 Καστοριά       0.03      0.07      0.04        27\n",
      "               Κεφαλληνία       0.13      0.24      0.17       236\n",
      "                   Κοζάνη       0.11      0.20      0.14       106\n",
      "                 Κορινθία       0.06      0.14      0.08        50\n",
      "                    Κρήτη       0.41      0.50      0.45       794\n",
      "                      Κως       0.03      0.06      0.04        17\n",
      "                   Κύθνος       0.00      0.00      0.00        20\n",
      "                   Κύπρος       0.78      0.79      0.79      1134\n",
      "                   Λάρισα       0.03      0.22      0.05         9\n",
      "                    Λέρος       0.03      0.09      0.05        11\n",
      "                   Λέσβος       0.20      0.32      0.25       133\n",
      "                   Λήμνος       0.00      0.00      0.00        10\n",
      "                  Λακωνία       0.16      0.22      0.18       558\n",
      "                  Λευκάδα       0.07      0.17      0.10        18\n",
      "                     Μάνη       0.04      0.07      0.05        54\n",
      "                    Μήλος       0.00      0.00      0.00        17\n",
      "                Μακεδονία       0.14      0.23      0.18       298\n",
      "                 Μεσσηνία       0.09      0.19      0.12        89\n",
      "               Μικρά Ασία       0.16      0.22      0.19       545\n",
      "                    Νάξος       0.49      0.63      0.56       492\n",
      "                  Νίσυρος       0.06      0.15      0.09        39\n",
      "                    Πήλιο       0.04      0.11      0.06        19\n",
      "                    Παξοί       0.07      0.23      0.11        13\n",
      "                   Πόντος       0.66      0.66      0.66       724\n",
      "                  Ρούμελη       0.11      0.17      0.13        69\n",
      "                    Ρόδος       0.45      0.57      0.50       335\n",
      "                    Σάμος       0.26      0.48      0.34        69\n",
      "                   Σέρρες       0.04      0.12      0.06        52\n",
      "                   Σίφνος       0.00      0.00      0.00        13\n",
      "                   Σκύρος       0.42      0.46      0.44       280\n",
      "                     Σύμη       0.04      0.08      0.05        24\n",
      "                    Σύρος       0.00      0.00      0.00        24\n",
      "                    Τήλος       0.00      0.00      0.00         6\n",
      "                    Τήνος       0.09      0.22      0.13         9\n",
      "             Φιλιππούπολη       0.05      0.08      0.06        77\n",
      "                     Χίος       0.07      0.28      0.12        29\n",
      "\n",
      "                 accuracy                           0.33     19272\n",
      "                macro avg       0.14      0.22      0.16     19272\n",
      "             weighted avg       0.40      0.33      0.35     19272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(tfidf_area_predictions, df_test.area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bY0jJUca03S"
   },
   "source": [
    "# Tuning TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FiZ4ppQXWMGP",
    "outputId": "2639ed67-c0f7-44b6-97e2-411377445c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best: 0.061019 using {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_param = [\n",
    "                {\n",
    "                    \"vect\": [TfidfVectorizer()],\n",
    "                    \"vect__analyzer\": [\"word\", \"char\"],\n",
    "                    \"vect__lowercase\": [True, False],\n",
    "                    \"vect__max_df\": [0.5],\n",
    "                    \"vect__min_df\": [2],\n",
    "                    \"vect__ngram_range\": [(1,1), (1,2), (1,3), (2,5)],\n",
    "                    \"clf\": [ExtraTreesRegressor()],\n",
    "                    \"clf__n_estimators\": range(10,100,10),\n",
    "                    \"clf__max_features\": range(5, 20, 5)\n",
    "                 },\n",
    "              ]\n",
    "\n",
    "# regression w/extratrees (lat/lon)\n",
    "xtra = Pipeline([('vect', TfidfVectorizer), ('clf', ExtraTreesRegressor())])    \n",
    "    \n",
    "gsc = GridSearchCV(estimator=xtra, param_grid=grid_param, n_jobs=-1, scoring='r2', cv=5, verbose=1)\n",
    "\n",
    "_train = df_train.sample(1000) # small-scale sandbox, remove this on the server\n",
    "tuning_result = gsc.fit(_train.text.values, _train[[\"lat\", \"lon\"]].values)\n",
    "\n",
    "print(\"Best: %f using %s\" % (tuning_result.best_score_, tuning_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5ZUFJaWanEe",
    "outputId": "b8d3cd4d-e2c2-4060-ff83-01862fcdbee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.19 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.18 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.19 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.18 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.19 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.08 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.04 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.05 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.05 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.06 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.17 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.15 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.15 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.13 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.14 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.04 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.00 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.00 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.14 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.14 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.14 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.14 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.15 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.00 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.02 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.15 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.14 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.13 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.13 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.01 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.15 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.14 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.13 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.14 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.01 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.13 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.14 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.14 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.12 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.12 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.02 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.14 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.13 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.12 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.13 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.14 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.14 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.13 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.13 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.12 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.13 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.12 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.12 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 5, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.20 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.20 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.21 (0.07) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.21 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.21 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.20 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.09 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.05 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.06 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.04 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.21 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.16 (0.07) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.19 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.18 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.18 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.00 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.01 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.00 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.00 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.01 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.18 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.16 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.17 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.17 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.00 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.00 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.01 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.18 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.16 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.17 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.18 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.16 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.17 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.16 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.17 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.15 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.12 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.15 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.02 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.00 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.17 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.15 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.16 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.14 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.06 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.17 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.15 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.16 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.15 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.15 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.17 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.16 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.15 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.15 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.15 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 10, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.22 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.23 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.20 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.22 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.24 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.23 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.12 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.01 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.05 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.04 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 10, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.21 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.19 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.19 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.20 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.19 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.20 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.06 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.01 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.01 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.01 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.00 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 20, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.20 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.18 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.20 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.19 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.18 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.00 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 30, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.19 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.18 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.18 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.20 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.19 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.02 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.02 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.00 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 40, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.19 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.18 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.06) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.18 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.16 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.18 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.00 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 50, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.19 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.18 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.18 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.18 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.18 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 60, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.19 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.18 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.18 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.17 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.01 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.06 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 70, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.19 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.17 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.18 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.17 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.17 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.04 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 80, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.19 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.17 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.05) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.13 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.17 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: -0.17 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: -0.16 (0.03) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: -0.10 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'word', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: -0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.05 (0.01) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.03 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n",
      "Score: 0.02 (0.04) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Score: 0.05 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 3)}\n",
      "Score: 0.04 (0.02) with: {'clf': ExtraTreesRegressor(max_features=15, n_estimators=70), 'clf__max_features': 15, 'clf__n_estimators': 90, 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
      "                ngram_range=(1, 3)), 'vect__analyzer': 'char', 'vect__lowercase': False, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n"
     ]
    }
   ],
   "source": [
    "for test_mean, std, param in zip(\n",
    "        tuning_result.cv_results_['mean_test_score'],\n",
    "        tuning_result.cv_results_['std_test_score'],\n",
    "        tuning_result.cv_results_['params']):\n",
    "    print(f\"Score: {test_mean:.2f} ({std:.2f}) with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsavzHpYbrPe",
    "outputId": "d35ef761-ee9b-450a-b5d3-58b8f168733d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': ExtraTreesRegressor(max_features=15, n_estimators=70),\n",
       " 'clf__max_features': 15,\n",
       " 'clf__n_estimators': 70,\n",
       " 'vect': TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5, min_df=2,\n",
       "                 ngram_range=(1, 3)),\n",
       " 'vect__analyzer': 'char',\n",
       " 'vect__lowercase': False,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__min_df': 2,\n",
       " 'vect__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "fW1vr4k6boD7",
    "outputId": "fc1d0c16-656e-4067-d6e7-17c4cf65cf97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, lowercase=False, max_df=0.5,\n",
       "                                 min_df=2, ngram_range=(1, 3))),\n",
       "                (&#x27;clf&#x27;, ExtraTreesRegressor(max_features=15, n_estimators=70))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, lowercase=False, max_df=0.5,\n",
       "                                 min_df=2, ngram_range=(1, 3))),\n",
       "                (&#x27;clf&#x27;, ExtraTreesRegressor(max_features=15, n_estimators=70))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, lowercase=False, max_df=0.5, min_df=2,\n",
       "                ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(max_features=15, n_estimators=70)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='char', lowercase=False, max_df=0.5,\n",
       "                                 min_df=2, ngram_range=(1, 3))),\n",
       "                ('clf', ExtraTreesRegressor(max_features=15, n_estimators=70))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([('vect', tuning_result.best_params_[\"vect\"]), ('clf', tuning_result.best_params_[\"clf\"])])\n",
    "model.fit(_train.text.values, _train[[\"lat\", \"lon\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjA7nh1vqYZR",
    "outputId": "19f29aa4-e088-4f9d-ab72-2f2ec8689a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of lat predictions: 1.28\n",
      "MAE of lon predictions: 1.61\n"
     ]
    }
   ],
   "source": [
    "xtra_preds = model.predict(df_test.text.values)\n",
    "print(f\"MAE of lat predictions: {metrics.mean_absolute_error(df_test.lat.values, xtra_preds[:, 0]):.2f}\")\n",
    "print(f\"MAE of lon predictions: {metrics.mean_absolute_error(df_test.lon.values, xtra_preds[:, 1]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxvMVm4Q0Qgy",
    "outputId": "000db25c-298b-4759-8217-1469d8d75d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W/XtraTrees, 25% of the predicted places fall within 146.31kms\n",
      "(NOTE: 4 areas out of the 68 were not in the train)\n"
     ]
    }
   ],
   "source": [
    "# interpreting the results in terms of predicted distance\n",
    "dist = km_distance(geocodes=_train.drop_duplicates(\"area\"), \n",
    "                   gold_locs=_train.area.values, \n",
    "                   pred_ll=xtra_preds)\n",
    "print(f\"W/XtraTrees, {25}% of the predicted places fall within {dist.quantile(0.25):.2f}kms\")\n",
    "print(f\"(NOTE: {len(set(df_test.area.unique())-set(df_test.area.unique()).intersection((_train.area.unique())))} areas out of the {len(set(df_test.area.unique()))} were not in the train)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4bpZnp0L_tY"
   },
   "source": [
    "## TF-DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_arr = np.vstack(df_train['representation'].values)\n",
    "\n",
    "# convert numpy array to tensor\n",
    "embeddings = tf.convert_to_tensor(embeddings_arr, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(77085, 768), dtype=float32, numpy=\n",
       "array([[ 0.14053239, -0.7308558 ,  0.8696693 , ...,  1.1983485 ,\n",
       "        -0.49721497,  0.4537516 ],\n",
       "       [-0.6920923 ,  0.08391377,  1.2510726 , ..., -0.20893349,\n",
       "         0.05581681,  0.68383366],\n",
       "       [-0.227305  , -0.717434  ,  0.37106586, ...,  0.88706005,\n",
       "        -1.2724943 ,  0.7528038 ],\n",
       "       ...,\n",
       "       [-0.08039971,  0.00567011,  1.6290509 , ...,  0.56280446,\n",
       "         0.6126828 ,  0.13060434],\n",
       "       [-0.91731757, -0.6683588 ,  0.26397768, ...,  1.3118266 ,\n",
       "        -0.68236375,  0.7196448 ],\n",
       "       [-0.20041801, -0.87810254,  1.2139724 , ...,  0.1320326 ,\n",
       "        -0.24505216, -0.07121552]], dtype=float32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((embeddings, df_train['lon'].values)).batch(10000)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings_arr = np.vstack(df_test['representation'].values)\n",
    "\n",
    "test_embeddings = tf.convert_to_tensor(test_embeddings_arr, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices((test_embeddings, df_test['lon'].values)).batch(10000)\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 10 thread(s) for training\n",
      "Use /var/folders/ys/l39bprrn1mv8cskyrqsspgvr0000gn/T/tmp27txgrib as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 23-05-23 13:42:12.0885 EEST gradient_boosted_trees.cc:1797] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-05-23 13:42:12.0906 EEST gradient_boosted_trees.cc:1808] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-05-23 13:42:12.0906 EEST gradient_boosted_trees.cc:1822] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tensor examples:\n",
      "Features: Tensor(\"data:0\", shape=(None, 768), dtype=float32)\n",
      "Label: Tensor(\"data_1:0\", shape=(None,), dtype=float64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>), 'data:0.49': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_49:0' shape=(None,) dtype=float32>), 'data:0.50': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_50:0' shape=(None,) dtype=float32>), 'data:0.51': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_51:0' shape=(None,) dtype=float32>), 'data:0.52': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_52:0' shape=(None,) dtype=float32>), 'data:0.53': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_53:0' shape=(None,) dtype=float32>), 'data:0.54': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_54:0' shape=(None,) dtype=float32>), 'data:0.55': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_55:0' shape=(None,) dtype=float32>), 'data:0.56': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_56:0' shape=(None,) dtype=float32>), 'data:0.57': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_57:0' shape=(None,) dtype=float32>), 'data:0.58': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_58:0' shape=(None,) dtype=float32>), 'data:0.59': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_59:0' shape=(None,) dtype=float32>), 'data:0.60': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_60:0' shape=(None,) dtype=float32>), 'data:0.61': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_61:0' shape=(None,) dtype=float32>), 'data:0.62': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_62:0' shape=(None,) dtype=float32>), 'data:0.63': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_63:0' shape=(None,) dtype=float32>), 'data:0.64': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_64:0' shape=(None,) dtype=float32>), 'data:0.65': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_65:0' shape=(None,) dtype=float32>), 'data:0.66': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_66:0' shape=(None,) dtype=float32>), 'data:0.67': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_67:0' shape=(None,) dtype=float32>), 'data:0.68': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_68:0' shape=(None,) dtype=float32>), 'data:0.69': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_69:0' shape=(None,) dtype=float32>), 'data:0.70': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_70:0' shape=(None,) dtype=float32>), 'data:0.71': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_71:0' shape=(None,) dtype=float32>), 'data:0.72': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_72:0' shape=(None,) dtype=float32>), 'data:0.73': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_73:0' shape=(None,) dtype=float32>), 'data:0.74': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_74:0' shape=(None,) dtype=float32>), 'data:0.75': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_75:0' shape=(None,) dtype=float32>), 'data:0.76': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_76:0' shape=(None,) dtype=float32>), 'data:0.77': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_77:0' shape=(None,) dtype=float32>), 'data:0.78': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_78:0' shape=(None,) dtype=float32>), 'data:0.79': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_79:0' shape=(None,) dtype=float32>), 'data:0.80': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_80:0' shape=(None,) dtype=float32>), 'data:0.81': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_81:0' shape=(None,) dtype=float32>), 'data:0.82': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_82:0' shape=(None,) dtype=float32>), 'data:0.83': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_83:0' shape=(None,) dtype=float32>), 'data:0.84': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_84:0' shape=(None,) dtype=float32>), 'data:0.85': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_85:0' shape=(None,) dtype=float32>), 'data:0.86': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_86:0' shape=(None,) dtype=float32>), 'data:0.87': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_87:0' shape=(None,) dtype=float32>), 'data:0.88': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_88:0' shape=(None,) dtype=float32>), 'data:0.89': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_89:0' shape=(None,) dtype=float32>), 'data:0.90': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_90:0' shape=(None,) dtype=float32>), 'data:0.91': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_91:0' shape=(None,) dtype=float32>), 'data:0.92': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_92:0' shape=(None,) dtype=float32>), 'data:0.93': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_93:0' shape=(None,) dtype=float32>), 'data:0.94': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_94:0' shape=(None,) dtype=float32>), 'data:0.95': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_95:0' shape=(None,) dtype=float32>), 'data:0.96': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_96:0' shape=(None,) dtype=float32>), 'data:0.97': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_97:0' shape=(None,) dtype=float32>), 'data:0.98': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_98:0' shape=(None,) dtype=float32>), 'data:0.99': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_99:0' shape=(None,) dtype=float32>), 'data:0.100': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_100:0' shape=(None,) dtype=float32>), 'data:0.101': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_101:0' shape=(None,) dtype=float32>), 'data:0.102': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_102:0' shape=(None,) dtype=float32>), 'data:0.103': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_103:0' shape=(None,) dtype=float32>), 'data:0.104': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_104:0' shape=(None,) dtype=float32>), 'data:0.105': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_105:0' shape=(None,) dtype=float32>), 'data:0.106': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_106:0' shape=(None,) dtype=float32>), 'data:0.107': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_107:0' shape=(None,) dtype=float32>), 'data:0.108': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_108:0' shape=(None,) dtype=float32>), 'data:0.109': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_109:0' shape=(None,) dtype=float32>), 'data:0.110': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_110:0' shape=(None,) dtype=float32>), 'data:0.111': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_111:0' shape=(None,) dtype=float32>), 'data:0.112': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_112:0' shape=(None,) dtype=float32>), 'data:0.113': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_113:0' shape=(None,) dtype=float32>), 'data:0.114': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_114:0' shape=(None,) dtype=float32>), 'data:0.115': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_115:0' shape=(None,) dtype=float32>), 'data:0.116': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_116:0' shape=(None,) dtype=float32>), 'data:0.117': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_117:0' shape=(None,) dtype=float32>), 'data:0.118': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_118:0' shape=(None,) dtype=float32>), 'data:0.119': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_119:0' shape=(None,) dtype=float32>), 'data:0.120': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_120:0' shape=(None,) dtype=float32>), 'data:0.121': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_121:0' shape=(None,) dtype=float32>), 'data:0.122': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_122:0' shape=(None,) dtype=float32>), 'data:0.123': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_123:0' shape=(None,) dtype=float32>), 'data:0.124': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_124:0' shape=(None,) dtype=float32>), 'data:0.125': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_125:0' shape=(None,) dtype=float32>), 'data:0.126': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_126:0' shape=(None,) dtype=float32>), 'data:0.127': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_127:0' shape=(None,) dtype=float32>), 'data:0.128': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_128:0' shape=(None,) dtype=float32>), 'data:0.129': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_129:0' shape=(None,) dtype=float32>), 'data:0.130': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_130:0' shape=(None,) dtype=float32>), 'data:0.131': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_131:0' shape=(None,) dtype=float32>), 'data:0.132': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_132:0' shape=(None,) dtype=float32>), 'data:0.133': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_133:0' shape=(None,) dtype=float32>), 'data:0.134': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_134:0' shape=(None,) dtype=float32>), 'data:0.135': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_135:0' shape=(None,) dtype=float32>), 'data:0.136': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_136:0' shape=(None,) dtype=float32>), 'data:0.137': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_137:0' shape=(None,) dtype=float32>), 'data:0.138': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_138:0' shape=(None,) dtype=float32>), 'data:0.139': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_139:0' shape=(None,) dtype=float32>), 'data:0.140': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_140:0' shape=(None,) dtype=float32>), 'data:0.141': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_141:0' shape=(None,) dtype=float32>), 'data:0.142': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_142:0' shape=(None,) dtype=float32>), 'data:0.143': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_143:0' shape=(None,) dtype=float32>), 'data:0.144': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_144:0' shape=(None,) dtype=float32>), 'data:0.145': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_145:0' shape=(None,) dtype=float32>), 'data:0.146': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_146:0' shape=(None,) dtype=float32>), 'data:0.147': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_147:0' shape=(None,) dtype=float32>), 'data:0.148': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_148:0' shape=(None,) dtype=float32>), 'data:0.149': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_149:0' shape=(None,) dtype=float32>), 'data:0.150': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_150:0' shape=(None,) dtype=float32>), 'data:0.151': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_151:0' shape=(None,) dtype=float32>), 'data:0.152': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_152:0' shape=(None,) dtype=float32>), 'data:0.153': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_153:0' shape=(None,) dtype=float32>), 'data:0.154': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_154:0' shape=(None,) dtype=float32>), 'data:0.155': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_155:0' shape=(None,) dtype=float32>), 'data:0.156': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_156:0' shape=(None,) dtype=float32>), 'data:0.157': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_157:0' shape=(None,) dtype=float32>), 'data:0.158': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_158:0' shape=(None,) dtype=float32>), 'data:0.159': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_159:0' shape=(None,) dtype=float32>), 'data:0.160': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_160:0' shape=(None,) dtype=float32>), 'data:0.161': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_161:0' shape=(None,) dtype=float32>), 'data:0.162': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_162:0' shape=(None,) dtype=float32>), 'data:0.163': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_163:0' shape=(None,) dtype=float32>), 'data:0.164': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_164:0' shape=(None,) dtype=float32>), 'data:0.165': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_165:0' shape=(None,) dtype=float32>), 'data:0.166': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_166:0' shape=(None,) dtype=float32>), 'data:0.167': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_167:0' shape=(None,) dtype=float32>), 'data:0.168': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_168:0' shape=(None,) dtype=float32>), 'data:0.169': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_169:0' shape=(None,) dtype=float32>), 'data:0.170': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_170:0' shape=(None,) dtype=float32>), 'data:0.171': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_171:0' shape=(None,) dtype=float32>), 'data:0.172': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_172:0' shape=(None,) dtype=float32>), 'data:0.173': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_173:0' shape=(None,) dtype=float32>), 'data:0.174': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_174:0' shape=(None,) dtype=float32>), 'data:0.175': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_175:0' shape=(None,) dtype=float32>), 'data:0.176': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_176:0' shape=(None,) dtype=float32>), 'data:0.177': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_177:0' shape=(None,) dtype=float32>), 'data:0.178': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_178:0' shape=(None,) dtype=float32>), 'data:0.179': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_179:0' shape=(None,) dtype=float32>), 'data:0.180': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_180:0' shape=(None,) dtype=float32>), 'data:0.181': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_181:0' shape=(None,) dtype=float32>), 'data:0.182': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_182:0' shape=(None,) dtype=float32>), 'data:0.183': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_183:0' shape=(None,) dtype=float32>), 'data:0.184': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_184:0' shape=(None,) dtype=float32>), 'data:0.185': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_185:0' shape=(None,) dtype=float32>), 'data:0.186': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_186:0' shape=(None,) dtype=float32>), 'data:0.187': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_187:0' shape=(None,) dtype=float32>), 'data:0.188': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_188:0' shape=(None,) dtype=float32>), 'data:0.189': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_189:0' shape=(None,) dtype=float32>), 'data:0.190': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_190:0' shape=(None,) dtype=float32>), 'data:0.191': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_191:0' shape=(None,) dtype=float32>), 'data:0.192': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_192:0' shape=(None,) dtype=float32>), 'data:0.193': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_193:0' shape=(None,) dtype=float32>), 'data:0.194': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_194:0' shape=(None,) dtype=float32>), 'data:0.195': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_195:0' shape=(None,) dtype=float32>), 'data:0.196': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_196:0' shape=(None,) dtype=float32>), 'data:0.197': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_197:0' shape=(None,) dtype=float32>), 'data:0.198': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_198:0' shape=(None,) dtype=float32>), 'data:0.199': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_199:0' shape=(None,) dtype=float32>), 'data:0.200': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_200:0' shape=(None,) dtype=float32>), 'data:0.201': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_201:0' shape=(None,) dtype=float32>), 'data:0.202': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_202:0' shape=(None,) dtype=float32>), 'data:0.203': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_203:0' shape=(None,) dtype=float32>), 'data:0.204': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_204:0' shape=(None,) dtype=float32>), 'data:0.205': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_205:0' shape=(None,) dtype=float32>), 'data:0.206': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_206:0' shape=(None,) dtype=float32>), 'data:0.207': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_207:0' shape=(None,) dtype=float32>), 'data:0.208': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_208:0' shape=(None,) dtype=float32>), 'data:0.209': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_209:0' shape=(None,) dtype=float32>), 'data:0.210': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_210:0' shape=(None,) dtype=float32>), 'data:0.211': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_211:0' shape=(None,) dtype=float32>), 'data:0.212': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_212:0' shape=(None,) dtype=float32>), 'data:0.213': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_213:0' shape=(None,) dtype=float32>), 'data:0.214': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_214:0' shape=(None,) dtype=float32>), 'data:0.215': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_215:0' shape=(None,) dtype=float32>), 'data:0.216': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_216:0' shape=(None,) dtype=float32>), 'data:0.217': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_217:0' shape=(None,) dtype=float32>), 'data:0.218': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_218:0' shape=(None,) dtype=float32>), 'data:0.219': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_219:0' shape=(None,) dtype=float32>), 'data:0.220': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_220:0' shape=(None,) dtype=float32>), 'data:0.221': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_221:0' shape=(None,) dtype=float32>), 'data:0.222': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_222:0' shape=(None,) dtype=float32>), 'data:0.223': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_223:0' shape=(None,) dtype=float32>), 'data:0.224': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_224:0' shape=(None,) dtype=float32>), 'data:0.225': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_225:0' shape=(None,) dtype=float32>), 'data:0.226': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_226:0' shape=(None,) dtype=float32>), 'data:0.227': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_227:0' shape=(None,) dtype=float32>), 'data:0.228': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_228:0' shape=(None,) dtype=float32>), 'data:0.229': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_229:0' shape=(None,) dtype=float32>), 'data:0.230': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_230:0' shape=(None,) dtype=float32>), 'data:0.231': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_231:0' shape=(None,) dtype=float32>), 'data:0.232': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_232:0' shape=(None,) dtype=float32>), 'data:0.233': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_233:0' shape=(None,) dtype=float32>), 'data:0.234': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_234:0' shape=(None,) dtype=float32>), 'data:0.235': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_235:0' shape=(None,) dtype=float32>), 'data:0.236': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_236:0' shape=(None,) dtype=float32>), 'data:0.237': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_237:0' shape=(None,) dtype=float32>), 'data:0.238': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_238:0' shape=(None,) dtype=float32>), 'data:0.239': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_239:0' shape=(None,) dtype=float32>), 'data:0.240': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_240:0' shape=(None,) dtype=float32>), 'data:0.241': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_241:0' shape=(None,) dtype=float32>), 'data:0.242': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_242:0' shape=(None,) dtype=float32>), 'data:0.243': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_243:0' shape=(None,) dtype=float32>), 'data:0.244': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_244:0' shape=(None,) dtype=float32>), 'data:0.245': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_245:0' shape=(None,) dtype=float32>), 'data:0.246': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_246:0' shape=(None,) dtype=float32>), 'data:0.247': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_247:0' shape=(None,) dtype=float32>), 'data:0.248': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_248:0' shape=(None,) dtype=float32>), 'data:0.249': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_249:0' shape=(None,) dtype=float32>), 'data:0.250': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_250:0' shape=(None,) dtype=float32>), 'data:0.251': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_251:0' shape=(None,) dtype=float32>), 'data:0.252': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_252:0' shape=(None,) dtype=float32>), 'data:0.253': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_253:0' shape=(None,) dtype=float32>), 'data:0.254': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_254:0' shape=(None,) dtype=float32>), 'data:0.255': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_255:0' shape=(None,) dtype=float32>), 'data:0.256': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_256:0' shape=(None,) dtype=float32>), 'data:0.257': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_257:0' shape=(None,) dtype=float32>), 'data:0.258': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_258:0' shape=(None,) dtype=float32>), 'data:0.259': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_259:0' shape=(None,) dtype=float32>), 'data:0.260': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_260:0' shape=(None,) dtype=float32>), 'data:0.261': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_261:0' shape=(None,) dtype=float32>), 'data:0.262': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_262:0' shape=(None,) dtype=float32>), 'data:0.263': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_263:0' shape=(None,) dtype=float32>), 'data:0.264': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_264:0' shape=(None,) dtype=float32>), 'data:0.265': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_265:0' shape=(None,) dtype=float32>), 'data:0.266': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_266:0' shape=(None,) dtype=float32>), 'data:0.267': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_267:0' shape=(None,) dtype=float32>), 'data:0.268': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_268:0' shape=(None,) dtype=float32>), 'data:0.269': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_269:0' shape=(None,) dtype=float32>), 'data:0.270': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_270:0' shape=(None,) dtype=float32>), 'data:0.271': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_271:0' shape=(None,) dtype=float32>), 'data:0.272': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_272:0' shape=(None,) dtype=float32>), 'data:0.273': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_273:0' shape=(None,) dtype=float32>), 'data:0.274': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_274:0' shape=(None,) dtype=float32>), 'data:0.275': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_275:0' shape=(None,) dtype=float32>), 'data:0.276': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_276:0' shape=(None,) dtype=float32>), 'data:0.277': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_277:0' shape=(None,) dtype=float32>), 'data:0.278': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_278:0' shape=(None,) dtype=float32>), 'data:0.279': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_279:0' shape=(None,) dtype=float32>), 'data:0.280': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_280:0' shape=(None,) dtype=float32>), 'data:0.281': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_281:0' shape=(None,) dtype=float32>), 'data:0.282': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_282:0' shape=(None,) dtype=float32>), 'data:0.283': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_283:0' shape=(None,) dtype=float32>), 'data:0.284': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_284:0' shape=(None,) dtype=float32>), 'data:0.285': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_285:0' shape=(None,) dtype=float32>), 'data:0.286': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_286:0' shape=(None,) dtype=float32>), 'data:0.287': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_287:0' shape=(None,) dtype=float32>), 'data:0.288': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_288:0' shape=(None,) dtype=float32>), 'data:0.289': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_289:0' shape=(None,) dtype=float32>), 'data:0.290': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_290:0' shape=(None,) dtype=float32>), 'data:0.291': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_291:0' shape=(None,) dtype=float32>), 'data:0.292': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_292:0' shape=(None,) dtype=float32>), 'data:0.293': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_293:0' shape=(None,) dtype=float32>), 'data:0.294': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_294:0' shape=(None,) dtype=float32>), 'data:0.295': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_295:0' shape=(None,) dtype=float32>), 'data:0.296': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_296:0' shape=(None,) dtype=float32>), 'data:0.297': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_297:0' shape=(None,) dtype=float32>), 'data:0.298': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_298:0' shape=(None,) dtype=float32>), 'data:0.299': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_299:0' shape=(None,) dtype=float32>), 'data:0.300': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_300:0' shape=(None,) dtype=float32>), 'data:0.301': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_301:0' shape=(None,) dtype=float32>), 'data:0.302': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_302:0' shape=(None,) dtype=float32>), 'data:0.303': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_303:0' shape=(None,) dtype=float32>), 'data:0.304': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_304:0' shape=(None,) dtype=float32>), 'data:0.305': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_305:0' shape=(None,) dtype=float32>), 'data:0.306': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_306:0' shape=(None,) dtype=float32>), 'data:0.307': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_307:0' shape=(None,) dtype=float32>), 'data:0.308': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_308:0' shape=(None,) dtype=float32>), 'data:0.309': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_309:0' shape=(None,) dtype=float32>), 'data:0.310': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_310:0' shape=(None,) dtype=float32>), 'data:0.311': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_311:0' shape=(None,) dtype=float32>), 'data:0.312': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_312:0' shape=(None,) dtype=float32>), 'data:0.313': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_313:0' shape=(None,) dtype=float32>), 'data:0.314': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_314:0' shape=(None,) dtype=float32>), 'data:0.315': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_315:0' shape=(None,) dtype=float32>), 'data:0.316': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_316:0' shape=(None,) dtype=float32>), 'data:0.317': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_317:0' shape=(None,) dtype=float32>), 'data:0.318': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_318:0' shape=(None,) dtype=float32>), 'data:0.319': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_319:0' shape=(None,) dtype=float32>), 'data:0.320': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_320:0' shape=(None,) dtype=float32>), 'data:0.321': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_321:0' shape=(None,) dtype=float32>), 'data:0.322': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_322:0' shape=(None,) dtype=float32>), 'data:0.323': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_323:0' shape=(None,) dtype=float32>), 'data:0.324': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_324:0' shape=(None,) dtype=float32>), 'data:0.325': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_325:0' shape=(None,) dtype=float32>), 'data:0.326': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_326:0' shape=(None,) dtype=float32>), 'data:0.327': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_327:0' shape=(None,) dtype=float32>), 'data:0.328': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_328:0' shape=(None,) dtype=float32>), 'data:0.329': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_329:0' shape=(None,) dtype=float32>), 'data:0.330': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_330:0' shape=(None,) dtype=float32>), 'data:0.331': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_331:0' shape=(None,) dtype=float32>), 'data:0.332': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_332:0' shape=(None,) dtype=float32>), 'data:0.333': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_333:0' shape=(None,) dtype=float32>), 'data:0.334': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_334:0' shape=(None,) dtype=float32>), 'data:0.335': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_335:0' shape=(None,) dtype=float32>), 'data:0.336': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_336:0' shape=(None,) dtype=float32>), 'data:0.337': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_337:0' shape=(None,) dtype=float32>), 'data:0.338': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_338:0' shape=(None,) dtype=float32>), 'data:0.339': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_339:0' shape=(None,) dtype=float32>), 'data:0.340': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_340:0' shape=(None,) dtype=float32>), 'data:0.341': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_341:0' shape=(None,) dtype=float32>), 'data:0.342': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_342:0' shape=(None,) dtype=float32>), 'data:0.343': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_343:0' shape=(None,) dtype=float32>), 'data:0.344': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_344:0' shape=(None,) dtype=float32>), 'data:0.345': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_345:0' shape=(None,) dtype=float32>), 'data:0.346': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_346:0' shape=(None,) dtype=float32>), 'data:0.347': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_347:0' shape=(None,) dtype=float32>), 'data:0.348': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_348:0' shape=(None,) dtype=float32>), 'data:0.349': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_349:0' shape=(None,) dtype=float32>), 'data:0.350': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_350:0' shape=(None,) dtype=float32>), 'data:0.351': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_351:0' shape=(None,) dtype=float32>), 'data:0.352': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_352:0' shape=(None,) dtype=float32>), 'data:0.353': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_353:0' shape=(None,) dtype=float32>), 'data:0.354': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_354:0' shape=(None,) dtype=float32>), 'data:0.355': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_355:0' shape=(None,) dtype=float32>), 'data:0.356': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_356:0' shape=(None,) dtype=float32>), 'data:0.357': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_357:0' shape=(None,) dtype=float32>), 'data:0.358': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_358:0' shape=(None,) dtype=float32>), 'data:0.359': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_359:0' shape=(None,) dtype=float32>), 'data:0.360': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_360:0' shape=(None,) dtype=float32>), 'data:0.361': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_361:0' shape=(None,) dtype=float32>), 'data:0.362': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_362:0' shape=(None,) dtype=float32>), 'data:0.363': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_363:0' shape=(None,) dtype=float32>), 'data:0.364': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_364:0' shape=(None,) dtype=float32>), 'data:0.365': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_365:0' shape=(None,) dtype=float32>), 'data:0.366': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_366:0' shape=(None,) dtype=float32>), 'data:0.367': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_367:0' shape=(None,) dtype=float32>), 'data:0.368': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_368:0' shape=(None,) dtype=float32>), 'data:0.369': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_369:0' shape=(None,) dtype=float32>), 'data:0.370': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_370:0' shape=(None,) dtype=float32>), 'data:0.371': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_371:0' shape=(None,) dtype=float32>), 'data:0.372': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_372:0' shape=(None,) dtype=float32>), 'data:0.373': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_373:0' shape=(None,) dtype=float32>), 'data:0.374': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_374:0' shape=(None,) dtype=float32>), 'data:0.375': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_375:0' shape=(None,) dtype=float32>), 'data:0.376': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_376:0' shape=(None,) dtype=float32>), 'data:0.377': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_377:0' shape=(None,) dtype=float32>), 'data:0.378': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_378:0' shape=(None,) dtype=float32>), 'data:0.379': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_379:0' shape=(None,) dtype=float32>), 'data:0.380': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_380:0' shape=(None,) dtype=float32>), 'data:0.381': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_381:0' shape=(None,) dtype=float32>), 'data:0.382': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_382:0' shape=(None,) dtype=float32>), 'data:0.383': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_383:0' shape=(None,) dtype=float32>), 'data:0.384': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_384:0' shape=(None,) dtype=float32>), 'data:0.385': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_385:0' shape=(None,) dtype=float32>), 'data:0.386': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_386:0' shape=(None,) dtype=float32>), 'data:0.387': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_387:0' shape=(None,) dtype=float32>), 'data:0.388': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_388:0' shape=(None,) dtype=float32>), 'data:0.389': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_389:0' shape=(None,) dtype=float32>), 'data:0.390': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_390:0' shape=(None,) dtype=float32>), 'data:0.391': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_391:0' shape=(None,) dtype=float32>), 'data:0.392': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_392:0' shape=(None,) dtype=float32>), 'data:0.393': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_393:0' shape=(None,) dtype=float32>), 'data:0.394': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_394:0' shape=(None,) dtype=float32>), 'data:0.395': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_395:0' shape=(None,) dtype=float32>), 'data:0.396': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_396:0' shape=(None,) dtype=float32>), 'data:0.397': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_397:0' shape=(None,) dtype=float32>), 'data:0.398': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_398:0' shape=(None,) dtype=float32>), 'data:0.399': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_399:0' shape=(None,) dtype=float32>), 'data:0.400': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_400:0' shape=(None,) dtype=float32>), 'data:0.401': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_401:0' shape=(None,) dtype=float32>), 'data:0.402': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_402:0' shape=(None,) dtype=float32>), 'data:0.403': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_403:0' shape=(None,) dtype=float32>), 'data:0.404': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_404:0' shape=(None,) dtype=float32>), 'data:0.405': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_405:0' shape=(None,) dtype=float32>), 'data:0.406': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_406:0' shape=(None,) dtype=float32>), 'data:0.407': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_407:0' shape=(None,) dtype=float32>), 'data:0.408': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_408:0' shape=(None,) dtype=float32>), 'data:0.409': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_409:0' shape=(None,) dtype=float32>), 'data:0.410': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_410:0' shape=(None,) dtype=float32>), 'data:0.411': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_411:0' shape=(None,) dtype=float32>), 'data:0.412': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_412:0' shape=(None,) dtype=float32>), 'data:0.413': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_413:0' shape=(None,) dtype=float32>), 'data:0.414': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_414:0' shape=(None,) dtype=float32>), 'data:0.415': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_415:0' shape=(None,) dtype=float32>), 'data:0.416': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_416:0' shape=(None,) dtype=float32>), 'data:0.417': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_417:0' shape=(None,) dtype=float32>), 'data:0.418': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_418:0' shape=(None,) dtype=float32>), 'data:0.419': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_419:0' shape=(None,) dtype=float32>), 'data:0.420': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_420:0' shape=(None,) dtype=float32>), 'data:0.421': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_421:0' shape=(None,) dtype=float32>), 'data:0.422': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_422:0' shape=(None,) dtype=float32>), 'data:0.423': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_423:0' shape=(None,) dtype=float32>), 'data:0.424': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_424:0' shape=(None,) dtype=float32>), 'data:0.425': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_425:0' shape=(None,) dtype=float32>), 'data:0.426': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_426:0' shape=(None,) dtype=float32>), 'data:0.427': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_427:0' shape=(None,) dtype=float32>), 'data:0.428': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_428:0' shape=(None,) dtype=float32>), 'data:0.429': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_429:0' shape=(None,) dtype=float32>), 'data:0.430': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_430:0' shape=(None,) dtype=float32>), 'data:0.431': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_431:0' shape=(None,) dtype=float32>), 'data:0.432': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_432:0' shape=(None,) dtype=float32>), 'data:0.433': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_433:0' shape=(None,) dtype=float32>), 'data:0.434': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_434:0' shape=(None,) dtype=float32>), 'data:0.435': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_435:0' shape=(None,) dtype=float32>), 'data:0.436': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_436:0' shape=(None,) dtype=float32>), 'data:0.437': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_437:0' shape=(None,) dtype=float32>), 'data:0.438': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_438:0' shape=(None,) dtype=float32>), 'data:0.439': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_439:0' shape=(None,) dtype=float32>), 'data:0.440': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_440:0' shape=(None,) dtype=float32>), 'data:0.441': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_441:0' shape=(None,) dtype=float32>), 'data:0.442': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_442:0' shape=(None,) dtype=float32>), 'data:0.443': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_443:0' shape=(None,) dtype=float32>), 'data:0.444': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_444:0' shape=(None,) dtype=float32>), 'data:0.445': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_445:0' shape=(None,) dtype=float32>), 'data:0.446': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_446:0' shape=(None,) dtype=float32>), 'data:0.447': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_447:0' shape=(None,) dtype=float32>), 'data:0.448': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_448:0' shape=(None,) dtype=float32>), 'data:0.449': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_449:0' shape=(None,) dtype=float32>), 'data:0.450': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_450:0' shape=(None,) dtype=float32>), 'data:0.451': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_451:0' shape=(None,) dtype=float32>), 'data:0.452': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_452:0' shape=(None,) dtype=float32>), 'data:0.453': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_453:0' shape=(None,) dtype=float32>), 'data:0.454': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_454:0' shape=(None,) dtype=float32>), 'data:0.455': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_455:0' shape=(None,) dtype=float32>), 'data:0.456': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_456:0' shape=(None,) dtype=float32>), 'data:0.457': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_457:0' shape=(None,) dtype=float32>), 'data:0.458': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_458:0' shape=(None,) dtype=float32>), 'data:0.459': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_459:0' shape=(None,) dtype=float32>), 'data:0.460': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_460:0' shape=(None,) dtype=float32>), 'data:0.461': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_461:0' shape=(None,) dtype=float32>), 'data:0.462': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_462:0' shape=(None,) dtype=float32>), 'data:0.463': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_463:0' shape=(None,) dtype=float32>), 'data:0.464': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_464:0' shape=(None,) dtype=float32>), 'data:0.465': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_465:0' shape=(None,) dtype=float32>), 'data:0.466': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_466:0' shape=(None,) dtype=float32>), 'data:0.467': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_467:0' shape=(None,) dtype=float32>), 'data:0.468': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_468:0' shape=(None,) dtype=float32>), 'data:0.469': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_469:0' shape=(None,) dtype=float32>), 'data:0.470': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_470:0' shape=(None,) dtype=float32>), 'data:0.471': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_471:0' shape=(None,) dtype=float32>), 'data:0.472': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_472:0' shape=(None,) dtype=float32>), 'data:0.473': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_473:0' shape=(None,) dtype=float32>), 'data:0.474': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_474:0' shape=(None,) dtype=float32>), 'data:0.475': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_475:0' shape=(None,) dtype=float32>), 'data:0.476': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_476:0' shape=(None,) dtype=float32>), 'data:0.477': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_477:0' shape=(None,) dtype=float32>), 'data:0.478': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_478:0' shape=(None,) dtype=float32>), 'data:0.479': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_479:0' shape=(None,) dtype=float32>), 'data:0.480': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_480:0' shape=(None,) dtype=float32>), 'data:0.481': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_481:0' shape=(None,) dtype=float32>), 'data:0.482': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_482:0' shape=(None,) dtype=float32>), 'data:0.483': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_483:0' shape=(None,) dtype=float32>), 'data:0.484': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_484:0' shape=(None,) dtype=float32>), 'data:0.485': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_485:0' shape=(None,) dtype=float32>), 'data:0.486': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_486:0' shape=(None,) dtype=float32>), 'data:0.487': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_487:0' shape=(None,) dtype=float32>), 'data:0.488': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_488:0' shape=(None,) dtype=float32>), 'data:0.489': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_489:0' shape=(None,) dtype=float32>), 'data:0.490': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_490:0' shape=(None,) dtype=float32>), 'data:0.491': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_491:0' shape=(None,) dtype=float32>), 'data:0.492': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_492:0' shape=(None,) dtype=float32>), 'data:0.493': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_493:0' shape=(None,) dtype=float32>), 'data:0.494': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_494:0' shape=(None,) dtype=float32>), 'data:0.495': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_495:0' shape=(None,) dtype=float32>), 'data:0.496': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_496:0' shape=(None,) dtype=float32>), 'data:0.497': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_497:0' shape=(None,) dtype=float32>), 'data:0.498': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_498:0' shape=(None,) dtype=float32>), 'data:0.499': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_499:0' shape=(None,) dtype=float32>), 'data:0.500': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_500:0' shape=(None,) dtype=float32>), 'data:0.501': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_501:0' shape=(None,) dtype=float32>), 'data:0.502': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_502:0' shape=(None,) dtype=float32>), 'data:0.503': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_503:0' shape=(None,) dtype=float32>), 'data:0.504': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_504:0' shape=(None,) dtype=float32>), 'data:0.505': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_505:0' shape=(None,) dtype=float32>), 'data:0.506': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_506:0' shape=(None,) dtype=float32>), 'data:0.507': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_507:0' shape=(None,) dtype=float32>), 'data:0.508': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_508:0' shape=(None,) dtype=float32>), 'data:0.509': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_509:0' shape=(None,) dtype=float32>), 'data:0.510': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_510:0' shape=(None,) dtype=float32>), 'data:0.511': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_511:0' shape=(None,) dtype=float32>), 'data:0.512': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_512:0' shape=(None,) dtype=float32>), 'data:0.513': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_513:0' shape=(None,) dtype=float32>), 'data:0.514': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_514:0' shape=(None,) dtype=float32>), 'data:0.515': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_515:0' shape=(None,) dtype=float32>), 'data:0.516': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_516:0' shape=(None,) dtype=float32>), 'data:0.517': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_517:0' shape=(None,) dtype=float32>), 'data:0.518': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_518:0' shape=(None,) dtype=float32>), 'data:0.519': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_519:0' shape=(None,) dtype=float32>), 'data:0.520': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_520:0' shape=(None,) dtype=float32>), 'data:0.521': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_521:0' shape=(None,) dtype=float32>), 'data:0.522': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_522:0' shape=(None,) dtype=float32>), 'data:0.523': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_523:0' shape=(None,) dtype=float32>), 'data:0.524': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_524:0' shape=(None,) dtype=float32>), 'data:0.525': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_525:0' shape=(None,) dtype=float32>), 'data:0.526': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_526:0' shape=(None,) dtype=float32>), 'data:0.527': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_527:0' shape=(None,) dtype=float32>), 'data:0.528': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_528:0' shape=(None,) dtype=float32>), 'data:0.529': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_529:0' shape=(None,) dtype=float32>), 'data:0.530': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_530:0' shape=(None,) dtype=float32>), 'data:0.531': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_531:0' shape=(None,) dtype=float32>), 'data:0.532': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_532:0' shape=(None,) dtype=float32>), 'data:0.533': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_533:0' shape=(None,) dtype=float32>), 'data:0.534': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_534:0' shape=(None,) dtype=float32>), 'data:0.535': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_535:0' shape=(None,) dtype=float32>), 'data:0.536': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_536:0' shape=(None,) dtype=float32>), 'data:0.537': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_537:0' shape=(None,) dtype=float32>), 'data:0.538': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_538:0' shape=(None,) dtype=float32>), 'data:0.539': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_539:0' shape=(None,) dtype=float32>), 'data:0.540': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_540:0' shape=(None,) dtype=float32>), 'data:0.541': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_541:0' shape=(None,) dtype=float32>), 'data:0.542': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_542:0' shape=(None,) dtype=float32>), 'data:0.543': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_543:0' shape=(None,) dtype=float32>), 'data:0.544': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_544:0' shape=(None,) dtype=float32>), 'data:0.545': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_545:0' shape=(None,) dtype=float32>), 'data:0.546': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_546:0' shape=(None,) dtype=float32>), 'data:0.547': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_547:0' shape=(None,) dtype=float32>), 'data:0.548': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_548:0' shape=(None,) dtype=float32>), 'data:0.549': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_549:0' shape=(None,) dtype=float32>), 'data:0.550': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_550:0' shape=(None,) dtype=float32>), 'data:0.551': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_551:0' shape=(None,) dtype=float32>), 'data:0.552': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_552:0' shape=(None,) dtype=float32>), 'data:0.553': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_553:0' shape=(None,) dtype=float32>), 'data:0.554': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_554:0' shape=(None,) dtype=float32>), 'data:0.555': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_555:0' shape=(None,) dtype=float32>), 'data:0.556': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_556:0' shape=(None,) dtype=float32>), 'data:0.557': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_557:0' shape=(None,) dtype=float32>), 'data:0.558': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_558:0' shape=(None,) dtype=float32>), 'data:0.559': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_559:0' shape=(None,) dtype=float32>), 'data:0.560': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_560:0' shape=(None,) dtype=float32>), 'data:0.561': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_561:0' shape=(None,) dtype=float32>), 'data:0.562': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_562:0' shape=(None,) dtype=float32>), 'data:0.563': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_563:0' shape=(None,) dtype=float32>), 'data:0.564': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_564:0' shape=(None,) dtype=float32>), 'data:0.565': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_565:0' shape=(None,) dtype=float32>), 'data:0.566': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_566:0' shape=(None,) dtype=float32>), 'data:0.567': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_567:0' shape=(None,) dtype=float32>), 'data:0.568': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_568:0' shape=(None,) dtype=float32>), 'data:0.569': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_569:0' shape=(None,) dtype=float32>), 'data:0.570': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_570:0' shape=(None,) dtype=float32>), 'data:0.571': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_571:0' shape=(None,) dtype=float32>), 'data:0.572': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_572:0' shape=(None,) dtype=float32>), 'data:0.573': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_573:0' shape=(None,) dtype=float32>), 'data:0.574': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_574:0' shape=(None,) dtype=float32>), 'data:0.575': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_575:0' shape=(None,) dtype=float32>), 'data:0.576': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_576:0' shape=(None,) dtype=float32>), 'data:0.577': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_577:0' shape=(None,) dtype=float32>), 'data:0.578': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_578:0' shape=(None,) dtype=float32>), 'data:0.579': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_579:0' shape=(None,) dtype=float32>), 'data:0.580': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_580:0' shape=(None,) dtype=float32>), 'data:0.581': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_581:0' shape=(None,) dtype=float32>), 'data:0.582': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_582:0' shape=(None,) dtype=float32>), 'data:0.583': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_583:0' shape=(None,) dtype=float32>), 'data:0.584': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_584:0' shape=(None,) dtype=float32>), 'data:0.585': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_585:0' shape=(None,) dtype=float32>), 'data:0.586': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_586:0' shape=(None,) dtype=float32>), 'data:0.587': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_587:0' shape=(None,) dtype=float32>), 'data:0.588': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_588:0' shape=(None,) dtype=float32>), 'data:0.589': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_589:0' shape=(None,) dtype=float32>), 'data:0.590': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_590:0' shape=(None,) dtype=float32>), 'data:0.591': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_591:0' shape=(None,) dtype=float32>), 'data:0.592': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_592:0' shape=(None,) dtype=float32>), 'data:0.593': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_593:0' shape=(None,) dtype=float32>), 'data:0.594': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_594:0' shape=(None,) dtype=float32>), 'data:0.595': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_595:0' shape=(None,) dtype=float32>), 'data:0.596': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_596:0' shape=(None,) dtype=float32>), 'data:0.597': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_597:0' shape=(None,) dtype=float32>), 'data:0.598': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_598:0' shape=(None,) dtype=float32>), 'data:0.599': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_599:0' shape=(None,) dtype=float32>), 'data:0.600': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_600:0' shape=(None,) dtype=float32>), 'data:0.601': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_601:0' shape=(None,) dtype=float32>), 'data:0.602': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_602:0' shape=(None,) dtype=float32>), 'data:0.603': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_603:0' shape=(None,) dtype=float32>), 'data:0.604': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_604:0' shape=(None,) dtype=float32>), 'data:0.605': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_605:0' shape=(None,) dtype=float32>), 'data:0.606': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_606:0' shape=(None,) dtype=float32>), 'data:0.607': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_607:0' shape=(None,) dtype=float32>), 'data:0.608': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_608:0' shape=(None,) dtype=float32>), 'data:0.609': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_609:0' shape=(None,) dtype=float32>), 'data:0.610': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_610:0' shape=(None,) dtype=float32>), 'data:0.611': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_611:0' shape=(None,) dtype=float32>), 'data:0.612': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_612:0' shape=(None,) dtype=float32>), 'data:0.613': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_613:0' shape=(None,) dtype=float32>), 'data:0.614': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_614:0' shape=(None,) dtype=float32>), 'data:0.615': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_615:0' shape=(None,) dtype=float32>), 'data:0.616': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_616:0' shape=(None,) dtype=float32>), 'data:0.617': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_617:0' shape=(None,) dtype=float32>), 'data:0.618': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_618:0' shape=(None,) dtype=float32>), 'data:0.619': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_619:0' shape=(None,) dtype=float32>), 'data:0.620': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_620:0' shape=(None,) dtype=float32>), 'data:0.621': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_621:0' shape=(None,) dtype=float32>), 'data:0.622': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_622:0' shape=(None,) dtype=float32>), 'data:0.623': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_623:0' shape=(None,) dtype=float32>), 'data:0.624': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_624:0' shape=(None,) dtype=float32>), 'data:0.625': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_625:0' shape=(None,) dtype=float32>), 'data:0.626': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_626:0' shape=(None,) dtype=float32>), 'data:0.627': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_627:0' shape=(None,) dtype=float32>), 'data:0.628': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_628:0' shape=(None,) dtype=float32>), 'data:0.629': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_629:0' shape=(None,) dtype=float32>), 'data:0.630': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_630:0' shape=(None,) dtype=float32>), 'data:0.631': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_631:0' shape=(None,) dtype=float32>), 'data:0.632': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_632:0' shape=(None,) dtype=float32>), 'data:0.633': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_633:0' shape=(None,) dtype=float32>), 'data:0.634': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_634:0' shape=(None,) dtype=float32>), 'data:0.635': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_635:0' shape=(None,) dtype=float32>), 'data:0.636': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_636:0' shape=(None,) dtype=float32>), 'data:0.637': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_637:0' shape=(None,) dtype=float32>), 'data:0.638': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_638:0' shape=(None,) dtype=float32>), 'data:0.639': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_639:0' shape=(None,) dtype=float32>), 'data:0.640': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_640:0' shape=(None,) dtype=float32>), 'data:0.641': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_641:0' shape=(None,) dtype=float32>), 'data:0.642': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_642:0' shape=(None,) dtype=float32>), 'data:0.643': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_643:0' shape=(None,) dtype=float32>), 'data:0.644': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_644:0' shape=(None,) dtype=float32>), 'data:0.645': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_645:0' shape=(None,) dtype=float32>), 'data:0.646': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_646:0' shape=(None,) dtype=float32>), 'data:0.647': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_647:0' shape=(None,) dtype=float32>), 'data:0.648': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_648:0' shape=(None,) dtype=float32>), 'data:0.649': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_649:0' shape=(None,) dtype=float32>), 'data:0.650': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_650:0' shape=(None,) dtype=float32>), 'data:0.651': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_651:0' shape=(None,) dtype=float32>), 'data:0.652': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_652:0' shape=(None,) dtype=float32>), 'data:0.653': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_653:0' shape=(None,) dtype=float32>), 'data:0.654': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_654:0' shape=(None,) dtype=float32>), 'data:0.655': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_655:0' shape=(None,) dtype=float32>), 'data:0.656': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_656:0' shape=(None,) dtype=float32>), 'data:0.657': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_657:0' shape=(None,) dtype=float32>), 'data:0.658': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_658:0' shape=(None,) dtype=float32>), 'data:0.659': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_659:0' shape=(None,) dtype=float32>), 'data:0.660': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_660:0' shape=(None,) dtype=float32>), 'data:0.661': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_661:0' shape=(None,) dtype=float32>), 'data:0.662': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_662:0' shape=(None,) dtype=float32>), 'data:0.663': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_663:0' shape=(None,) dtype=float32>), 'data:0.664': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_664:0' shape=(None,) dtype=float32>), 'data:0.665': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_665:0' shape=(None,) dtype=float32>), 'data:0.666': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_666:0' shape=(None,) dtype=float32>), 'data:0.667': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_667:0' shape=(None,) dtype=float32>), 'data:0.668': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_668:0' shape=(None,) dtype=float32>), 'data:0.669': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_669:0' shape=(None,) dtype=float32>), 'data:0.670': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_670:0' shape=(None,) dtype=float32>), 'data:0.671': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_671:0' shape=(None,) dtype=float32>), 'data:0.672': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_672:0' shape=(None,) dtype=float32>), 'data:0.673': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_673:0' shape=(None,) dtype=float32>), 'data:0.674': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_674:0' shape=(None,) dtype=float32>), 'data:0.675': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_675:0' shape=(None,) dtype=float32>), 'data:0.676': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_676:0' shape=(None,) dtype=float32>), 'data:0.677': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_677:0' shape=(None,) dtype=float32>), 'data:0.678': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_678:0' shape=(None,) dtype=float32>), 'data:0.679': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_679:0' shape=(None,) dtype=float32>), 'data:0.680': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_680:0' shape=(None,) dtype=float32>), 'data:0.681': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_681:0' shape=(None,) dtype=float32>), 'data:0.682': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_682:0' shape=(None,) dtype=float32>), 'data:0.683': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_683:0' shape=(None,) dtype=float32>), 'data:0.684': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_684:0' shape=(None,) dtype=float32>), 'data:0.685': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_685:0' shape=(None,) dtype=float32>), 'data:0.686': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_686:0' shape=(None,) dtype=float32>), 'data:0.687': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_687:0' shape=(None,) dtype=float32>), 'data:0.688': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_688:0' shape=(None,) dtype=float32>), 'data:0.689': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_689:0' shape=(None,) dtype=float32>), 'data:0.690': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_690:0' shape=(None,) dtype=float32>), 'data:0.691': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_691:0' shape=(None,) dtype=float32>), 'data:0.692': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_692:0' shape=(None,) dtype=float32>), 'data:0.693': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_693:0' shape=(None,) dtype=float32>), 'data:0.694': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_694:0' shape=(None,) dtype=float32>), 'data:0.695': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_695:0' shape=(None,) dtype=float32>), 'data:0.696': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_696:0' shape=(None,) dtype=float32>), 'data:0.697': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_697:0' shape=(None,) dtype=float32>), 'data:0.698': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_698:0' shape=(None,) dtype=float32>), 'data:0.699': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_699:0' shape=(None,) dtype=float32>), 'data:0.700': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_700:0' shape=(None,) dtype=float32>), 'data:0.701': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_701:0' shape=(None,) dtype=float32>), 'data:0.702': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_702:0' shape=(None,) dtype=float32>), 'data:0.703': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_703:0' shape=(None,) dtype=float32>), 'data:0.704': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_704:0' shape=(None,) dtype=float32>), 'data:0.705': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_705:0' shape=(None,) dtype=float32>), 'data:0.706': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_706:0' shape=(None,) dtype=float32>), 'data:0.707': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_707:0' shape=(None,) dtype=float32>), 'data:0.708': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_708:0' shape=(None,) dtype=float32>), 'data:0.709': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_709:0' shape=(None,) dtype=float32>), 'data:0.710': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_710:0' shape=(None,) dtype=float32>), 'data:0.711': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_711:0' shape=(None,) dtype=float32>), 'data:0.712': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_712:0' shape=(None,) dtype=float32>), 'data:0.713': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_713:0' shape=(None,) dtype=float32>), 'data:0.714': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_714:0' shape=(None,) dtype=float32>), 'data:0.715': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_715:0' shape=(None,) dtype=float32>), 'data:0.716': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_716:0' shape=(None,) dtype=float32>), 'data:0.717': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_717:0' shape=(None,) dtype=float32>), 'data:0.718': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_718:0' shape=(None,) dtype=float32>), 'data:0.719': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_719:0' shape=(None,) dtype=float32>), 'data:0.720': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_720:0' shape=(None,) dtype=float32>), 'data:0.721': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_721:0' shape=(None,) dtype=float32>), 'data:0.722': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_722:0' shape=(None,) dtype=float32>), 'data:0.723': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_723:0' shape=(None,) dtype=float32>), 'data:0.724': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_724:0' shape=(None,) dtype=float32>), 'data:0.725': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_725:0' shape=(None,) dtype=float32>), 'data:0.726': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_726:0' shape=(None,) dtype=float32>), 'data:0.727': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_727:0' shape=(None,) dtype=float32>), 'data:0.728': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_728:0' shape=(None,) dtype=float32>), 'data:0.729': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_729:0' shape=(None,) dtype=float32>), 'data:0.730': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_730:0' shape=(None,) dtype=float32>), 'data:0.731': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_731:0' shape=(None,) dtype=float32>), 'data:0.732': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_732:0' shape=(None,) dtype=float32>), 'data:0.733': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_733:0' shape=(None,) dtype=float32>), 'data:0.734': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_734:0' shape=(None,) dtype=float32>), 'data:0.735': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_735:0' shape=(None,) dtype=float32>), 'data:0.736': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_736:0' shape=(None,) dtype=float32>), 'data:0.737': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_737:0' shape=(None,) dtype=float32>), 'data:0.738': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_738:0' shape=(None,) dtype=float32>), 'data:0.739': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_739:0' shape=(None,) dtype=float32>), 'data:0.740': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_740:0' shape=(None,) dtype=float32>), 'data:0.741': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_741:0' shape=(None,) dtype=float32>), 'data:0.742': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_742:0' shape=(None,) dtype=float32>), 'data:0.743': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_743:0' shape=(None,) dtype=float32>), 'data:0.744': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_744:0' shape=(None,) dtype=float32>), 'data:0.745': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_745:0' shape=(None,) dtype=float32>), 'data:0.746': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_746:0' shape=(None,) dtype=float32>), 'data:0.747': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_747:0' shape=(None,) dtype=float32>), 'data:0.748': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_748:0' shape=(None,) dtype=float32>), 'data:0.749': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_749:0' shape=(None,) dtype=float32>), 'data:0.750': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_750:0' shape=(None,) dtype=float32>), 'data:0.751': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_751:0' shape=(None,) dtype=float32>), 'data:0.752': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_752:0' shape=(None,) dtype=float32>), 'data:0.753': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_753:0' shape=(None,) dtype=float32>), 'data:0.754': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_754:0' shape=(None,) dtype=float32>), 'data:0.755': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_755:0' shape=(None,) dtype=float32>), 'data:0.756': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_756:0' shape=(None,) dtype=float32>), 'data:0.757': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_757:0' shape=(None,) dtype=float32>), 'data:0.758': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_758:0' shape=(None,) dtype=float32>), 'data:0.759': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_759:0' shape=(None,) dtype=float32>), 'data:0.760': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_760:0' shape=(None,) dtype=float32>), 'data:0.761': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_761:0' shape=(None,) dtype=float32>), 'data:0.762': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_762:0' shape=(None,) dtype=float32>), 'data:0.763': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_763:0' shape=(None,) dtype=float32>), 'data:0.764': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_764:0' shape=(None,) dtype=float32>), 'data:0.765': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_765:0' shape=(None,) dtype=float32>), 'data:0.766': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_766:0' shape=(None,) dtype=float32>), 'data:0.767': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_767:0' shape=(None,) dtype=float32>)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 13:42:16.208404: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:05.062708. Found 77085 examples.\n",
      "Training model...\n",
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 23-05-23 13:42:17.1717 EEST kernel.cc:773] Start Yggdrasil model training\n",
      "[INFO 23-05-23 13:42:17.1717 EEST kernel.cc:774] Collect training examples\n",
      "[INFO 23-05-23 13:42:17.1718 EEST kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: NUMERICAL\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 23-05-23 13:42:17.1742 EEST kernel.cc:393] Number of batches: 8\n",
      "[INFO 23-05-23 13:42:17.1742 EEST kernel.cc:394] Number of examples: 77085\n",
      "[INFO 23-05-23 13:42:17.6136 EEST kernel.cc:794] Training dataset:\n",
      "Number of records: 77085\n",
      "Number of columns: 769\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 769 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 769 (100%)\n",
      "\t0: \"__LABEL\" NUMERICAL mean:23.7603 min:13.2766 max:29.5874 sd:2.05542\n",
      "\t1: \"data:0.0\" NUMERICAL mean:-0.142956 min:-2.33358 max:2.40065 sd:0.559246\n",
      "\t2: \"data:0.1\" NUMERICAL mean:-0.236279 min:-2.80781 max:2.51872 sd:0.554726\n",
      "\t3: \"data:0.10\" NUMERICAL mean:-0.762071 min:-4.13514 max:2.20492 sd:0.707709\n",
      "\t4: \"data:0.100\" NUMERICAL mean:0.383945 min:-2.42812 max:3.47129 sd:0.710287\n",
      "\t5: \"data:0.101\" NUMERICAL mean:-1.15763 min:-3.69038 max:1.69148 sd:0.683089\n",
      "\t6: \"data:0.102\" NUMERICAL mean:-0.136945 min:-2.92761 max:2.64169 sd:0.611423\n",
      "\t7: \"data:0.103\" NUMERICAL mean:-1.00964 min:-4.0753 max:1.97537 sd:0.74888\n",
      "\t8: \"data:0.104\" NUMERICAL mean:0.0399301 min:-3.26401 max:2.67798 sd:0.602807\n",
      "\t9: \"data:0.105\" NUMERICAL mean:0.147392 min:-3.20317 max:3.37212 sd:0.795298\n",
      "\t10: \"data:0.106\" NUMERICAL mean:0.465 min:-2.26834 max:3.87742 sd:0.732441\n",
      "\t11: \"data:0.107\" NUMERICAL mean:0.0639645 min:-3.19888 max:2.68239 sd:0.661994\n",
      "\t12: \"data:0.108\" NUMERICAL mean:-0.381666 min:-2.78784 max:2.24227 sd:0.586575\n",
      "\t13: \"data:0.109\" NUMERICAL mean:-0.239717 min:-3.11921 max:2.56272 sd:0.648757\n",
      "\t14: \"data:0.11\" NUMERICAL mean:-0.962002 min:-3.32049 max:1.76802 sd:0.576948\n",
      "\t15: \"data:0.110\" NUMERICAL mean:0.404003 min:-2.38033 max:3.04958 sd:0.597634\n",
      "\t16: \"data:0.111\" NUMERICAL mean:-0.0760698 min:-3.93231 max:3.23036 sd:0.843203\n",
      "\t17: \"data:0.112\" NUMERICAL mean:-0.04022 min:-2.51871 max:2.52785 sd:0.555963\n",
      "\t18: \"data:0.113\" NUMERICAL mean:-0.431625 min:-3.12761 max:2.70115 sd:0.668454\n",
      "\t19: \"data:0.114\" NUMERICAL mean:0.563665 min:-2.12262 max:3.07522 sd:0.581155\n",
      "\t20: \"data:0.115\" NUMERICAL mean:-0.385152 min:-3.37366 max:2.29076 sd:0.631535\n",
      "\t21: \"data:0.116\" NUMERICAL mean:-0.26167 min:-3.13412 max:3.01138 sd:0.697137\n",
      "\t22: \"data:0.117\" NUMERICAL mean:0.519676 min:-2.05669 max:3.06416 sd:0.619057\n",
      "\t23: \"data:0.118\" NUMERICAL mean:0.1441 min:-2.58647 max:3.23997 sd:0.679302\n",
      "\t24: \"data:0.119\" NUMERICAL mean:0.479334 min:-2.79671 max:3.18061 sd:0.716827\n",
      "\t25: \"data:0.12\" NUMERICAL mean:-0.0908121 min:-2.89588 max:2.60785 sd:0.646594\n",
      "\t26: \"data:0.120\" NUMERICAL mean:-0.632618 min:-2.93 max:1.8238 sd:0.58325\n",
      "\t27: \"data:0.121\" NUMERICAL mean:0.223349 min:-2.31065 max:2.87386 sd:0.594629\n",
      "\t28: \"data:0.122\" NUMERICAL mean:1.18169 min:-2.01905 max:4.31789 sd:0.794126\n",
      "\t29: \"data:0.123\" NUMERICAL mean:0.535227 min:-1.98403 max:3.41023 sd:0.629307\n",
      "\t30: \"data:0.124\" NUMERICAL mean:0.231942 min:-2.50412 max:2.77929 sd:0.577877\n",
      "\t31: \"data:0.125\" NUMERICAL mean:-0.247208 min:-2.88836 max:2.35019 sd:0.616237\n",
      "\t32: \"data:0.126\" NUMERICAL mean:-0.645983 min:-3.18353 max:2.21796 sd:0.603924\n",
      "\t33: \"data:0.127\" NUMERICAL mean:0.412577 min:-2.78668 max:3.06719 sd:0.635696\n",
      "\t34: \"data:0.128\" NUMERICAL mean:-0.619105 min:-3.08944 max:2.00634 sd:0.660232\n",
      "\t35: \"data:0.129\" NUMERICAL mean:0.166519 min:-2.1247 max:2.68728 sd:0.630992\n",
      "\t36: \"data:0.13\" NUMERICAL mean:0.446523 min:-1.89655 max:2.82615 sd:0.567904\n",
      "\t37: \"data:0.130\" NUMERICAL mean:-0.295992 min:-2.72537 max:2.42858 sd:0.576118\n",
      "\t38: \"data:0.131\" NUMERICAL mean:-0.955439 min:-3.85602 max:1.90595 sd:0.599846\n",
      "\t39: \"data:0.132\" NUMERICAL mean:0.859393 min:-1.91399 max:3.4609 sd:0.588429\n",
      "\t40: \"data:0.133\" NUMERICAL mean:0.333356 min:-2.15471 max:2.70318 sd:0.569647\n",
      "\t41: \"data:0.134\" NUMERICAL mean:-0.312935 min:-2.61266 max:2.00313 sd:0.534595\n",
      "\t42: \"data:0.135\" NUMERICAL mean:-0.0446907 min:-2.61098 max:2.62706 sd:0.698623\n",
      "\t43: \"data:0.136\" NUMERICAL mean:-0.14591 min:-2.40052 max:2.232 sd:0.541622\n",
      "\t44: \"data:0.137\" NUMERICAL mean:0.235285 min:-2.70998 max:2.87497 sd:0.609624\n",
      "\t45: \"data:0.138\" NUMERICAL mean:-0.508054 min:-2.89498 max:2.36387 sd:0.623899\n",
      "\t46: \"data:0.139\" NUMERICAL mean:0.205423 min:-2.51681 max:2.50491 sd:0.608713\n",
      "\t47: \"data:0.14\" NUMERICAL mean:-0.313201 min:-3.55861 max:2.31609 sd:0.611036\n",
      "\t48: \"data:0.140\" NUMERICAL mean:-0.110129 min:-2.44677 max:2.55736 sd:0.637457\n",
      "\t49: \"data:0.141\" NUMERICAL mean:-0.212819 min:-2.90888 max:2.68672 sd:0.691748\n",
      "\t50: \"data:0.142\" NUMERICAL mean:-0.887996 min:-3.49856 max:2.71347 sd:0.697063\n",
      "\t51: \"data:0.143\" NUMERICAL mean:2.14593 min:-1.14116 max:12.2822 sd:2.48533\n",
      "\t52: \"data:0.144\" NUMERICAL mean:0.579891 min:-1.87879 max:3.16421 sd:0.617316\n",
      "\t53: \"data:0.145\" NUMERICAL mean:-0.4766 min:-2.88539 max:2.08576 sd:0.546074\n",
      "\t54: \"data:0.146\" NUMERICAL mean:-0.0413471 min:-2.50806 max:2.69388 sd:0.609607\n",
      "\t55: \"data:0.147\" NUMERICAL mean:0.210077 min:-2.18968 max:2.49887 sd:0.559231\n",
      "\t56: \"data:0.148\" NUMERICAL mean:-0.0477741 min:-3.06184 max:2.83452 sd:0.649101\n",
      "\t57: \"data:0.149\" NUMERICAL mean:0.965776 min:-2.28756 max:3.65871 sd:0.836911\n",
      "\t58: \"data:0.15\" NUMERICAL mean:-0.23728 min:-2.85116 max:2.48495 sd:0.611915\n",
      "\t59: \"data:0.150\" NUMERICAL mean:0.751792 min:-2.20969 max:3.96663 sd:0.683789\n",
      "\t60: \"data:0.151\" NUMERICAL mean:0.658961 min:-1.79925 max:2.87782 sd:0.555181\n",
      "\t61: \"data:0.152\" NUMERICAL mean:0.404217 min:-1.79153 max:2.86695 sd:0.558104\n",
      "\t62: \"data:0.153\" NUMERICAL mean:0.333527 min:-2.01045 max:2.81784 sd:0.570182\n",
      "\t63: \"data:0.154\" NUMERICAL mean:0.476845 min:-2.2704 max:2.7615 sd:0.558212\n",
      "\t64: \"data:0.155\" NUMERICAL mean:0.336044 min:-2.1276 max:3.11812 sd:0.551745\n",
      "\t65: \"data:0.156\" NUMERICAL mean:-0.558557 min:-3.26829 max:2.19354 sd:0.600772\n",
      "\t66: \"data:0.157\" NUMERICAL mean:-0.020826 min:-2.70516 max:2.32984 sd:0.57839\n",
      "\t67: \"data:0.158\" NUMERICAL mean:-0.187816 min:-2.76839 max:2.39177 sd:0.535102\n",
      "\t68: \"data:0.159\" NUMERICAL mean:-8.09859 min:-13.5272 max:1.53864 sd:2.01996\n",
      "\t69: \"data:0.16\" NUMERICAL mean:-0.325128 min:-2.76886 max:2.43085 sd:0.66496\n",
      "\t70: \"data:0.160\" NUMERICAL mean:0.278931 min:-2.75877 max:3.33724 sd:0.757966\n",
      "\t71: \"data:0.161\" NUMERICAL mean:0.808313 min:-1.50859 max:3.20628 sd:0.545076\n",
      "\t72: \"data:0.162\" NUMERICAL mean:0.0306194 min:-2.91093 max:2.48693 sd:0.623498\n",
      "\t73: \"data:0.163\" NUMERICAL mean:-0.667536 min:-3.00718 max:1.74498 sd:0.614103\n",
      "\t74: \"data:0.164\" NUMERICAL mean:0.263625 min:-2.5137 max:3.13661 sd:0.737459\n",
      "\t75: \"data:0.165\" NUMERICAL mean:-0.476746 min:-2.93663 max:2.18331 sd:0.5884\n",
      "\t76: \"data:0.166\" NUMERICAL mean:-0.228651 min:-3.0471 max:2.62625 sd:0.610075\n",
      "\t77: \"data:0.167\" NUMERICAL mean:0.0484453 min:-2.44993 max:2.61619 sd:0.586543\n",
      "\t78: \"data:0.168\" NUMERICAL mean:-0.445196 min:-2.70778 max:1.94133 sd:0.544554\n",
      "\t79: \"data:0.169\" NUMERICAL mean:-0.502623 min:-3.12469 max:2.47377 sd:0.679312\n",
      "\t80: \"data:0.17\" NUMERICAL mean:-0.3058 min:-3.33138 max:2.7054 sd:0.659278\n",
      "\t81: \"data:0.170\" NUMERICAL mean:-0.0207232 min:-2.83112 max:2.48182 sd:0.585367\n",
      "\t82: \"data:0.171\" NUMERICAL mean:0.22515 min:-2.6133 max:2.56713 sd:0.561395\n",
      "\t83: \"data:0.172\" NUMERICAL mean:0.000976336 min:-2.88455 max:2.89611 sd:0.744732\n",
      "\t84: \"data:0.173\" NUMERICAL mean:-0.334154 min:-3.11439 max:2.56726 sd:0.667326\n",
      "\t85: \"data:0.174\" NUMERICAL mean:0.30058 min:-2.23836 max:2.93971 sd:0.572199\n",
      "\t86: \"data:0.175\" NUMERICAL mean:-0.442257 min:-3.06531 max:2.49952 sd:0.622533\n",
      "\t87: \"data:0.176\" NUMERICAL mean:1.60586 min:-1.50397 max:4.10973 sd:0.717612\n",
      "\t88: \"data:0.177\" NUMERICAL mean:-1.22929 min:-6.97663 max:4.18933 sd:1.50871\n",
      "\t89: \"data:0.178\" NUMERICAL mean:0.15934 min:-2.23807 max:2.97923 sd:0.627162\n",
      "\t90: \"data:0.179\" NUMERICAL mean:0.561854 min:-2.50866 max:3.23995 sd:0.806918\n",
      "\t91: \"data:0.18\" NUMERICAL mean:-0.131548 min:-2.77108 max:2.4925 sd:0.609026\n",
      "\t92: \"data:0.180\" NUMERICAL mean:0.539574 min:-2.67895 max:3.46873 sd:0.659221\n",
      "\t93: \"data:0.181\" NUMERICAL mean:0.694615 min:-2.72321 max:3.64412 sd:0.742585\n",
      "\t94: \"data:0.182\" NUMERICAL mean:-0.204137 min:-2.72035 max:2.46102 sd:0.62063\n",
      "\t95: \"data:0.183\" NUMERICAL mean:0.797812 min:-1.72187 max:3.40359 sd:0.610081\n",
      "\t96: \"data:0.184\" NUMERICAL mean:-0.36394 min:-3.47151 max:2.81737 sd:0.722135\n",
      "\t97: \"data:0.185\" NUMERICAL mean:0.248261 min:-2.48221 max:2.66746 sd:0.58643\n",
      "\t98: \"data:0.186\" NUMERICAL mean:-1.0253 min:-3.78841 max:1.52088 sd:0.646714\n",
      "\t99: \"data:0.187\" NUMERICAL mean:0.184553 min:-2.33289 max:2.92389 sd:0.701816\n",
      "\t100: \"data:0.188\" NUMERICAL mean:0.273638 min:-2.50777 max:3.24133 sd:0.708179\n",
      "\t101: \"data:0.189\" NUMERICAL mean:1.14801 min:-2.21589 max:3.93121 sd:0.730055\n",
      "\t102: \"data:0.19\" NUMERICAL mean:-0.309565 min:-3.2668 max:2.33317 sd:0.589682\n",
      "\t103: \"data:0.190\" NUMERICAL mean:-0.57164 min:-3.20988 max:2.15685 sd:0.639833\n",
      "\t104: \"data:0.191\" NUMERICAL mean:-0.617642 min:-3.26298 max:1.9356 sd:0.640392\n",
      "\t105: \"data:0.192\" NUMERICAL mean:-0.536094 min:-3.52352 max:2.09023 sd:0.724675\n",
      "\t106: \"data:0.193\" NUMERICAL mean:0.325289 min:-3.05761 max:4.01579 sd:0.87828\n",
      "\t107: \"data:0.194\" NUMERICAL mean:-0.0285266 min:-2.91272 max:2.35069 sd:0.617171\n",
      "\t108: \"data:0.195\" NUMERICAL mean:-0.573317 min:-3.41037 max:2.26882 sd:0.693819\n",
      "\t109: \"data:0.196\" NUMERICAL mean:-0.0829718 min:-2.49032 max:2.61391 sd:0.587724\n",
      "\t110: \"data:0.197\" NUMERICAL mean:-0.00308293 min:-2.67432 max:2.69959 sd:0.608535\n",
      "\t111: \"data:0.198\" NUMERICAL mean:-0.326308 min:-3.33754 max:2.89933 sd:0.740063\n",
      "\t112: \"data:0.199\" NUMERICAL mean:-0.0399211 min:-3.08567 max:3.0425 sd:0.66607\n",
      "\t113: \"data:0.2\" NUMERICAL mean:0.608931 min:-2.18349 max:2.89703 sd:0.568905\n",
      "\t114: \"data:0.20\" NUMERICAL mean:0.199573 min:-2.608 max:2.77651 sd:0.589164\n",
      "\t115: \"data:0.200\" NUMERICAL mean:0.0998146 min:-3.27722 max:2.92318 sd:0.666717\n",
      "\t116: \"data:0.201\" NUMERICAL mean:0.158119 min:-2.35306 max:2.64114 sd:0.549223\n",
      "\t117: \"data:0.202\" NUMERICAL mean:-0.433241 min:-3.12242 max:2.00747 sd:0.629665\n",
      "\t118: \"data:0.203\" NUMERICAL mean:-0.729664 min:-3.45977 max:1.73008 sd:0.608496\n",
      "\t119: \"data:0.204\" NUMERICAL mean:0.562983 min:-2.1364 max:3.00388 sd:0.625668\n",
      "\t120: \"data:0.205\" NUMERICAL mean:0.557428 min:-2.0708 max:2.90156 sd:0.569318\n",
      "\t121: \"data:0.206\" NUMERICAL mean:-0.906529 min:-3.82397 max:1.89575 sd:0.644557\n",
      "\t122: \"data:0.207\" NUMERICAL mean:0.412142 min:-2.51966 max:2.84491 sd:0.574392\n",
      "\t123: \"data:0.208\" NUMERICAL mean:0.143895 min:-2.64113 max:2.83134 sd:0.680798\n",
      "\t124: \"data:0.209\" NUMERICAL mean:-0.581106 min:-3.47886 max:2.01251 sd:0.581454\n",
      "\t125: \"data:0.21\" NUMERICAL mean:-0.189406 min:-2.8138 max:2.81977 sd:0.575003\n",
      "\t126: \"data:0.210\" NUMERICAL mean:-0.359378 min:-3.1941 max:2.13422 sd:0.645911\n",
      "\t127: \"data:0.211\" NUMERICAL mean:-0.0998249 min:-2.93464 max:2.26242 sd:0.572115\n",
      "\t128: \"data:0.212\" NUMERICAL mean:-0.597484 min:-3.08366 max:1.9048 sd:0.570065\n",
      "\t129: \"data:0.213\" NUMERICAL mean:-0.150057 min:-2.48547 max:2.01045 sd:0.574876\n",
      "\t130: \"data:0.214\" NUMERICAL mean:-0.132186 min:-2.97372 max:2.61247 sd:0.640055\n",
      "\t131: \"data:0.215\" NUMERICAL mean:-0.645573 min:-3.18225 max:2.35478 sd:0.601594\n",
      "\t132: \"data:0.216\" NUMERICAL mean:-0.2908 min:-2.99083 max:2.40542 sd:0.589059\n",
      "\t133: \"data:0.217\" NUMERICAL mean:1.03296 min:-1.50214 max:3.49533 sd:0.624014\n",
      "\t134: \"data:0.218\" NUMERICAL mean:0.816205 min:-2.14681 max:3.704 sd:0.699936\n",
      "\t135: \"data:0.219\" NUMERICAL mean:-0.382769 min:-3.63655 max:2.18724 sd:0.544502\n",
      "\t136: \"data:0.22\" NUMERICAL mean:-0.664332 min:-3.38586 max:2.44768 sd:0.591539\n",
      "\t137: \"data:0.220\" NUMERICAL mean:-0.672662 min:-3.97846 max:2.02408 sd:0.773525\n",
      "\t138: \"data:0.221\" NUMERICAL mean:-0.0748796 min:-3.48186 max:2.79008 sd:0.63697\n",
      "\t139: \"data:0.222\" NUMERICAL mean:-0.182787 min:-2.86461 max:2.14598 sd:0.551197\n",
      "\t140: \"data:0.223\" NUMERICAL mean:0.352123 min:-2.22788 max:3.05215 sd:0.632944\n",
      "\t141: \"data:0.224\" NUMERICAL mean:0.367349 min:-2.09548 max:2.82687 sd:0.583562\n",
      "\t142: \"data:0.225\" NUMERICAL mean:-0.0679021 min:-2.65276 max:2.44671 sd:0.60054\n",
      "\t143: \"data:0.226\" NUMERICAL mean:0.597778 min:-1.74141 max:2.95672 sd:0.591174\n",
      "\t144: \"data:0.227\" NUMERICAL mean:0.711045 min:-1.6352 max:3.13203 sd:0.557336\n",
      "\t145: \"data:0.228\" NUMERICAL mean:-1.4488 min:-4.14612 max:1.37123 sd:0.657885\n",
      "\t146: \"data:0.229\" NUMERICAL mean:0.903156 min:-1.59786 max:3.60706 sd:0.621184\n",
      "\t147: \"data:0.23\" NUMERICAL mean:-0.687711 min:-3.18935 max:2.71501 sd:0.715742\n",
      "\t148: \"data:0.230\" NUMERICAL mean:0.361565 min:-2.10834 max:2.68782 sd:0.591878\n",
      "\t149: \"data:0.231\" NUMERICAL mean:-0.167554 min:-2.65196 max:2.34775 sd:0.568518\n",
      "\t150: \"data:0.232\" NUMERICAL mean:0.165853 min:-2.42515 max:2.5564 sd:0.653942\n",
      "\t151: \"data:0.233\" NUMERICAL mean:-0.586152 min:-3.14617 max:2.0645 sd:0.572248\n",
      "\t152: \"data:0.234\" NUMERICAL mean:0.746742 min:-2.14494 max:3.46078 sd:0.617718\n",
      "\t153: \"data:0.235\" NUMERICAL mean:0.189669 min:-2.94638 max:3.20742 sd:0.767164\n",
      "\t154: \"data:0.236\" NUMERICAL mean:-0.66045 min:-3.40366 max:2.20748 sd:0.764127\n",
      "\t155: \"data:0.237\" NUMERICAL mean:-0.468727 min:-2.9432 max:2.53884 sd:0.632306\n",
      "\t156: \"data:0.238\" NUMERICAL mean:0.69627 min:-2.29872 max:3.33965 sd:0.773367\n",
      "\t157: \"data:0.239\" NUMERICAL mean:0.632923 min:-2.21343 max:3.47469 sd:0.611027\n",
      "\t158: \"data:0.24\" NUMERICAL mean:-0.916232 min:-3.30606 max:1.68065 sd:0.524486\n",
      "\t159: \"data:0.240\" NUMERICAL mean:-0.466262 min:-2.93057 max:2.53733 sd:0.56431\n",
      "\t160: \"data:0.241\" NUMERICAL mean:1.12071 min:-2.22948 max:3.79504 sd:0.745618\n",
      "\t161: \"data:0.242\" NUMERICAL mean:-0.588681 min:-3.19167 max:2.36276 sd:0.638772\n",
      "\t162: \"data:0.243\" NUMERICAL mean:-0.00275477 min:-2.33403 max:3.18018 sd:0.712088\n",
      "\t163: \"data:0.244\" NUMERICAL mean:0.363105 min:-2.12565 max:3.23165 sd:0.650547\n",
      "\t164: \"data:0.245\" NUMERICAL mean:-0.396381 min:-2.85726 max:2.69895 sd:0.67019\n",
      "\t165: \"data:0.246\" NUMERICAL mean:-0.108573 min:-3.21986 max:2.7662 sd:0.692581\n",
      "\t166: \"data:0.247\" NUMERICAL mean:-0.43783 min:-2.86741 max:2.12347 sd:0.578314\n",
      "\t167: \"data:0.248\" NUMERICAL mean:-0.551602 min:-3.26224 max:2.01504 sd:0.699925\n",
      "\t168: \"data:0.249\" NUMERICAL mean:-0.0307922 min:-2.15537 max:2.43465 sd:0.53216\n",
      "\t169: \"data:0.25\" NUMERICAL mean:0.755797 min:-2.04761 max:3.39279 sd:0.64282\n",
      "\t170: \"data:0.250\" NUMERICAL mean:0.459332 min:-2.16009 max:3.15224 sd:0.603215\n",
      "\t171: \"data:0.251\" NUMERICAL mean:0.759214 min:-2.28748 max:3.39541 sd:0.835125\n",
      "\t172: \"data:0.252\" NUMERICAL mean:-0.566559 min:-3.66959 max:2.19415 sd:0.652447\n",
      "\t173: \"data:0.253\" NUMERICAL mean:0.928121 min:-2.10275 max:3.44837 sd:0.615759\n",
      "\t174: \"data:0.254\" NUMERICAL mean:-0.386423 min:-2.62661 max:2.31271 sd:0.625053\n",
      "\t175: \"data:0.255\" NUMERICAL mean:0.381195 min:-2.88418 max:2.74793 sd:0.593729\n",
      "\t176: \"data:0.256\" NUMERICAL mean:-0.525372 min:-2.98666 max:1.98335 sd:0.569877\n",
      "\t177: \"data:0.257\" NUMERICAL mean:-0.488924 min:-3.23465 max:2.86385 sd:0.653722\n",
      "\t178: \"data:0.258\" NUMERICAL mean:0.438565 min:-2.63166 max:3.17564 sd:0.675059\n",
      "\t179: \"data:0.259\" NUMERICAL mean:0.464888 min:-2.42775 max:2.96093 sd:0.613949\n",
      "\t180: \"data:0.26\" NUMERICAL mean:0.125806 min:-2.76736 max:3.35081 sd:0.802112\n",
      "\t181: \"data:0.260\" NUMERICAL mean:0.0450799 min:-2.31424 max:2.32737 sd:0.531035\n",
      "\t182: \"data:0.261\" NUMERICAL mean:-0.240959 min:-2.77481 max:2.58149 sd:0.637234\n",
      "\t183: \"data:0.262\" NUMERICAL mean:-0.223301 min:-2.93185 max:2.42354 sd:0.648359\n",
      "\t184: \"data:0.263\" NUMERICAL mean:-0.498385 min:-3.81456 max:2.84879 sd:0.744999\n",
      "\t185: \"data:0.264\" NUMERICAL mean:0.357424 min:-2.29206 max:2.85533 sd:0.547579\n",
      "\t186: \"data:0.265\" NUMERICAL mean:0.188193 min:-1.74748 max:2.46043 sd:0.485217\n",
      "\t187: \"data:0.266\" NUMERICAL mean:0.14564 min:-2.53899 max:2.5922 sd:0.564765\n",
      "\t188: \"data:0.267\" NUMERICAL mean:-0.23696 min:-3.0113 max:2.34214 sd:0.629025\n",
      "\t189: \"data:0.268\" NUMERICAL mean:-0.547702 min:-2.76666 max:2.1779 sd:0.585417\n",
      "\t190: \"data:0.269\" NUMERICAL mean:0.496239 min:-2.16013 max:3.10587 sd:0.594334\n",
      "\t191: \"data:0.27\" NUMERICAL mean:-0.0944388 min:-2.52411 max:2.42028 sd:0.550488\n",
      "\t192: \"data:0.270\" NUMERICAL mean:-0.306147 min:-3.3081 max:3.10593 sd:0.850383\n",
      "\t193: \"data:0.271\" NUMERICAL mean:-0.397034 min:-2.90298 max:1.87012 sd:0.555467\n",
      "\t194: \"data:0.272\" NUMERICAL mean:0.11718 min:-2.86307 max:2.67751 sd:0.541574\n",
      "\t195: \"data:0.273\" NUMERICAL mean:0.0704494 min:-2.52895 max:2.3187 sd:0.578058\n",
      "\t196: \"data:0.274\" NUMERICAL mean:0.384553 min:-2.01318 max:3.2931 sd:0.634214\n",
      "\t197: \"data:0.275\" NUMERICAL mean:-0.323254 min:-3.34401 max:2.44229 sd:0.709577\n",
      "\t198: \"data:0.276\" NUMERICAL mean:-0.981035 min:-3.73441 max:1.81389 sd:0.684238\n",
      "\t199: \"data:0.277\" NUMERICAL mean:-0.25354 min:-2.30814 max:2.34905 sd:0.569998\n",
      "\t200: \"data:0.278\" NUMERICAL mean:-0.0440931 min:-2.33837 max:2.59237 sd:0.605457\n",
      "\t201: \"data:0.279\" NUMERICAL mean:0.080681 min:-2.64195 max:2.98843 sd:0.68329\n",
      "\t202: \"data:0.28\" NUMERICAL mean:0.243369 min:-2.82851 max:2.57122 sd:0.608754\n",
      "\t203: \"data:0.280\" NUMERICAL mean:0.559081 min:-2.35068 max:3.36413 sd:0.691896\n",
      "\t204: \"data:0.281\" NUMERICAL mean:-0.0853729 min:-2.71877 max:2.41167 sd:0.61535\n",
      "\t205: \"data:0.282\" NUMERICAL mean:0.514955 min:-2.68183 max:3.24095 sd:0.680051\n",
      "\t206: \"data:0.283\" NUMERICAL mean:-0.195592 min:-2.48686 max:2.12766 sd:0.587035\n",
      "\t207: \"data:0.284\" NUMERICAL mean:-0.220427 min:-3.04255 max:2.28106 sd:0.627148\n",
      "\t208: \"data:0.285\" NUMERICAL mean:0.282418 min:-2.06367 max:2.63135 sd:0.589652\n",
      "\t209: \"data:0.286\" NUMERICAL mean:-0.621886 min:-3.34507 max:1.56167 sd:0.540106\n",
      "\t210: \"data:0.287\" NUMERICAL mean:-0.474594 min:-3.23881 max:2.60625 sd:0.640993\n",
      "\t211: \"data:0.288\" NUMERICAL mean:-0.182899 min:-2.87932 max:2.41857 sd:0.592056\n",
      "\t212: \"data:0.289\" NUMERICAL mean:0.0886784 min:-2.83798 max:2.60503 sd:0.588036\n",
      "\t213: \"data:0.29\" NUMERICAL mean:-0.63996 min:-3.20058 max:1.8263 sd:0.587304\n",
      "\t214: \"data:0.290\" NUMERICAL mean:0.111429 min:-2.41862 max:2.4739 sd:0.566623\n",
      "\t215: \"data:0.291\" NUMERICAL mean:0.33694 min:-1.90217 max:2.81224 sd:0.584195\n",
      "\t216: \"data:0.292\" NUMERICAL mean:0.0434988 min:-2.63543 max:2.455 sd:0.607381\n",
      "\t217: \"data:0.293\" NUMERICAL mean:0.0533183 min:-2.475 max:2.7989 sd:0.583945\n",
      "\t218: \"data:0.294\" NUMERICAL mean:-0.243003 min:-2.7602 max:2.37796 sd:0.598818\n",
      "\t219: \"data:0.295\" NUMERICAL mean:-0.117141 min:-2.64196 max:2.36399 sd:0.581825\n",
      "\t220: \"data:0.296\" NUMERICAL mean:-0.0777126 min:-2.55017 max:2.66844 sd:0.611065\n",
      "\t221: \"data:0.297\" NUMERICAL mean:0.00260291 min:-2.81861 max:2.61982 sd:0.583383\n",
      "\t222: \"data:0.298\" NUMERICAL mean:-1.17879 min:-3.46208 max:1.79333 sd:0.607978\n",
      "\t223: \"data:0.299\" NUMERICAL mean:-0.0197033 min:-2.444 max:2.72908 sd:0.571674\n",
      "\t224: \"data:0.3\" NUMERICAL mean:0.441979 min:-2.13159 max:2.9745 sd:0.600481\n",
      "\t225: \"data:0.30\" NUMERICAL mean:0.932037 min:-2.51585 max:3.9174 sd:0.901327\n",
      "\t226: \"data:0.300\" NUMERICAL mean:0.168795 min:-2.2648 max:2.5054 sd:0.50134\n",
      "\t227: \"data:0.301\" NUMERICAL mean:-0.171277 min:-2.32762 max:2.38064 sd:0.571694\n",
      "\t228: \"data:0.302\" NUMERICAL mean:0.695195 min:-2.12611 max:2.8954 sd:0.540378\n",
      "\t229: \"data:0.303\" NUMERICAL mean:0.222139 min:-2.93141 max:3.55501 sd:0.774571\n",
      "\t230: \"data:0.304\" NUMERICAL mean:0.50535 min:-2.11728 max:2.99682 sd:0.591699\n",
      "\t231: \"data:0.305\" NUMERICAL mean:0.725789 min:-1.81598 max:3.46513 sd:0.59719\n",
      "\t232: \"data:0.306\" NUMERICAL mean:-0.510315 min:-2.71924 max:2.17905 sd:0.617325\n",
      "\t233: \"data:0.307\" NUMERICAL mean:0.437291 min:-2.39423 max:3.04178 sd:0.595872\n",
      "\t234: \"data:0.308\" NUMERICAL mean:0.139962 min:-2.89865 max:2.9274 sd:0.681598\n",
      "\t235: \"data:0.309\" NUMERICAL mean:-0.0803403 min:-2.30013 max:2.26461 sd:0.562331\n",
      "\t236: \"data:0.31\" NUMERICAL mean:-0.288388 min:-2.76362 max:2.11429 sd:0.636745\n",
      "\t237: \"data:0.310\" NUMERICAL mean:0.0593395 min:-2.88839 max:2.69882 sd:0.753616\n",
      "\t238: \"data:0.311\" NUMERICAL mean:0.775305 min:-2.01216 max:3.20737 sd:0.596413\n",
      "\t239: \"data:0.312\" NUMERICAL mean:-1.02229 min:-4.1947 max:1.46826 sd:0.679922\n",
      "\t240: \"data:0.313\" NUMERICAL mean:0.270028 min:-2.25598 max:2.98573 sd:0.557686\n",
      "\t241: \"data:0.314\" NUMERICAL mean:-0.629313 min:-3.10143 max:2.00858 sd:0.549066\n",
      "\t242: \"data:0.315\" NUMERICAL mean:0.646038 min:-2.23946 max:3.44365 sd:0.728414\n",
      "\t243: \"data:0.316\" NUMERICAL mean:-0.390378 min:-3.09591 max:2.85649 sd:0.822206\n",
      "\t244: \"data:0.317\" NUMERICAL mean:-0.500514 min:-3.6823 max:2.11195 sd:0.602302\n",
      "\t245: \"data:0.318\" NUMERICAL mean:0.570056 min:-1.93303 max:3.21297 sd:0.603955\n",
      "\t246: \"data:0.319\" NUMERICAL mean:0.315046 min:-2.48049 max:3.08743 sd:0.657662\n",
      "\t247: \"data:0.32\" NUMERICAL mean:0.114095 min:-2.35855 max:2.46831 sd:0.587087\n",
      "\t248: \"data:0.320\" NUMERICAL mean:-0.37497 min:-2.85115 max:2.20278 sd:0.644667\n",
      "\t249: \"data:0.321\" NUMERICAL mean:0.148211 min:-2.29475 max:2.71755 sd:0.598889\n",
      "\t250: \"data:0.322\" NUMERICAL mean:-0.413407 min:-3.0538 max:3.00617 sd:0.656045\n",
      "\t251: \"data:0.323\" NUMERICAL mean:-0.518745 min:-2.88222 max:2.20004 sd:0.606787\n",
      "\t252: \"data:0.324\" NUMERICAL mean:-0.289463 min:-3.07566 max:2.66361 sd:0.690983\n",
      "\t253: \"data:0.325\" NUMERICAL mean:-0.0200627 min:-3.04324 max:2.48275 sd:0.622249\n",
      "\t254: \"data:0.326\" NUMERICAL mean:-0.327611 min:-2.8285 max:2.3194 sd:0.569015\n",
      "\t255: \"data:0.327\" NUMERICAL mean:1.15693 min:-1.70362 max:3.83675 sd:0.668386\n",
      "\t256: \"data:0.328\" NUMERICAL mean:0.237987 min:-2.40997 max:2.73796 sd:0.629039\n",
      "\t257: \"data:0.329\" NUMERICAL mean:0.264475 min:-2.19958 max:2.46307 sd:0.554143\n",
      "\t258: \"data:0.33\" NUMERICAL mean:0.268346 min:-2.53492 max:3.11402 sd:0.613092\n",
      "\t259: \"data:0.330\" NUMERICAL mean:-0.111885 min:-2.59907 max:2.30702 sd:0.5593\n",
      "\t260: \"data:0.331\" NUMERICAL mean:0.3311 min:-2.786 max:2.94738 sd:0.613345\n",
      "\t261: \"data:0.332\" NUMERICAL mean:-0.21539 min:-2.91995 max:2.50965 sd:0.628657\n",
      "\t262: \"data:0.333\" NUMERICAL mean:0.217204 min:-2.37475 max:2.39481 sd:0.549337\n",
      "\t263: \"data:0.334\" NUMERICAL mean:0.0570235 min:-2.33342 max:2.25841 sd:0.533129\n",
      "\t264: \"data:0.335\" NUMERICAL mean:-0.961414 min:-3.61284 max:1.7531 sd:0.640215\n",
      "\t265: \"data:0.336\" NUMERICAL mean:0.449241 min:-2.30384 max:3.25079 sd:0.754539\n",
      "\t266: \"data:0.337\" NUMERICAL mean:-1.32595 min:-3.96128 max:1.38222 sd:0.659709\n",
      "\t267: \"data:0.338\" NUMERICAL mean:0.95532 min:-2.41039 max:3.70079 sd:0.711291\n",
      "\t268: \"data:0.339\" NUMERICAL mean:0.401459 min:-2.13785 max:2.91625 sd:0.560667\n",
      "\t269: \"data:0.34\" NUMERICAL mean:0.0652871 min:-2.4397 max:2.5426 sd:0.554579\n",
      "\t270: \"data:0.340\" NUMERICAL mean:0.211396 min:-2.21687 max:2.91435 sd:0.611819\n",
      "\t271: \"data:0.341\" NUMERICAL mean:0.654075 min:-1.84728 max:3.38006 sd:0.618865\n",
      "\t272: \"data:0.342\" NUMERICAL mean:-0.0807121 min:-2.59204 max:2.14069 sd:0.541782\n",
      "\t273: \"data:0.343\" NUMERICAL mean:0.176935 min:-2.75298 max:2.87131 sd:0.62263\n",
      "\t274: \"data:0.344\" NUMERICAL mean:-0.346495 min:-2.87313 max:2.26138 sd:0.600168\n",
      "\t275: \"data:0.345\" NUMERICAL mean:-0.102918 min:-2.97718 max:2.22267 sd:0.640242\n",
      "\t276: \"data:0.346\" NUMERICAL mean:0.399545 min:-2.29604 max:3.13495 sd:0.629827\n",
      "\t277: \"data:0.347\" NUMERICAL mean:-0.135704 min:-3.03273 max:3.64287 sd:0.72758\n",
      "\t278: \"data:0.348\" NUMERICAL mean:0.792368 min:-2.23764 max:3.43238 sd:0.675039\n",
      "\t279: \"data:0.349\" NUMERICAL mean:0.637829 min:-2.24443 max:3.79558 sd:0.7596\n",
      "\t280: \"data:0.35\" NUMERICAL mean:0.0141665 min:-2.59589 max:2.97942 sd:0.744255\n",
      "\t281: \"data:0.350\" NUMERICAL mean:0.15056 min:-2.23654 max:2.69691 sd:0.576377\n",
      "\t282: \"data:0.351\" NUMERICAL mean:-0.125897 min:-2.45784 max:2.28122 sd:0.565318\n",
      "\t283: \"data:0.352\" NUMERICAL mean:-0.72544 min:-3.12072 max:2.85845 sd:0.586599\n",
      "\t284: \"data:0.353\" NUMERICAL mean:-0.367875 min:-3.11591 max:2.66571 sd:0.639885\n",
      "\t285: \"data:0.354\" NUMERICAL mean:-0.105456 min:-2.95979 max:2.2239 sd:0.696615\n",
      "\t286: \"data:0.355\" NUMERICAL mean:0.813801 min:-1.54217 max:3.37403 sd:0.571553\n",
      "\t287: \"data:0.356\" NUMERICAL mean:-0.0822094 min:-2.61772 max:2.9692 sd:0.593232\n",
      "\t288: \"data:0.357\" NUMERICAL mean:-0.675116 min:-3.6438 max:1.70842 sd:0.624046\n",
      "\t289: \"data:0.358\" NUMERICAL mean:-0.0596346 min:-2.5534 max:2.24856 sd:0.558362\n",
      "\t290: \"data:0.359\" NUMERICAL mean:-0.0953641 min:-2.80827 max:2.08166 sd:0.518288\n",
      "\t291: \"data:0.36\" NUMERICAL mean:-0.46727 min:-2.88643 max:2.05255 sd:0.552235\n",
      "\t292: \"data:0.360\" NUMERICAL mean:0.761678 min:-1.83366 max:3.36497 sd:0.587904\n",
      "\t293: \"data:0.361\" NUMERICAL mean:0.59599 min:-1.71781 max:3.40521 sd:0.550294\n",
      "\t294: \"data:0.362\" NUMERICAL mean:-1.27446 min:-4.02336 max:1.15545 sd:0.638195\n",
      "\t295: \"data:0.363\" NUMERICAL mean:-0.642133 min:-3.32604 max:2.06026 sd:0.640529\n",
      "\t296: \"data:0.364\" NUMERICAL mean:0.312165 min:-2.66887 max:2.78437 sd:0.595313\n",
      "\t297: \"data:0.365\" NUMERICAL mean:1.00355 min:-1.89471 max:3.52139 sd:0.673912\n",
      "\t298: \"data:0.366\" NUMERICAL mean:-0.108291 min:-2.82835 max:2.51306 sd:0.589162\n",
      "\t299: \"data:0.367\" NUMERICAL mean:-0.0862168 min:-3.07265 max:2.46962 sd:0.746864\n",
      "\t300: \"data:0.368\" NUMERICAL mean:-0.412008 min:-3.10167 max:2.56677 sd:0.611154\n",
      "\t301: \"data:0.369\" NUMERICAL mean:0.0524372 min:-2.7809 max:2.72893 sd:0.602\n",
      "\t302: \"data:0.37\" NUMERICAL mean:-0.684529 min:-3.47213 max:3.14684 sd:0.76862\n",
      "\t303: \"data:0.370\" NUMERICAL mean:0.280642 min:-2.04417 max:3.52981 sd:0.622359\n",
      "\t304: \"data:0.371\" NUMERICAL mean:0.654408 min:-1.78363 max:3.18249 sd:0.554814\n",
      "\t305: \"data:0.372\" NUMERICAL mean:-0.1962 min:-2.6948 max:2.0858 sd:0.577348\n",
      "\t306: \"data:0.373\" NUMERICAL mean:-0.27702 min:-2.37491 max:1.76797 sd:0.525873\n",
      "\t307: \"data:0.374\" NUMERICAL mean:-0.357415 min:-2.81118 max:2.34598 sd:0.630502\n",
      "\t308: \"data:0.375\" NUMERICAL mean:-0.264368 min:-2.71415 max:2.73431 sd:0.655043\n",
      "\t309: \"data:0.376\" NUMERICAL mean:-0.786233 min:-3.17782 max:1.65775 sd:0.553233\n",
      "\t310: \"data:0.377\" NUMERICAL mean:-0.635576 min:-3.77729 max:1.99569 sd:0.689937\n",
      "\t311: \"data:0.378\" NUMERICAL mean:-0.737608 min:-3.37661 max:1.75974 sd:0.603879\n",
      "\t312: \"data:0.379\" NUMERICAL mean:-0.476151 min:-2.91433 max:1.88828 sd:0.556643\n",
      "\t313: \"data:0.38\" NUMERICAL mean:0.125594 min:-3.08926 max:3.20735 sd:0.815273\n",
      "\t314: \"data:0.380\" NUMERICAL mean:-0.588765 min:-3.92835 max:2.86233 sd:0.833743\n",
      "\t315: \"data:0.381\" NUMERICAL mean:0.376758 min:-2.56732 max:3.14849 sd:0.633244\n",
      "\t316: \"data:0.382\" NUMERICAL mean:-0.645232 min:-3.15436 max:2.18804 sd:0.620782\n",
      "\t317: \"data:0.383\" NUMERICAL mean:0.659935 min:-2.67926 max:3.3101 sd:0.913909\n",
      "\t318: \"data:0.384\" NUMERICAL mean:0.44899 min:-2.21265 max:3.36488 sd:0.614328\n",
      "\t319: \"data:0.385\" NUMERICAL mean:0.923172 min:-1.90054 max:3.92732 sd:0.680578\n",
      "\t320: \"data:0.386\" NUMERICAL mean:-0.0253344 min:-3.07472 max:2.71882 sd:0.700807\n",
      "\t321: \"data:0.387\" NUMERICAL mean:-0.194253 min:-2.51964 max:2.87631 sd:0.614507\n",
      "\t322: \"data:0.388\" NUMERICAL mean:-0.454662 min:-3.03089 max:2.19452 sd:0.636457\n",
      "\t323: \"data:0.389\" NUMERICAL mean:0.0967673 min:-2.36927 max:2.33995 sd:0.570172\n",
      "\t324: \"data:0.39\" NUMERICAL mean:0.493926 min:-2.34028 max:3.39771 sd:0.733619\n",
      "\t325: \"data:0.390\" NUMERICAL mean:-0.0420599 min:-2.38625 max:2.18736 sd:0.530222\n",
      "\t326: \"data:0.391\" NUMERICAL mean:0.0293081 min:-2.50922 max:2.79988 sd:0.589505\n",
      "\t327: \"data:0.392\" NUMERICAL mean:-0.036792 min:-3.0196 max:2.73517 sd:0.652767\n",
      "\t328: \"data:0.393\" NUMERICAL mean:0.48544 min:-2.10781 max:2.99088 sd:0.56681\n",
      "\t329: \"data:0.394\" NUMERICAL mean:0.400325 min:-2.36321 max:2.98975 sd:0.662516\n",
      "\t330: \"data:0.395\" NUMERICAL mean:-0.305947 min:-3.08307 max:2.18723 sd:0.559462\n",
      "\t331: \"data:0.396\" NUMERICAL mean:0.0130049 min:-2.66114 max:2.30114 sd:0.601106\n",
      "\t332: \"data:0.397\" NUMERICAL mean:0.325087 min:-2.37378 max:2.9323 sd:0.606615\n",
      "\t333: \"data:0.398\" NUMERICAL mean:-0.218197 min:-2.49984 max:2.77068 sd:0.604361\n",
      "\t334: \"data:0.399\" NUMERICAL mean:-0.123377 min:-2.58722 max:2.40349 sd:0.592594\n",
      "\t335: \"data:0.4\" NUMERICAL mean:-0.68094 min:-3.51581 max:1.62978 sd:0.618917\n",
      "\t336: \"data:0.40\" NUMERICAL mean:-0.466219 min:-3.06795 max:2.05151 sd:0.571893\n",
      "\t337: \"data:0.400\" NUMERICAL mean:-0.0311091 min:-2.79116 max:2.30734 sd:0.565321\n",
      "\t338: \"data:0.401\" NUMERICAL mean:0.0410873 min:-2.38758 max:2.44676 sd:0.5409\n",
      "\t339: \"data:0.402\" NUMERICAL mean:0.218928 min:-2.63039 max:2.94962 sd:0.563818\n",
      "\t340: \"data:0.403\" NUMERICAL mean:0.372052 min:-2.12138 max:2.75893 sd:0.572687\n",
      "\t341: \"data:0.404\" NUMERICAL mean:-0.525896 min:-3.49087 max:2.82223 sd:0.768904\n",
      "\t342: \"data:0.405\" NUMERICAL mean:0.53629 min:-2.11186 max:2.95717 sd:0.671186\n",
      "\t343: \"data:0.406\" NUMERICAL mean:1.50162 min:-2.33579 max:4.87106 sd:0.957111\n",
      "\t344: \"data:0.407\" NUMERICAL mean:0.658635 min:-2.24158 max:3.51517 sd:0.687199\n",
      "\t345: \"data:0.408\" NUMERICAL mean:-0.838947 min:-3.38529 max:1.63394 sd:0.586343\n",
      "\t346: \"data:0.409\" NUMERICAL mean:0.523536 min:-2.24851 max:3.18806 sd:0.645567\n",
      "\t347: \"data:0.41\" NUMERICAL mean:-0.834079 min:-3.73839 max:2.43547 sd:0.847593\n",
      "\t348: \"data:0.410\" NUMERICAL mean:-0.454521 min:-2.77522 max:2.22512 sd:0.574358\n",
      "\t349: \"data:0.411\" NUMERICAL mean:-0.606183 min:-3.29084 max:2.0685 sd:0.611094\n",
      "\t350: \"data:0.412\" NUMERICAL mean:-0.416703 min:-2.96911 max:2.19494 sd:0.631623\n",
      "\t351: \"data:0.413\" NUMERICAL mean:-0.508558 min:-3.32584 max:2.11345 sd:0.718574\n",
      "\t352: \"data:0.414\" NUMERICAL mean:0.597285 min:-2.26543 max:3.42026 sd:0.590697\n",
      "\t353: \"data:0.415\" NUMERICAL mean:-1.13481 min:-4.39571 max:1.57962 sd:0.70818\n",
      "\t354: \"data:0.416\" NUMERICAL mean:0.0161731 min:-2.34694 max:2.49893 sd:0.530348\n",
      "\t355: \"data:0.417\" NUMERICAL mean:0.0888127 min:-2.24734 max:2.9355 sd:0.571521\n",
      "\t356: \"data:0.418\" NUMERICAL mean:0.119883 min:-2.00861 max:2.39111 sd:0.51256\n",
      "\t357: \"data:0.419\" NUMERICAL mean:-0.14381 min:-3.01827 max:2.5526 sd:0.700319\n",
      "\t358: \"data:0.42\" NUMERICAL mean:-0.0669263 min:-2.69331 max:2.70389 sd:0.579688\n",
      "\t359: \"data:0.420\" NUMERICAL mean:-0.266684 min:-3.00242 max:2.03336 sd:0.649644\n",
      "\t360: \"data:0.421\" NUMERICAL mean:-0.057814 min:-2.41498 max:2.49521 sd:0.535489\n",
      "\t361: \"data:0.422\" NUMERICAL mean:-0.311247 min:-2.72284 max:2.7294 sd:0.643284\n",
      "\t362: \"data:0.423\" NUMERICAL mean:0.277571 min:-2.00252 max:2.3277 sd:0.518289\n",
      "\t363: \"data:0.424\" NUMERICAL mean:0.386628 min:-2.79404 max:3.84889 sd:0.794165\n",
      "\t364: \"data:0.425\" NUMERICAL mean:1.12017 min:-2.27349 max:3.77597 sd:0.656936\n",
      "\t365: \"data:0.426\" NUMERICAL mean:0.452258 min:-1.92157 max:2.90469 sd:0.606595\n",
      "\t366: \"data:0.427\" NUMERICAL mean:2.26637 min:-1.38652 max:7.37822 sd:1.02571\n",
      "\t367: \"data:0.428\" NUMERICAL mean:-0.319199 min:-3.16879 max:2.3847 sd:0.654453\n",
      "\t368: \"data:0.429\" NUMERICAL mean:0.238651 min:-2.66 max:2.8407 sd:0.652518\n",
      "\t369: \"data:0.43\" NUMERICAL mean:-0.101799 min:-2.91029 max:2.33962 sd:0.599164\n",
      "\t370: \"data:0.430\" NUMERICAL mean:0.0494726 min:-2.88678 max:2.76199 sd:0.666078\n",
      "\t371: \"data:0.431\" NUMERICAL mean:0.0702473 min:-2.4238 max:2.57813 sd:0.578957\n",
      "\t372: \"data:0.432\" NUMERICAL mean:-0.613282 min:-3.20923 max:2.16725 sd:0.631407\n",
      "\t373: \"data:0.433\" NUMERICAL mean:0.0585096 min:-2.6136 max:2.62759 sd:0.681426\n",
      "\t374: \"data:0.434\" NUMERICAL mean:0.0794487 min:-2.68895 max:2.64167 sd:0.540826\n",
      "\t375: \"data:0.435\" NUMERICAL mean:0.098004 min:-3.24805 max:2.73848 sd:0.742378\n",
      "\t376: \"data:0.436\" NUMERICAL mean:0.314164 min:-2.63785 max:2.51948 sd:0.633326\n",
      "\t377: \"data:0.437\" NUMERICAL mean:-0.555746 min:-3.67915 max:2.26627 sd:0.766646\n",
      "\t378: \"data:0.438\" NUMERICAL mean:-0.414311 min:-3.04198 max:2.20372 sd:0.590133\n",
      "\t379: \"data:0.439\" NUMERICAL mean:-0.559205 min:-2.82424 max:1.85917 sd:0.533174\n",
      "\t380: \"data:0.44\" NUMERICAL mean:0.730265 min:-2.3354 max:3.38127 sd:0.6564\n",
      "\t381: \"data:0.440\" NUMERICAL mean:0.437444 min:-1.83136 max:2.6108 sd:0.553329\n",
      "\t382: \"data:0.441\" NUMERICAL mean:0.106507 min:-2.09402 max:2.56775 sd:0.55189\n",
      "\t383: \"data:0.442\" NUMERICAL mean:0.266772 min:-2.29125 max:3.37239 sd:0.596011\n",
      "\t384: \"data:0.443\" NUMERICAL mean:0.588209 min:-2.60171 max:3.45162 sd:0.67721\n",
      "\t385: \"data:0.444\" NUMERICAL mean:0.816787 min:-1.88435 max:3.19906 sd:0.627564\n",
      "\t386: \"data:0.445\" NUMERICAL mean:-0.661089 min:-4.40374 max:3.1513 sd:0.933799\n",
      "\t387: \"data:0.446\" NUMERICAL mean:-0.56754 min:-2.78288 max:1.81519 sd:0.528292\n",
      "\t388: \"data:0.447\" NUMERICAL mean:-0.505904 min:-3.06291 max:2.66314 sd:0.701718\n",
      "\t389: \"data:0.448\" NUMERICAL mean:-0.409653 min:-2.67846 max:1.89882 sd:0.600236\n",
      "\t390: \"data:0.449\" NUMERICAL mean:0.409033 min:-1.94836 max:3.29379 sd:0.593641\n",
      "\t391: \"data:0.45\" NUMERICAL mean:0.92811 min:-2.21507 max:3.31057 sd:0.598881\n",
      "\t392: \"data:0.450\" NUMERICAL mean:0.237309 min:-2.14318 max:3.05621 sd:0.66593\n",
      "\t393: \"data:0.451\" NUMERICAL mean:-0.315647 min:-2.86896 max:2.29824 sd:0.591779\n",
      "\t394: \"data:0.452\" NUMERICAL mean:-0.0828824 min:-2.56615 max:2.61925 sd:0.647698\n",
      "\t395: \"data:0.453\" NUMERICAL mean:0.298421 min:-2.80201 max:2.72902 sd:0.691684\n",
      "\t396: \"data:0.454\" NUMERICAL mean:0.806465 min:-1.89741 max:3.40747 sd:0.601356\n",
      "\t397: \"data:0.455\" NUMERICAL mean:0.711493 min:-2.17288 max:3.79364 sd:0.673373\n",
      "\t398: \"data:0.456\" NUMERICAL mean:-0.205165 min:-2.61994 max:2.43787 sd:0.558344\n",
      "\t399: \"data:0.457\" NUMERICAL mean:0.123787 min:-2.24455 max:2.82856 sd:0.584022\n",
      "\t400: \"data:0.458\" NUMERICAL mean:0.243033 min:-2.42459 max:2.85116 sd:0.578364\n",
      "\t401: \"data:0.459\" NUMERICAL mean:-2.29398 min:-8.9594 max:1.32482 sd:1.48683\n",
      "\t402: \"data:0.46\" NUMERICAL mean:-0.438574 min:-3.18605 max:2.54933 sd:0.651412\n",
      "\t403: \"data:0.460\" NUMERICAL mean:0.0847065 min:-2.08917 max:2.72312 sd:0.576374\n",
      "\t404: \"data:0.461\" NUMERICAL mean:0.151843 min:-2.82099 max:2.60493 sd:0.624187\n",
      "\t405: \"data:0.462\" NUMERICAL mean:0.0621848 min:-2.29498 max:2.24855 sd:0.526432\n",
      "\t406: \"data:0.463\" NUMERICAL mean:-0.284518 min:-3.15325 max:2.14802 sd:0.606462\n",
      "\t407: \"data:0.464\" NUMERICAL mean:0.662687 min:-1.89693 max:3.5332 sd:0.669657\n",
      "\t408: \"data:0.465\" NUMERICAL mean:0.767177 min:-1.58528 max:3.35935 sd:0.602102\n",
      "\t409: \"data:0.466\" NUMERICAL mean:0.202413 min:-2.25098 max:2.6608 sd:0.604594\n",
      "\t410: \"data:0.467\" NUMERICAL mean:-0.354634 min:-2.6381 max:2.1826 sd:0.602418\n",
      "\t411: \"data:0.468\" NUMERICAL mean:-0.0110963 min:-2.62654 max:2.92817 sd:0.642299\n",
      "\t412: \"data:0.469\" NUMERICAL mean:0.0370371 min:-3.24118 max:2.22186 sd:0.682393\n",
      "\t413: \"data:0.47\" NUMERICAL mean:0.181404 min:-2.52895 max:3.17173 sd:0.69029\n",
      "\t414: \"data:0.470\" NUMERICAL mean:-0.243875 min:-2.75041 max:2.56181 sd:0.60803\n",
      "\t415: \"data:0.471\" NUMERICAL mean:-1.01832 min:-3.44652 max:1.70544 sd:0.609734\n",
      "\t416: \"data:0.472\" NUMERICAL mean:-0.289902 min:-2.92647 max:2.68772 sd:0.614235\n",
      "\t417: \"data:0.473\" NUMERICAL mean:-0.390506 min:-3.23562 max:2.8021 sd:0.711679\n",
      "\t418: \"data:0.474\" NUMERICAL mean:-0.754966 min:-3.05483 max:1.84998 sd:0.614281\n",
      "\t419: \"data:0.475\" NUMERICAL mean:-0.0372826 min:-2.3118 max:2.2026 sd:0.5353\n",
      "\t420: \"data:0.476\" NUMERICAL mean:-0.12761 min:-2.68092 max:2.12938 sd:0.622052\n",
      "\t421: \"data:0.477\" NUMERICAL mean:-0.0344631 min:-2.83003 max:2.88941 sd:0.628703\n",
      "\t422: \"data:0.478\" NUMERICAL mean:-0.255153 min:-2.89433 max:2.34928 sd:0.627999\n",
      "\t423: \"data:0.479\" NUMERICAL mean:-0.101031 min:-3.09623 max:2.62456 sd:0.673107\n",
      "\t424: \"data:0.48\" NUMERICAL mean:-0.367288 min:-2.81812 max:2.44658 sd:0.574264\n",
      "\t425: \"data:0.480\" NUMERICAL mean:0.335597 min:-1.60006 max:2.64834 sd:0.457007\n",
      "\t426: \"data:0.481\" NUMERICAL mean:-1.65706 min:-4.12377 max:1.00712 sd:0.602881\n",
      "\t427: \"data:0.482\" NUMERICAL mean:0.223525 min:-2.26037 max:2.85065 sd:0.610401\n",
      "\t428: \"data:0.483\" NUMERICAL mean:-0.357402 min:-2.75903 max:1.95199 sd:0.545084\n",
      "\t429: \"data:0.484\" NUMERICAL mean:-0.580937 min:-2.80947 max:1.82619 sd:0.602606\n",
      "\t430: \"data:0.485\" NUMERICAL mean:-0.632899 min:-3.36844 max:2.36092 sd:0.644527\n",
      "\t431: \"data:0.486\" NUMERICAL mean:-0.0907138 min:-2.71925 max:2.70505 sd:0.660183\n",
      "\t432: \"data:0.487\" NUMERICAL mean:0.223883 min:-2.80337 max:2.77063 sd:0.704865\n",
      "\t433: \"data:0.488\" NUMERICAL mean:-0.846809 min:-4.11653 max:1.91588 sd:0.608096\n",
      "\t434: \"data:0.489\" NUMERICAL mean:0.30718 min:-2.47344 max:2.43916 sd:0.56514\n",
      "\t435: \"data:0.49\" NUMERICAL mean:0.0858205 min:-2.51059 max:2.59353 sd:0.627961\n",
      "\t436: \"data:0.490\" NUMERICAL mean:0.0757717 min:-2.67435 max:2.99815 sd:0.587371\n",
      "\t437: \"data:0.491\" NUMERICAL mean:0.325652 min:-2.70049 max:3.11563 sd:0.674055\n",
      "\t438: \"data:0.492\" NUMERICAL mean:-0.148438 min:-2.71593 max:2.55066 sd:0.621\n",
      "\t439: \"data:0.493\" NUMERICAL mean:0.204828 min:-2.80933 max:2.5927 sd:0.592476\n",
      "\t440: \"data:0.494\" NUMERICAL mean:-0.767384 min:-2.99764 max:1.63282 sd:0.585749\n",
      "\t441: \"data:0.495\" NUMERICAL mean:0.383145 min:-2.63833 max:2.64749 sd:0.598094\n",
      "\t442: \"data:0.496\" NUMERICAL mean:-0.369672 min:-2.65248 max:2.17221 sd:0.575314\n",
      "\t443: \"data:0.497\" NUMERICAL mean:0.556332 min:-2.06036 max:2.91633 sd:0.584393\n",
      "\t444: \"data:0.498\" NUMERICAL mean:-0.477606 min:-2.85255 max:2.23179 sd:0.612704\n",
      "\t445: \"data:0.499\" NUMERICAL mean:-0.177378 min:-2.52293 max:1.96599 sd:0.514503\n",
      "\t446: \"data:0.5\" NUMERICAL mean:0.0503397 min:-2.05265 max:2.52502 sd:0.526573\n",
      "\t447: \"data:0.50\" NUMERICAL mean:-0.00284083 min:-2.83593 max:2.86769 sd:0.61616\n",
      "\t448: \"data:0.500\" NUMERICAL mean:-0.413489 min:-2.88261 max:2.46288 sd:0.603499\n",
      "\t449: \"data:0.501\" NUMERICAL mean:-0.0761307 min:-2.98573 max:2.49092 sd:0.669775\n",
      "\t450: \"data:0.502\" NUMERICAL mean:0.261565 min:-2.1337 max:2.69502 sd:0.582873\n",
      "\t451: \"data:0.503\" NUMERICAL mean:-0.221928 min:-2.57016 max:2.99246 sd:0.620476\n",
      "\t452: \"data:0.504\" NUMERICAL mean:-0.276695 min:-3.86108 max:3.71856 sd:0.925703\n",
      "\t453: \"data:0.505\" NUMERICAL mean:0.548916 min:-2.45892 max:3.05787 sd:0.654158\n",
      "\t454: \"data:0.506\" NUMERICAL mean:0.141098 min:-2.721 max:2.63399 sd:0.594162\n",
      "\t455: \"data:0.507\" NUMERICAL mean:0.459121 min:-2.44225 max:2.64084 sd:0.553192\n",
      "\t456: \"data:0.508\" NUMERICAL mean:0.901506 min:-2.30409 max:3.43174 sd:0.611474\n",
      "\t457: \"data:0.509\" NUMERICAL mean:0.0638188 min:-2.5075 max:2.75922 sd:0.580876\n",
      "\t458: \"data:0.51\" NUMERICAL mean:-0.141121 min:-3.21692 max:2.39274 sd:0.571229\n",
      "\t459: \"data:0.510\" NUMERICAL mean:-0.00104821 min:-2.99908 max:2.42128 sd:0.626184\n",
      "\t460: \"data:0.511\" NUMERICAL mean:-0.159584 min:-2.58599 max:2.47912 sd:0.541016\n",
      "\t461: \"data:0.512\" NUMERICAL mean:0.242483 min:-2.52875 max:2.72722 sd:0.597112\n",
      "\t462: \"data:0.513\" NUMERICAL mean:0.450738 min:-2.6331 max:3.19587 sd:0.638619\n",
      "\t463: \"data:0.514\" NUMERICAL mean:0.118826 min:-2.61932 max:2.42865 sd:0.598153\n",
      "\t464: \"data:0.515\" NUMERICAL mean:-0.00689078 min:-2.42038 max:2.69405 sd:0.619397\n",
      "\t465: \"data:0.516\" NUMERICAL mean:0.164992 min:-2.3792 max:2.95462 sd:0.574911\n",
      "\t466: \"data:0.517\" NUMERICAL mean:-0.687957 min:-3.45657 max:1.89882 sd:0.652825\n",
      "\t467: \"data:0.518\" NUMERICAL mean:-0.481846 min:-3.18175 max:1.96188 sd:0.58118\n",
      "\t468: \"data:0.519\" NUMERICAL mean:0.202875 min:-2.11359 max:2.9979 sd:0.592631\n",
      "\t469: \"data:0.52\" NUMERICAL mean:0.170294 min:-2.3693 max:3.00565 sd:0.660544\n",
      "\t470: \"data:0.520\" NUMERICAL mean:-0.582149 min:-3.22822 max:1.81835 sd:0.582053\n",
      "\t471: \"data:0.521\" NUMERICAL mean:-0.116301 min:-2.28672 max:1.97208 sd:0.518921\n",
      "\t472: \"data:0.522\" NUMERICAL mean:0.322017 min:-2.38897 max:2.79913 sd:0.604641\n",
      "\t473: \"data:0.523\" NUMERICAL mean:-0.100519 min:-2.80665 max:2.75935 sd:0.610738\n",
      "\t474: \"data:0.524\" NUMERICAL mean:-0.0840807 min:-2.95497 max:2.83835 sd:0.641788\n",
      "\t475: \"data:0.525\" NUMERICAL mean:-0.630742 min:-3.27236 max:2.61334 sd:0.65291\n",
      "\t476: \"data:0.526\" NUMERICAL mean:-0.124909 min:-2.83986 max:2.67037 sd:0.629434\n",
      "\t477: \"data:0.527\" NUMERICAL mean:0.36563 min:-2.05871 max:2.88241 sd:0.536912\n",
      "\t478: \"data:0.528\" NUMERICAL mean:0.173096 min:-2.3771 max:2.76959 sd:0.657875\n",
      "\t479: \"data:0.529\" NUMERICAL mean:0.696194 min:-2.17558 max:3.11484 sd:0.604157\n",
      "\t480: \"data:0.53\" NUMERICAL mean:0.433524 min:-2.46331 max:3.02152 sd:0.621498\n",
      "\t481: \"data:0.530\" NUMERICAL mean:0.393417 min:-2.33745 max:3.57006 sd:0.689881\n",
      "\t482: \"data:0.531\" NUMERICAL mean:0.352027 min:-1.93993 max:3.06546 sd:0.588169\n",
      "\t483: \"data:0.532\" NUMERICAL mean:-0.0620238 min:-2.49518 max:2.38676 sd:0.597955\n",
      "\t484: \"data:0.533\" NUMERICAL mean:0.42793 min:-1.87128 max:2.8881 sd:0.55532\n",
      "\t485: \"data:0.534\" NUMERICAL mean:0.11199 min:-2.55327 max:2.89191 sd:0.648358\n",
      "\t486: \"data:0.535\" NUMERICAL mean:0.283944 min:-1.95975 max:2.8578 sd:0.545109\n",
      "\t487: \"data:0.536\" NUMERICAL mean:-0.231053 min:-2.77857 max:2.07833 sd:0.650144\n",
      "\t488: \"data:0.537\" NUMERICAL mean:-0.687964 min:-2.97694 max:1.91167 sd:0.59954\n",
      "\t489: \"data:0.538\" NUMERICAL mean:-0.402543 min:-3.59779 max:2.92028 sd:0.751708\n",
      "\t490: \"data:0.539\" NUMERICAL mean:-0.356134 min:-3.48215 max:2.38937 sd:0.669413\n",
      "\t491: \"data:0.54\" NUMERICAL mean:-0.298554 min:-3.09009 max:2.0149 sd:0.611019\n",
      "\t492: \"data:0.540\" NUMERICAL mean:-0.693008 min:-3.05784 max:1.55445 sd:0.55725\n",
      "\t493: \"data:0.541\" NUMERICAL mean:-0.565789 min:-3.02952 max:2.16129 sd:0.59071\n",
      "\t494: \"data:0.542\" NUMERICAL mean:0.542304 min:-1.7924 max:3.21939 sd:0.608976\n",
      "\t495: \"data:0.543\" NUMERICAL mean:0.260531 min:-2.56776 max:3.36357 sd:0.629853\n",
      "\t496: \"data:0.544\" NUMERICAL mean:-0.204194 min:-2.46327 max:2.73907 sd:0.565677\n",
      "\t497: \"data:0.545\" NUMERICAL mean:-0.588432 min:-3.3367 max:2.09166 sd:0.588269\n",
      "\t498: \"data:0.546\" NUMERICAL mean:0.572853 min:-2.2467 max:3.50229 sd:0.72275\n",
      "\t499: \"data:0.547\" NUMERICAL mean:0.400162 min:-2.19825 max:2.86533 sd:0.685\n",
      "\t500: \"data:0.548\" NUMERICAL mean:-0.389791 min:-2.69351 max:2.08072 sd:0.565497\n",
      "\t501: \"data:0.549\" NUMERICAL mean:-0.790681 min:-3.66966 max:2.16906 sd:0.606003\n",
      "\t502: \"data:0.55\" NUMERICAL mean:0.155784 min:-2.30836 max:2.94077 sd:0.594041\n",
      "\t503: \"data:0.550\" NUMERICAL mean:-0.143263 min:-2.95287 max:2.24992 sd:0.638141\n",
      "\t504: \"data:0.551\" NUMERICAL mean:0.285608 min:-2.05528 max:2.7801 sd:0.587308\n",
      "\t505: \"data:0.552\" NUMERICAL mean:0.320603 min:-2.45878 max:3.11115 sd:0.638258\n",
      "\t506: \"data:0.553\" NUMERICAL mean:0.258189 min:-2.09763 max:3.06296 sd:0.586284\n",
      "\t507: \"data:0.554\" NUMERICAL mean:-0.0464866 min:-2.58655 max:2.85699 sd:0.629428\n",
      "\t508: \"data:0.555\" NUMERICAL mean:-0.424102 min:-3.22009 max:2.11773 sd:0.639411\n",
      "\t509: \"data:0.556\" NUMERICAL mean:0.293201 min:-2.3457 max:3.16466 sd:0.626258\n",
      "\t510: \"data:0.557\" NUMERICAL mean:0.341011 min:-2.19695 max:2.92342 sd:0.588383\n",
      "\t511: \"data:0.558\" NUMERICAL mean:0.0734612 min:-2.72013 max:2.67065 sd:0.614607\n",
      "\t512: \"data:0.559\" NUMERICAL mean:0.277824 min:-2.28412 max:2.79936 sd:0.64133\n",
      "\t513: \"data:0.56\" NUMERICAL mean:-0.201551 min:-2.88865 max:1.92654 sd:0.585419\n",
      "\t514: \"data:0.560\" NUMERICAL mean:0.643768 min:-2.02942 max:3.16012 sd:0.635039\n",
      "\t515: \"data:0.561\" NUMERICAL mean:0.54401 min:-1.97094 max:3.51801 sd:0.65483\n",
      "\t516: \"data:0.562\" NUMERICAL mean:-0.117297 min:-3.17848 max:2.29526 sd:0.578034\n",
      "\t517: \"data:0.563\" NUMERICAL mean:0.351179 min:-2.04696 max:3.22901 sd:0.667695\n",
      "\t518: \"data:0.564\" NUMERICAL mean:0.0782686 min:-2.7951 max:2.71369 sd:0.62613\n",
      "\t519: \"data:0.565\" NUMERICAL mean:-0.200589 min:-3.65064 max:2.45895 sd:0.599666\n",
      "\t520: \"data:0.566\" NUMERICAL mean:0.619709 min:-2.11511 max:3.52614 sd:0.626062\n",
      "\t521: \"data:0.567\" NUMERICAL mean:-0.401643 min:-2.84296 max:2.20771 sd:0.697599\n",
      "\t522: \"data:0.568\" NUMERICAL mean:-0.1127 min:-2.67392 max:3.12137 sd:0.677734\n",
      "\t523: \"data:0.569\" NUMERICAL mean:0.671194 min:-2.02487 max:3.14949 sd:0.636591\n",
      "\t524: \"data:0.57\" NUMERICAL mean:0.750101 min:-1.83037 max:3.74399 sd:0.670072\n",
      "\t525: \"data:0.570\" NUMERICAL mean:-0.202887 min:-2.74901 max:3.16262 sd:0.745918\n",
      "\t526: \"data:0.571\" NUMERICAL mean:1.06832 min:-1.29802 max:3.29344 sd:0.523208\n",
      "\t527: \"data:0.572\" NUMERICAL mean:-0.224584 min:-2.9216 max:1.97902 sd:0.635205\n",
      "\t528: \"data:0.573\" NUMERICAL mean:0.465304 min:-2.44108 max:2.77244 sd:0.566297\n",
      "\t529: \"data:0.574\" NUMERICAL mean:0.48477 min:-2.10869 max:3.03462 sd:0.585109\n",
      "\t530: \"data:0.575\" NUMERICAL mean:0.100312 min:-2.39506 max:2.2582 sd:0.567412\n",
      "\t531: \"data:0.576\" NUMERICAL mean:0.133007 min:-2.33408 max:2.91382 sd:0.59622\n",
      "\t532: \"data:0.577\" NUMERICAL mean:-0.952215 min:-3.19048 max:1.6423 sd:0.599158\n",
      "\t533: \"data:0.578\" NUMERICAL mean:-0.480529 min:-3.10867 max:2.24155 sd:0.647657\n",
      "\t534: \"data:0.579\" NUMERICAL mean:0.475737 min:-3.13284 max:2.98501 sd:0.725629\n",
      "\t535: \"data:0.58\" NUMERICAL mean:-0.260518 min:-2.5852 max:2.08982 sd:0.591618\n",
      "\t536: \"data:0.580\" NUMERICAL mean:-0.0751273 min:-2.52618 max:2.41947 sd:0.569319\n",
      "\t537: \"data:0.581\" NUMERICAL mean:-1.03156 min:-3.78546 max:1.52543 sd:0.630503\n",
      "\t538: \"data:0.582\" NUMERICAL mean:-0.32605 min:-3.19002 max:2.25695 sd:0.66733\n",
      "\t539: \"data:0.583\" NUMERICAL mean:-0.0227477 min:-2.61977 max:2.74866 sd:0.681647\n",
      "\t540: \"data:0.584\" NUMERICAL mean:-0.936569 min:-3.58307 max:1.65115 sd:0.633151\n",
      "\t541: \"data:0.585\" NUMERICAL mean:-0.112792 min:-3.40979 max:2.46491 sd:0.606774\n",
      "\t542: \"data:0.586\" NUMERICAL mean:-0.060321 min:-2.53214 max:2.66103 sd:0.609671\n",
      "\t543: \"data:0.587\" NUMERICAL mean:0.166249 min:-2.20086 max:2.66798 sd:0.568315\n",
      "\t544: \"data:0.588\" NUMERICAL mean:0.664113 min:-2.42543 max:3.4138 sd:0.627582\n",
      "\t545: \"data:0.589\" NUMERICAL mean:-0.322491 min:-2.59403 max:2.24108 sd:0.568963\n",
      "\t546: \"data:0.59\" NUMERICAL mean:-0.640998 min:-3.42543 max:1.73517 sd:0.58406\n",
      "\t547: \"data:0.590\" NUMERICAL mean:-0.275547 min:-2.82189 max:2.77925 sd:0.688651\n",
      "\t548: \"data:0.591\" NUMERICAL mean:-0.709171 min:-3.40288 max:2.20168 sd:0.592175\n",
      "\t549: \"data:0.592\" NUMERICAL mean:-0.589502 min:-3.24531 max:2.36952 sd:0.628328\n",
      "\t550: \"data:0.593\" NUMERICAL mean:-0.0669861 min:-2.52287 max:2.44714 sd:0.592604\n",
      "\t551: \"data:0.594\" NUMERICAL mean:0.728729 min:-1.84583 max:3.35003 sd:0.559763\n",
      "\t552: \"data:0.595\" NUMERICAL mean:-0.0605768 min:-2.2572 max:2.15498 sd:0.554582\n",
      "\t553: \"data:0.596\" NUMERICAL mean:-0.336203 min:-2.58771 max:2.43962 sd:0.605186\n",
      "\t554: \"data:0.597\" NUMERICAL mean:0.663122 min:-2.06046 max:3.13546 sd:0.624747\n",
      "\t555: \"data:0.598\" NUMERICAL mean:-0.270053 min:-2.82511 max:1.9284 sd:0.553913\n",
      "\t556: \"data:0.599\" NUMERICAL mean:-0.41871 min:-2.80316 max:2.20322 sd:0.572779\n",
      "\t557: \"data:0.6\" NUMERICAL mean:0.906991 min:-1.73344 max:3.38543 sd:0.577045\n",
      "\t558: \"data:0.60\" NUMERICAL mean:-0.679544 min:-3.13652 max:2.01973 sd:0.645391\n",
      "\t559: \"data:0.600\" NUMERICAL mean:-0.0732097 min:-2.80783 max:2.38882 sd:0.655538\n",
      "\t560: \"data:0.601\" NUMERICAL mean:0.248738 min:-2.24868 max:2.6637 sd:0.598731\n",
      "\t561: \"data:0.602\" NUMERICAL mean:-0.0922608 min:-3.06887 max:2.56961 sd:0.650309\n",
      "\t562: \"data:0.603\" NUMERICAL mean:-0.540732 min:-3.06287 max:2.00677 sd:0.57266\n",
      "\t563: \"data:0.604\" NUMERICAL mean:0.359336 min:-2.32498 max:2.99379 sd:0.618672\n",
      "\t564: \"data:0.605\" NUMERICAL mean:0.127153 min:-2.37266 max:2.44423 sd:0.578256\n",
      "\t565: \"data:0.606\" NUMERICAL mean:0.486465 min:-3.11911 max:3.26536 sd:0.661945\n",
      "\t566: \"data:0.607\" NUMERICAL mean:0.303497 min:-2.28857 max:2.64436 sd:0.571655\n",
      "\t567: \"data:0.608\" NUMERICAL mean:0.306616 min:-2.09054 max:2.85254 sd:0.613311\n",
      "\t568: \"data:0.609\" NUMERICAL mean:-0.625445 min:-3.49137 max:2.24756 sd:0.77932\n",
      "\t569: \"data:0.61\" NUMERICAL mean:-1.07852 min:-3.60321 max:1.80878 sd:0.573473\n",
      "\t570: \"data:0.610\" NUMERICAL mean:-0.271171 min:-2.9182 max:1.9967 sd:0.575087\n",
      "\t571: \"data:0.611\" NUMERICAL mean:0.154507 min:-2.61333 max:2.80074 sd:0.681702\n",
      "\t572: \"data:0.612\" NUMERICAL mean:0.240028 min:-2.2506 max:2.92565 sd:0.603291\n",
      "\t573: \"data:0.613\" NUMERICAL mean:0.93762 min:-2.18032 max:4.06434 sd:0.705146\n",
      "\t574: \"data:0.614\" NUMERICAL mean:-0.494696 min:-3.17824 max:2.19577 sd:0.616449\n",
      "\t575: \"data:0.615\" NUMERICAL mean:0.426468 min:-1.93611 max:3.00337 sd:0.568782\n",
      "\t576: \"data:0.616\" NUMERICAL mean:0.00621234 min:-2.59862 max:2.70054 sd:0.607596\n",
      "\t577: \"data:0.617\" NUMERICAL mean:0.841977 min:-1.5513 max:3.15768 sd:0.578738\n",
      "\t578: \"data:0.618\" NUMERICAL mean:0.255541 min:-2.10167 max:2.80487 sd:0.66956\n",
      "\t579: \"data:0.619\" NUMERICAL mean:-0.21242 min:-2.66602 max:2.25766 sd:0.594146\n",
      "\t580: \"data:0.62\" NUMERICAL mean:-0.321633 min:-2.63914 max:2.16051 sd:0.583263\n",
      "\t581: \"data:0.620\" NUMERICAL mean:0.230168 min:-2.49557 max:2.71959 sd:0.591495\n",
      "\t582: \"data:0.621\" NUMERICAL mean:-0.448208 min:-2.70228 max:2.27082 sd:0.634457\n",
      "\t583: \"data:0.622\" NUMERICAL mean:-0.153132 min:-3.21458 max:3.12731 sd:0.671895\n",
      "\t584: \"data:0.623\" NUMERICAL mean:0.242204 min:-2.64164 max:3.04928 sd:0.632265\n",
      "\t585: \"data:0.624\" NUMERICAL mean:0.120605 min:-2.4213 max:2.45542 sd:0.547199\n",
      "\t586: \"data:0.625\" NUMERICAL mean:0.207746 min:-2.29584 max:2.65955 sd:0.538058\n",
      "\t587: \"data:0.626\" NUMERICAL mean:0.327285 min:-1.96287 max:3.03292 sd:0.65824\n",
      "\t588: \"data:0.627\" NUMERICAL mean:0.222596 min:-3.09228 max:2.77353 sd:0.619095\n",
      "\t589: \"data:0.628\" NUMERICAL mean:0.0554061 min:-2.67484 max:2.5554 sd:0.582325\n",
      "\t590: \"data:0.629\" NUMERICAL mean:-0.493049 min:-3.0003 max:2.24204 sd:0.586348\n",
      "\t591: \"data:0.63\" NUMERICAL mean:-0.0727377 min:-3.36414 max:3.19701 sd:0.897537\n",
      "\t592: \"data:0.630\" NUMERICAL mean:0.138542 min:-2.21176 max:2.27118 sd:0.537374\n",
      "\t593: \"data:0.631\" NUMERICAL mean:-0.401496 min:-2.9857 max:1.79438 sd:0.567548\n",
      "\t594: \"data:0.632\" NUMERICAL mean:-0.0122893 min:-2.36774 max:3.03116 sd:0.579912\n",
      "\t595: \"data:0.633\" NUMERICAL mean:-0.362654 min:-3.09338 max:2.60831 sd:0.674677\n",
      "\t596: \"data:0.634\" NUMERICAL mean:0.578665 min:-2.32513 max:3.47428 sd:0.690519\n",
      "\t597: \"data:0.635\" NUMERICAL mean:-0.484977 min:-3.58493 max:2.27556 sd:0.678975\n",
      "\t598: \"data:0.636\" NUMERICAL mean:0.235175 min:-2.57275 max:2.9195 sd:0.621501\n",
      "\t599: \"data:0.637\" NUMERICAL mean:-0.111096 min:-2.72968 max:2.33624 sd:0.558396\n",
      "\t600: \"data:0.638\" NUMERICAL mean:0.325912 min:-2.2201 max:2.88383 sd:0.57017\n",
      "\t601: \"data:0.639\" NUMERICAL mean:0.217585 min:-2.22287 max:2.89046 sd:0.55852\n",
      "\t602: \"data:0.64\" NUMERICAL mean:-0.366344 min:-3.33149 max:2.58477 sd:0.67075\n",
      "\t603: \"data:0.640\" NUMERICAL mean:-0.553115 min:-2.95587 max:2.05911 sd:0.576592\n",
      "\t604: \"data:0.641\" NUMERICAL mean:-0.496689 min:-3.29804 max:2.11075 sd:0.612074\n",
      "\t605: \"data:0.642\" NUMERICAL mean:-0.196111 min:-2.70681 max:2.11772 sd:0.583882\n",
      "\t606: \"data:0.643\" NUMERICAL mean:0.810055 min:-2.33355 max:3.31005 sd:0.786538\n",
      "\t607: \"data:0.644\" NUMERICAL mean:0.220655 min:-2.35043 max:3.24607 sd:0.613148\n",
      "\t608: \"data:0.645\" NUMERICAL mean:0.114766 min:-2.5114 max:3.02149 sd:0.605604\n",
      "\t609: \"data:0.646\" NUMERICAL mean:0.756141 min:-2.22102 max:3.4886 sd:0.703962\n",
      "\t610: \"data:0.647\" NUMERICAL mean:0.198152 min:-2.31575 max:2.91262 sd:0.576983\n",
      "\t611: \"data:0.648\" NUMERICAL mean:-0.273617 min:-2.63376 max:1.81868 sd:0.510337\n",
      "\t612: \"data:0.649\" NUMERICAL mean:0.699537 min:-2.33153 max:3.67103 sd:0.692065\n",
      "\t613: \"data:0.65\" NUMERICAL mean:-0.651519 min:-2.95905 max:1.79354 sd:0.56173\n",
      "\t614: \"data:0.650\" NUMERICAL mean:0.110761 min:-2.18975 max:2.4275 sd:0.548176\n",
      "\t615: \"data:0.651\" NUMERICAL mean:-0.224675 min:-2.29218 max:2.01276 sd:0.524692\n",
      "\t616: \"data:0.652\" NUMERICAL mean:0.0549674 min:-2.64915 max:2.72508 sd:0.618563\n",
      "\t617: \"data:0.653\" NUMERICAL mean:-0.151346 min:-2.89479 max:2.34359 sd:0.635615\n",
      "\t618: \"data:0.654\" NUMERICAL mean:0.277923 min:-2.4172 max:2.72197 sd:0.577308\n",
      "\t619: \"data:0.655\" NUMERICAL mean:0.429125 min:-2.15857 max:3.41956 sd:0.658023\n",
      "\t620: \"data:0.656\" NUMERICAL mean:0.369525 min:-2.7874 max:3.35311 sd:0.761141\n",
      "\t621: \"data:0.657\" NUMERICAL mean:0.0235604 min:-2.95439 max:3.25944 sd:0.675657\n",
      "\t622: \"data:0.658\" NUMERICAL mean:0.572513 min:-2.03307 max:2.86069 sd:0.625773\n",
      "\t623: \"data:0.659\" NUMERICAL mean:0.205963 min:-2.66063 max:2.68293 sd:0.584316\n",
      "\t624: \"data:0.66\" NUMERICAL mean:0.063804 min:-2.44778 max:2.41538 sd:0.544833\n",
      "\t625: \"data:0.660\" NUMERICAL mean:-0.401147 min:-3.18886 max:2.18503 sd:0.597636\n",
      "\t626: \"data:0.661\" NUMERICAL mean:0.46274 min:-2.05871 max:3.46363 sd:0.642921\n",
      "\t627: \"data:0.662\" NUMERICAL mean:0.135564 min:-2.32538 max:2.6538 sd:0.566018\n",
      "\t628: \"data:0.663\" NUMERICAL mean:-0.49796 min:-3.37407 max:1.93203 sd:0.603368\n",
      "\t629: \"data:0.664\" NUMERICAL mean:-0.498099 min:-3.1152 max:1.86648 sd:0.590144\n",
      "\t630: \"data:0.665\" NUMERICAL mean:0.747566 min:-1.76529 max:2.98613 sd:0.527327\n",
      "\t631: \"data:0.666\" NUMERICAL mean:0.873663 min:-1.88086 max:3.63171 sd:0.657913\n",
      "\t632: \"data:0.667\" NUMERICAL mean:0.11068 min:-2.43824 max:2.73989 sd:0.569675\n",
      "\t633: \"data:0.668\" NUMERICAL mean:-0.431502 min:-2.51019 max:2.11264 sd:0.634091\n",
      "\t634: \"data:0.669\" NUMERICAL mean:-0.170839 min:-2.70998 max:2.31306 sd:0.615425\n",
      "\t635: \"data:0.67\" NUMERICAL mean:0.0485043 min:-2.59157 max:2.41908 sd:0.594512\n",
      "\t636: \"data:0.670\" NUMERICAL mean:-0.619991 min:-3.57447 max:1.92647 sd:0.702227\n",
      "\t637: \"data:0.671\" NUMERICAL mean:-0.703492 min:-3.39651 max:2.09941 sd:0.671061\n",
      "\t638: \"data:0.672\" NUMERICAL mean:-1.04886 min:-4.03991 max:2.34708 sd:0.638212\n",
      "\t639: \"data:0.673\" NUMERICAL mean:-0.0220552 min:-2.79133 max:2.6287 sd:0.596882\n",
      "\t640: \"data:0.674\" NUMERICAL mean:0.00426046 min:-2.39326 max:2.56968 sd:0.591242\n",
      "\t641: \"data:0.675\" NUMERICAL mean:-0.333974 min:-2.90872 max:2.31071 sd:0.677338\n",
      "\t642: \"data:0.676\" NUMERICAL mean:0.013957 min:-2.70535 max:2.56331 sd:0.605208\n",
      "\t643: \"data:0.677\" NUMERICAL mean:-0.735513 min:-3.66018 max:2.297 sd:0.661689\n",
      "\t644: \"data:0.678\" NUMERICAL mean:0.235936 min:-2.2663 max:2.66984 sd:0.566297\n",
      "\t645: \"data:0.679\" NUMERICAL mean:-0.0439729 min:-3.02774 max:2.63996 sd:0.641932\n",
      "\t646: \"data:0.68\" NUMERICAL mean:0.932628 min:-2.14545 max:3.87478 sd:0.633282\n",
      "\t647: \"data:0.680\" NUMERICAL mean:0.151052 min:-2.38302 max:2.45052 sd:0.580639\n",
      "\t648: \"data:0.681\" NUMERICAL mean:-0.279568 min:-2.73929 max:2.4468 sd:0.593723\n",
      "\t649: \"data:0.682\" NUMERICAL mean:-0.167724 min:-2.76807 max:2.14708 sd:0.565727\n",
      "\t650: \"data:0.683\" NUMERICAL mean:0.313128 min:-2.43169 max:2.86641 sd:0.640154\n",
      "\t651: \"data:0.684\" NUMERICAL mean:0.259107 min:-2.18839 max:3.78235 sd:0.751298\n",
      "\t652: \"data:0.685\" NUMERICAL mean:-0.918817 min:-3.87972 max:2.26442 sd:0.827372\n",
      "\t653: \"data:0.686\" NUMERICAL mean:-0.603401 min:-2.83337 max:1.84096 sd:0.522341\n",
      "\t654: \"data:0.687\" NUMERICAL mean:-0.096918 min:-2.70899 max:2.57764 sd:0.629999\n",
      "\t655: \"data:0.688\" NUMERICAL mean:0.0255329 min:-2.40442 max:2.25462 sd:0.549649\n",
      "\t656: \"data:0.689\" NUMERICAL mean:0.233277 min:-2.32813 max:2.9343 sd:0.615747\n",
      "\t657: \"data:0.69\" NUMERICAL mean:-0.00302295 min:-2.47949 max:2.53215 sd:0.550592\n",
      "\t658: \"data:0.690\" NUMERICAL mean:0.405425 min:-1.89935 max:3.25049 sd:0.619203\n",
      "\t659: \"data:0.691\" NUMERICAL mean:-0.325753 min:-2.39681 max:1.98942 sd:0.533128\n",
      "\t660: \"data:0.692\" NUMERICAL mean:-0.197243 min:-3.23007 max:2.92535 sd:0.683898\n",
      "\t661: \"data:0.693\" NUMERICAL mean:0.059361 min:-2.25016 max:2.71678 sd:0.581339\n",
      "\t662: \"data:0.694\" NUMERICAL mean:0.135836 min:-2.78777 max:2.65673 sd:0.63316\n",
      "\t663: \"data:0.695\" NUMERICAL mean:0.398583 min:-2.14437 max:2.95464 sd:0.609037\n",
      "\t664: \"data:0.696\" NUMERICAL mean:0.717955 min:-1.99055 max:3.9231 sd:0.680161\n",
      "\t665: \"data:0.697\" NUMERICAL mean:-0.121662 min:-3.08106 max:2.38332 sd:0.642454\n",
      "\t666: \"data:0.698\" NUMERICAL mean:0.912885 min:-2.14085 max:3.46199 sd:0.619163\n",
      "\t667: \"data:0.699\" NUMERICAL mean:0.403267 min:-2.90778 max:3.21758 sd:0.651555\n",
      "\t668: \"data:0.7\" NUMERICAL mean:1.29196 min:-1.59813 max:3.88705 sd:0.63411\n",
      "\t669: \"data:0.70\" NUMERICAL mean:0.222652 min:-2.14099 max:3.31524 sd:0.63756\n",
      "\t670: \"data:0.700\" NUMERICAL mean:-0.125453 min:-2.72741 max:2.69861 sd:0.592304\n",
      "\t671: \"data:0.701\" NUMERICAL mean:-0.0187762 min:-2.87311 max:2.91919 sd:0.628876\n",
      "\t672: \"data:0.702\" NUMERICAL mean:0.548617 min:-2.46372 max:4.18464 sd:0.805943\n",
      "\t673: \"data:0.703\" NUMERICAL mean:0.276951 min:-2.19767 max:2.68989 sd:0.615604\n",
      "\t674: \"data:0.704\" NUMERICAL mean:-0.29559 min:-3.05099 max:2.5032 sd:0.614158\n",
      "\t675: \"data:0.705\" NUMERICAL mean:0.588779 min:-2.05254 max:3.65171 sd:0.638763\n",
      "\t676: \"data:0.706\" NUMERICAL mean:-0.476483 min:-2.84456 max:2.44058 sd:0.615079\n",
      "\t677: \"data:0.707\" NUMERICAL mean:-0.0120187 min:-3.03809 max:3.3019 sd:0.744131\n",
      "\t678: \"data:0.708\" NUMERICAL mean:-0.173717 min:-2.83644 max:2.57114 sd:0.600217\n",
      "\t679: \"data:0.709\" NUMERICAL mean:-0.863086 min:-3.38749 max:1.80875 sd:0.564095\n",
      "\t680: \"data:0.71\" NUMERICAL mean:0.884227 min:-1.80587 max:3.62654 sd:0.706801\n",
      "\t681: \"data:0.710\" NUMERICAL mean:0.723621 min:-1.79952 max:3.10781 sd:0.557981\n",
      "\t682: \"data:0.711\" NUMERICAL mean:0.242307 min:-2.60913 max:2.96986 sd:0.708924\n",
      "\t683: \"data:0.712\" NUMERICAL mean:-0.166139 min:-2.77707 max:2.5156 sd:0.614011\n",
      "\t684: \"data:0.713\" NUMERICAL mean:0.637041 min:-2.30796 max:3.4931 sd:0.689465\n",
      "\t685: \"data:0.714\" NUMERICAL mean:-0.283479 min:-2.67507 max:2.49158 sd:0.638249\n",
      "\t686: \"data:0.715\" NUMERICAL mean:0.652393 min:-2.44661 max:3.37945 sd:0.721877\n",
      "\t687: \"data:0.716\" NUMERICAL mean:-0.0992701 min:-2.44064 max:2.39464 sd:0.556501\n",
      "\t688: \"data:0.717\" NUMERICAL mean:-0.0336037 min:-3.15551 max:3.12689 sd:0.734392\n",
      "\t689: \"data:0.718\" NUMERICAL mean:0.277957 min:-2.2393 max:2.70681 sd:0.585282\n",
      "\t690: \"data:0.719\" NUMERICAL mean:-0.23834 min:-3.1806 max:2.15263 sd:0.585619\n",
      "\t691: \"data:0.72\" NUMERICAL mean:-0.400469 min:-3.02261 max:2.50136 sd:0.589975\n",
      "\t692: \"data:0.720\" NUMERICAL mean:0.309182 min:-1.84987 max:2.88494 sd:0.565192\n",
      "\t693: \"data:0.721\" NUMERICAL mean:0.501512 min:-2.1155 max:2.75916 sd:0.613436\n",
      "\t694: \"data:0.722\" NUMERICAL mean:-0.538614 min:-3.2594 max:2.04441 sd:0.656387\n",
      "\t695: \"data:0.723\" NUMERICAL mean:-0.183191 min:-2.80225 max:2.66983 sd:0.64022\n",
      "\t696: \"data:0.724\" NUMERICAL mean:-0.628293 min:-3.21298 max:1.59684 sd:0.617298\n",
      "\t697: \"data:0.725\" NUMERICAL mean:-0.211182 min:-2.51853 max:2.38151 sd:0.590603\n",
      "\t698: \"data:0.726\" NUMERICAL mean:0.279043 min:-2.48875 max:2.86902 sd:0.660443\n",
      "\t699: \"data:0.727\" NUMERICAL mean:-0.397715 min:-2.97511 max:2.35682 sd:0.611996\n",
      "\t700: \"data:0.728\" NUMERICAL mean:0.124091 min:-2.65575 max:3.01802 sd:0.660605\n",
      "\t701: \"data:0.729\" NUMERICAL mean:-0.237788 min:-2.66336 max:2.25312 sd:0.556295\n",
      "\t702: \"data:0.73\" NUMERICAL mean:-0.12733 min:-2.4514 max:2.47705 sd:0.589084\n",
      "\t703: \"data:0.730\" NUMERICAL mean:-0.0320515 min:-2.84438 max:2.89752 sd:0.687569\n",
      "\t704: \"data:0.731\" NUMERICAL mean:0.29979 min:-2.95857 max:3.45225 sd:0.863997\n",
      "\t705: \"data:0.732\" NUMERICAL mean:0.576322 min:-2.03613 max:2.89175 sd:0.59801\n",
      "\t706: \"data:0.733\" NUMERICAL mean:0.766551 min:-1.95669 max:3.30423 sd:0.594623\n",
      "\t707: \"data:0.734\" NUMERICAL mean:-0.598308 min:-3.36817 max:2.26674 sd:0.636811\n",
      "\t708: \"data:0.735\" NUMERICAL mean:-1.01656 min:-3.46673 max:1.47443 sd:0.55785\n",
      "\t709: \"data:0.736\" NUMERICAL mean:0.699642 min:-2.19916 max:3.48776 sd:0.761437\n",
      "\t710: \"data:0.737\" NUMERICAL mean:0.48673 min:-1.83682 max:3.48293 sd:0.567977\n",
      "\t711: \"data:0.738\" NUMERICAL mean:1.20812 min:-1.56213 max:3.63055 sd:0.68127\n",
      "\t712: \"data:0.739\" NUMERICAL mean:0.156306 min:-2.36778 max:2.96499 sd:0.599258\n",
      "\t713: \"data:0.74\" NUMERICAL mean:0.645148 min:-1.66897 max:3.57055 sd:0.59418\n",
      "\t714: \"data:0.740\" NUMERICAL mean:-0.0721625 min:-2.50139 max:2.69372 sd:0.626032\n",
      "\t715: \"data:0.741\" NUMERICAL mean:-0.120432 min:-2.67845 max:2.67007 sd:0.63813\n",
      "\t716: \"data:0.742\" NUMERICAL mean:-0.75907 min:-3.17897 max:2.42122 sd:0.660101\n",
      "\t717: \"data:0.743\" NUMERICAL mean:0.360996 min:-2.06585 max:2.86409 sd:0.562558\n",
      "\t718: \"data:0.744\" NUMERICAL mean:0.263218 min:-1.88236 max:3.12067 sd:0.540958\n",
      "\t719: \"data:0.745\" NUMERICAL mean:-0.0482615 min:-2.73952 max:2.68839 sd:0.609624\n",
      "\t720: \"data:0.746\" NUMERICAL mean:-0.289971 min:-2.89832 max:2.6733 sd:0.615085\n",
      "\t721: \"data:0.747\" NUMERICAL mean:-0.223241 min:-3.04388 max:2.49026 sd:0.57169\n",
      "\t722: \"data:0.748\" NUMERICAL mean:0.878284 min:-1.41999 max:3.15731 sd:0.582817\n",
      "\t723: \"data:0.749\" NUMERICAL mean:0.176571 min:-1.92281 max:2.82301 sd:0.526958\n",
      "\t724: \"data:0.75\" NUMERICAL mean:0.219837 min:-2.42226 max:3.18433 sd:0.565228\n",
      "\t725: \"data:0.750\" NUMERICAL mean:-0.26298 min:-3.22569 max:2.27036 sd:0.625794\n",
      "\t726: \"data:0.751\" NUMERICAL mean:-0.317348 min:-3.03944 max:2.4522 sd:0.629476\n",
      "\t727: \"data:0.752\" NUMERICAL mean:0.515381 min:-1.90112 max:2.6863 sd:0.573985\n",
      "\t728: \"data:0.753\" NUMERICAL mean:0.634719 min:-2.10373 max:3.62188 sd:0.683932\n",
      "\t729: \"data:0.754\" NUMERICAL mean:-0.442764 min:-3.29284 max:2.27784 sd:0.717348\n",
      "\t730: \"data:0.755\" NUMERICAL mean:-0.619834 min:-2.84911 max:1.81759 sd:0.56369\n",
      "\t731: \"data:0.756\" NUMERICAL mean:0.594599 min:-2.14223 max:3.27784 sd:0.619741\n",
      "\t732: \"data:0.757\" NUMERICAL mean:0.582327 min:-1.89748 max:3.2896 sd:0.598005\n",
      "\t733: \"data:0.758\" NUMERICAL mean:0.0839506 min:-2.56692 max:3.40631 sd:0.755404\n",
      "\t734: \"data:0.759\" NUMERICAL mean:0.397092 min:-3.0001 max:3.03555 sd:0.778377\n",
      "\t735: \"data:0.76\" NUMERICAL mean:0.270916 min:-2.93221 max:2.79989 sd:0.634873\n",
      "\t736: \"data:0.760\" NUMERICAL mean:-0.495495 min:-2.98804 max:1.81202 sd:0.586357\n",
      "\t737: \"data:0.761\" NUMERICAL mean:0.363018 min:-2.6477 max:3.48247 sd:0.69617\n",
      "\t738: \"data:0.762\" NUMERICAL mean:0.297685 min:-2.10076 max:2.68014 sd:0.536802\n",
      "\t739: \"data:0.763\" NUMERICAL mean:-0.349768 min:-2.58229 max:2.12222 sd:0.517567\n",
      "\t740: \"data:0.764\" NUMERICAL mean:-0.645529 min:-2.85372 max:1.65806 sd:0.531488\n",
      "\t741: \"data:0.765\" NUMERICAL mean:0.0941493 min:-3.24824 max:2.73867 sd:0.667128\n",
      "\t742: \"data:0.766\" NUMERICAL mean:-0.214638 min:-2.88311 max:2.14607 sd:0.57054\n",
      "\t743: \"data:0.767\" NUMERICAL mean:0.420249 min:-2.12437 max:2.83038 sd:0.548274\n",
      "\t744: \"data:0.77\" NUMERICAL mean:-0.29353 min:-2.70436 max:2.54317 sd:0.568369\n",
      "\t745: \"data:0.78\" NUMERICAL mean:0.0847665 min:-2.60056 max:2.82025 sd:0.619038\n",
      "\t746: \"data:0.79\" NUMERICAL mean:1.15293 min:-1.58272 max:3.83116 sd:0.602898\n",
      "\t747: \"data:0.8\" NUMERICAL mean:-0.0489443 min:-2.53798 max:2.36162 sd:0.568642\n",
      "\t748: \"data:0.80\" NUMERICAL mean:-0.275628 min:-3.02693 max:2.29798 sd:0.566785\n",
      "\t749: \"data:0.81\" NUMERICAL mean:0.297838 min:-2.39504 max:3.15666 sd:0.661035\n",
      "\t750: \"data:0.82\" NUMERICAL mean:-0.492329 min:-3.13849 max:1.99659 sd:0.575321\n",
      "\t751: \"data:0.83\" NUMERICAL mean:0.00686406 min:-3.19425 max:2.58797 sd:0.648849\n",
      "\t752: \"data:0.84\" NUMERICAL mean:0.0481643 min:-2.65369 max:3.43977 sd:0.582949\n",
      "\t753: \"data:0.85\" NUMERICAL mean:-0.644299 min:-3.44768 max:2.04543 sd:0.623164\n",
      "\t754: \"data:0.86\" NUMERICAL mean:0.516982 min:-1.95128 max:3.09716 sd:0.634473\n",
      "\t755: \"data:0.87\" NUMERICAL mean:0.0751956 min:-2.92437 max:2.68469 sd:0.596519\n",
      "\t756: \"data:0.88\" NUMERICAL mean:0.270867 min:-2.01097 max:2.94419 sd:0.597645\n",
      "\t757: \"data:0.89\" NUMERICAL mean:-0.155586 min:-2.34452 max:2.51408 sd:0.588374\n",
      "\t758: \"data:0.9\" NUMERICAL mean:-0.639125 min:-3.27203 max:1.57787 sd:0.529212\n",
      "\t759: \"data:0.90\" NUMERICAL mean:-0.21689 min:-2.68633 max:2.5881 sd:0.582544\n",
      "\t760: \"data:0.91\" NUMERICAL mean:0.0173536 min:-3.12875 max:2.71507 sd:0.663258\n",
      "\t761: \"data:0.92\" NUMERICAL mean:-0.492454 min:-2.91436 max:2.4915 sd:0.795318\n",
      "\t762: \"data:0.93\" NUMERICAL mean:-0.706659 min:-3.47404 max:2.08261 sd:0.653737\n",
      "\t763: \"data:0.94\" NUMERICAL mean:0.22892 min:-2.03657 max:2.66793 sd:0.555669\n",
      "\t764: \"data:0.95\" NUMERICAL mean:-0.92903 min:-3.44127 max:1.6223 sd:0.599047\n",
      "\t765: \"data:0.96\" NUMERICAL mean:-2.57602 min:-7.10173 max:0.886333 sd:1.06119\n",
      "\t766: \"data:0.97\" NUMERICAL mean:-0.380972 min:-2.59809 max:2.18504 sd:0.550538\n",
      "\t767: \"data:0.98\" NUMERICAL mean:-0.433947 min:-2.88435 max:1.79922 sd:0.568376\n",
      "\t768: \"data:0.99\" NUMERICAL mean:0.297676 min:-2.79936 max:3.19091 sd:0.838888\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 23-05-23 13:42:17.6151 EEST kernel.cc:810] Configure learner\n",
      "[WARNING 23-05-23 13:42:17.6153 EEST gradient_boosted_trees.cc:1797] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-05-23 13:42:17.6153 EEST gradient_boosted_trees.cc:1808] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-05-23 13:42:17.6153 EEST gradient_boosted_trees.cc:1822] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 23-05-23 13:42:17.6154 EEST kernel.cc:824] Training config:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0\\\\.0$\"\n",
      "features: \"^data:0\\\\.1$\"\n",
      "features: \"^data:0\\\\.10$\"\n",
      "features: \"^data:0\\\\.100$\"\n",
      "features: \"^data:0\\\\.101$\"\n",
      "features: \"^data:0\\\\.102$\"\n",
      "features: \"^data:0\\\\.103$\"\n",
      "features: \"^data:0\\\\.104$\"\n",
      "features: \"^data:0\\\\.105$\"\n",
      "features: \"^data:0\\\\.106$\"\n",
      "features: \"^data:0\\\\.107$\"\n",
      "features: \"^data:0\\\\.108$\"\n",
      "features: \"^data:0\\\\.109$\"\n",
      "features: \"^data:0\\\\.11$\"\n",
      "features: \"^data:0\\\\.110$\"\n",
      "features: \"^data:0\\\\.111$\"\n",
      "features: \"^data:0\\\\.112$\"\n",
      "features: \"^data:0\\\\.113$\"\n",
      "features: \"^data:0\\\\.114$\"\n",
      "features: \"^data:0\\\\.115$\"\n",
      "features: \"^data:0\\\\.116$\"\n",
      "features: \"^data:0\\\\.117$\"\n",
      "features: \"^data:0\\\\.118$\"\n",
      "features: \"^data:0\\\\.119$\"\n",
      "features: \"^data:0\\\\.12$\"\n",
      "features: \"^data:0\\\\.120$\"\n",
      "features: \"^data:0\\\\.121$\"\n",
      "features: \"^data:0\\\\.122$\"\n",
      "features: \"^data:0\\\\.123$\"\n",
      "features: \"^data:0\\\\.124$\"\n",
      "features: \"^data:0\\\\.125$\"\n",
      "features: \"^data:0\\\\.126$\"\n",
      "features: \"^data:0\\\\.127$\"\n",
      "features: \"^data:0\\\\.128$\"\n",
      "features: \"^data:0\\\\.129$\"\n",
      "features: \"^data:0\\\\.13$\"\n",
      "features: \"^data:0\\\\.130$\"\n",
      "features: \"^data:0\\\\.131$\"\n",
      "features: \"^data:0\\\\.132$\"\n",
      "features: \"^data:0\\\\.133$\"\n",
      "features: \"^data:0\\\\.134$\"\n",
      "features: \"^data:0\\\\.135$\"\n",
      "features: \"^data:0\\\\.136$\"\n",
      "features: \"^data:0\\\\.137$\"\n",
      "features: \"^data:0\\\\.138$\"\n",
      "features: \"^data:0\\\\.139$\"\n",
      "features: \"^data:0\\\\.14$\"\n",
      "features: \"^data:0\\\\.140$\"\n",
      "features: \"^data:0\\\\.141$\"\n",
      "features: \"^data:0\\\\.142$\"\n",
      "features: \"^data:0\\\\.143$\"\n",
      "features: \"^data:0\\\\.144$\"\n",
      "features: \"^data:0\\\\.145$\"\n",
      "features: \"^data:0\\\\.146$\"\n",
      "features: \"^data:0\\\\.147$\"\n",
      "features: \"^data:0\\\\.148$\"\n",
      "features: \"^data:0\\\\.149$\"\n",
      "features: \"^data:0\\\\.15$\"\n",
      "features: \"^data:0\\\\.150$\"\n",
      "features: \"^data:0\\\\.151$\"\n",
      "features: \"^data:0\\\\.152$\"\n",
      "features: \"^data:0\\\\.153$\"\n",
      "features: \"^data:0\\\\.154$\"\n",
      "features: \"^data:0\\\\.155$\"\n",
      "features: \"^data:0\\\\.156$\"\n",
      "features: \"^data:0\\\\.157$\"\n",
      "features: \"^data:0\\\\.158$\"\n",
      "features: \"^data:0\\\\.159$\"\n",
      "features: \"^data:0\\\\.16$\"\n",
      "features: \"^data:0\\\\.160$\"\n",
      "features: \"^data:0\\\\.161$\"\n",
      "features: \"^data:0\\\\.162$\"\n",
      "features: \"^data:0\\\\.163$\"\n",
      "features: \"^data:0\\\\.164$\"\n",
      "features: \"^data:0\\\\.165$\"\n",
      "features: \"^data:0\\\\.166$\"\n",
      "features: \"^data:0\\\\.167$\"\n",
      "features: \"^data:0\\\\.168$\"\n",
      "features: \"^data:0\\\\.169$\"\n",
      "features: \"^data:0\\\\.17$\"\n",
      "features: \"^data:0\\\\.170$\"\n",
      "features: \"^data:0\\\\.171$\"\n",
      "features: \"^data:0\\\\.172$\"\n",
      "features: \"^data:0\\\\.173$\"\n",
      "features: \"^data:0\\\\.174$\"\n",
      "features: \"^data:0\\\\.175$\"\n",
      "features: \"^data:0\\\\.176$\"\n",
      "features: \"^data:0\\\\.177$\"\n",
      "features: \"^data:0\\\\.178$\"\n",
      "features: \"^data:0\\\\.179$\"\n",
      "features: \"^data:0\\\\.18$\"\n",
      "features: \"^data:0\\\\.180$\"\n",
      "features: \"^data:0\\\\.181$\"\n",
      "features: \"^data:0\\\\.182$\"\n",
      "features: \"^data:0\\\\.183$\"\n",
      "features: \"^data:0\\\\.184$\"\n",
      "features: \"^data:0\\\\.185$\"\n",
      "features: \"^data:0\\\\.186$\"\n",
      "features: \"^data:0\\\\.187$\"\n",
      "features: \"^data:0\\\\.188$\"\n",
      "features: \"^data:0\\\\.189$\"\n",
      "features: \"^data:0\\\\.19$\"\n",
      "features: \"^data:0\\\\.190$\"\n",
      "features: \"^data:0\\\\.191$\"\n",
      "features: \"^data:0\\\\.192$\"\n",
      "features: \"^data:0\\\\.193$\"\n",
      "features: \"^data:0\\\\.194$\"\n",
      "features: \"^data:0\\\\.195$\"\n",
      "features: \"^data:0\\\\.196$\"\n",
      "features: \"^data:0\\\\.197$\"\n",
      "features: \"^data:0\\\\.198$\"\n",
      "features: \"^data:0\\\\.199$\"\n",
      "features: \"^data:0\\\\.2$\"\n",
      "features: \"^data:0\\\\.20$\"\n",
      "features: \"^data:0\\\\.200$\"\n",
      "features: \"^data:0\\\\.201$\"\n",
      "features: \"^data:0\\\\.202$\"\n",
      "features: \"^data:0\\\\.203$\"\n",
      "features: \"^data:0\\\\.204$\"\n",
      "features: \"^data:0\\\\.205$\"\n",
      "features: \"^data:0\\\\.206$\"\n",
      "features: \"^data:0\\\\.207$\"\n",
      "features: \"^data:0\\\\.208$\"\n",
      "features: \"^data:0\\\\.209$\"\n",
      "features: \"^data:0\\\\.21$\"\n",
      "features: \"^data:0\\\\.210$\"\n",
      "features: \"^data:0\\\\.211$\"\n",
      "features: \"^data:0\\\\.212$\"\n",
      "features: \"^data:0\\\\.213$\"\n",
      "features: \"^data:0\\\\.214$\"\n",
      "features: \"^data:0\\\\.215$\"\n",
      "features: \"^data:0\\\\.216$\"\n",
      "features: \"^data:0\\\\.217$\"\n",
      "features: \"^data:0\\\\.218$\"\n",
      "features: \"^data:0\\\\.219$\"\n",
      "features: \"^data:0\\\\.22$\"\n",
      "features: \"^data:0\\\\.220$\"\n",
      "features: \"^data:0\\\\.221$\"\n",
      "features: \"^data:0\\\\.222$\"\n",
      "features: \"^data:0\\\\.223$\"\n",
      "features: \"^data:0\\\\.224$\"\n",
      "features: \"^data:0\\\\.225$\"\n",
      "features: \"^data:0\\\\.226$\"\n",
      "features: \"^data:0\\\\.227$\"\n",
      "features: \"^data:0\\\\.228$\"\n",
      "features: \"^data:0\\\\.229$\"\n",
      "features: \"^data:0\\\\.23$\"\n",
      "features: \"^data:0\\\\.230$\"\n",
      "features: \"^data:0\\\\.231$\"\n",
      "features: \"^data:0\\\\.232$\"\n",
      "features: \"^data:0\\\\.233$\"\n",
      "features: \"^data:0\\\\.234$\"\n",
      "features: \"^data:0\\\\.235$\"\n",
      "features: \"^data:0\\\\.236$\"\n",
      "features: \"^data:0\\\\.237$\"\n",
      "features: \"^data:0\\\\.238$\"\n",
      "features: \"^data:0\\\\.239$\"\n",
      "features: \"^data:0\\\\.24$\"\n",
      "features: \"^data:0\\\\.240$\"\n",
      "features: \"^data:0\\\\.241$\"\n",
      "features: \"^data:0\\\\.242$\"\n",
      "features: \"^data:0\\\\.243$\"\n",
      "features: \"^data:0\\\\.244$\"\n",
      "features: \"^data:0\\\\.245$\"\n",
      "features: \"^data:0\\\\.246$\"\n",
      "features: \"^data:0\\\\.247$\"\n",
      "features: \"^data:0\\\\.248$\"\n",
      "features: \"^data:0\\\\.249$\"\n",
      "features: \"^data:0\\\\.25$\"\n",
      "features: \"^data:0\\\\.250$\"\n",
      "features: \"^data:0\\\\.251$\"\n",
      "features: \"^data:0\\\\.252$\"\n",
      "features: \"^data:0\\\\.253$\"\n",
      "features: \"^data:0\\\\.254$\"\n",
      "features: \"^data:0\\\\.255$\"\n",
      "features: \"^data:0\\\\.256$\"\n",
      "features: \"^data:0\\\\.257$\"\n",
      "features: \"^data:0\\\\.258$\"\n",
      "features: \"^data:0\\\\.259$\"\n",
      "features: \"^data:0\\\\.26$\"\n",
      "features: \"^data:0\\\\.260$\"\n",
      "features: \"^data:0\\\\.261$\"\n",
      "features: \"^data:0\\\\.262$\"\n",
      "features: \"^data:0\\\\.263$\"\n",
      "features: \"^data:0\\\\.264$\"\n",
      "features: \"^data:0\\\\.265$\"\n",
      "features: \"^data:0\\\\.266$\"\n",
      "features: \"^data:0\\\\.267$\"\n",
      "features: \"^data:0\\\\.268$\"\n",
      "features: \"^data:0\\\\.269$\"\n",
      "features: \"^data:0\\\\.27$\"\n",
      "features: \"^data:0\\\\.270$\"\n",
      "features: \"^data:0\\\\.271$\"\n",
      "features: \"^data:0\\\\.272$\"\n",
      "features: \"^data:0\\\\.273$\"\n",
      "features: \"^data:0\\\\.274$\"\n",
      "features: \"^data:0\\\\.275$\"\n",
      "features: \"^data:0\\\\.276$\"\n",
      "features: \"^data:0\\\\.277$\"\n",
      "features: \"^data:0\\\\.278$\"\n",
      "features: \"^data:0\\\\.279$\"\n",
      "features: \"^data:0\\\\.28$\"\n",
      "features: \"^data:0\\\\.280$\"\n",
      "features: \"^data:0\\\\.281$\"\n",
      "features: \"^data:0\\\\.282$\"\n",
      "features: \"^data:0\\\\.283$\"\n",
      "features: \"^data:0\\\\.284$\"\n",
      "features: \"^data:0\\\\.285$\"\n",
      "features: \"^data:0\\\\.286$\"\n",
      "features: \"^data:0\\\\.287$\"\n",
      "features: \"^data:0\\\\.288$\"\n",
      "features: \"^data:0\\\\.289$\"\n",
      "features: \"^data:0\\\\.29$\"\n",
      "features: \"^data:0\\\\.290$\"\n",
      "features: \"^data:0\\\\.291$\"\n",
      "features: \"^data:0\\\\.292$\"\n",
      "features: \"^data:0\\\\.293$\"\n",
      "features: \"^data:0\\\\.294$\"\n",
      "features: \"^data:0\\\\.295$\"\n",
      "features: \"^data:0\\\\.296$\"\n",
      "features: \"^data:0\\\\.297$\"\n",
      "features: \"^data:0\\\\.298$\"\n",
      "features: \"^data:0\\\\.299$\"\n",
      "features: \"^data:0\\\\.3$\"\n",
      "features: \"^data:0\\\\.30$\"\n",
      "features: \"^data:0\\\\.300$\"\n",
      "features: \"^data:0\\\\.301$\"\n",
      "features: \"^data:0\\\\.302$\"\n",
      "features: \"^data:0\\\\.303$\"\n",
      "features: \"^data:0\\\\.304$\"\n",
      "features: \"^data:0\\\\.305$\"\n",
      "features: \"^data:0\\\\.306$\"\n",
      "features: \"^data:0\\\\.307$\"\n",
      "features: \"^data:0\\\\.308$\"\n",
      "features: \"^data:0\\\\.309$\"\n",
      "features: \"^data:0\\\\.31$\"\n",
      "features: \"^data:0\\\\.310$\"\n",
      "features: \"^data:0\\\\.311$\"\n",
      "features: \"^data:0\\\\.312$\"\n",
      "features: \"^data:0\\\\.313$\"\n",
      "features: \"^data:0\\\\.314$\"\n",
      "features: \"^data:0\\\\.315$\"\n",
      "features: \"^data:0\\\\.316$\"\n",
      "features: \"^data:0\\\\.317$\"\n",
      "features: \"^data:0\\\\.318$\"\n",
      "features: \"^data:0\\\\.319$\"\n",
      "features: \"^data:0\\\\.32$\"\n",
      "features: \"^data:0\\\\.320$\"\n",
      "features: \"^data:0\\\\.321$\"\n",
      "features: \"^data:0\\\\.322$\"\n",
      "features: \"^data:0\\\\.323$\"\n",
      "features: \"^data:0\\\\.324$\"\n",
      "features: \"^data:0\\\\.325$\"\n",
      "features: \"^data:0\\\\.326$\"\n",
      "features: \"^data:0\\\\.327$\"\n",
      "features: \"^data:0\\\\.328$\"\n",
      "features: \"^data:0\\\\.329$\"\n",
      "features: \"^data:0\\\\.33$\"\n",
      "features: \"^data:0\\\\.330$\"\n",
      "features: \"^data:0\\\\.331$\"\n",
      "features: \"^data:0\\\\.332$\"\n",
      "features: \"^data:0\\\\.333$\"\n",
      "features: \"^data:0\\\\.334$\"\n",
      "features: \"^data:0\\\\.335$\"\n",
      "features: \"^data:0\\\\.336$\"\n",
      "features: \"^data:0\\\\.337$\"\n",
      "features: \"^data:0\\\\.338$\"\n",
      "features: \"^data:0\\\\.339$\"\n",
      "features: \"^data:0\\\\.34$\"\n",
      "features: \"^data:0\\\\.340$\"\n",
      "features: \"^data:0\\\\.341$\"\n",
      "features: \"^data:0\\\\.342$\"\n",
      "features: \"^data:0\\\\.343$\"\n",
      "features: \"^data:0\\\\.344$\"\n",
      "features: \"^data:0\\\\.345$\"\n",
      "features: \"^data:0\\\\.346$\"\n",
      "features: \"^data:0\\\\.347$\"\n",
      "features: \"^data:0\\\\.348$\"\n",
      "features: \"^data:0\\\\.349$\"\n",
      "features: \"^data:0\\\\.35$\"\n",
      "features: \"^data:0\\\\.350$\"\n",
      "features: \"^data:0\\\\.351$\"\n",
      "features: \"^data:0\\\\.352$\"\n",
      "features: \"^data:0\\\\.353$\"\n",
      "features: \"^data:0\\\\.354$\"\n",
      "features: \"^data:0\\\\.355$\"\n",
      "features: \"^data:0\\\\.356$\"\n",
      "features: \"^data:0\\\\.357$\"\n",
      "features: \"^data:0\\\\.358$\"\n",
      "features: \"^data:0\\\\.359$\"\n",
      "features: \"^data:0\\\\.36$\"\n",
      "features: \"^data:0\\\\.360$\"\n",
      "features: \"^data:0\\\\.361$\"\n",
      "features: \"^data:0\\\\.362$\"\n",
      "features: \"^data:0\\\\.363$\"\n",
      "features: \"^data:0\\\\.364$\"\n",
      "features: \"^data:0\\\\.365$\"\n",
      "features: \"^data:0\\\\.366$\"\n",
      "features: \"^data:0\\\\.367$\"\n",
      "features: \"^data:0\\\\.368$\"\n",
      "features: \"^data:0\\\\.369$\"\n",
      "features: \"^data:0\\\\.37$\"\n",
      "features: \"^data:0\\\\.370$\"\n",
      "features: \"^data:0\\\\.371$\"\n",
      "features: \"^data:0\\\\.372$\"\n",
      "features: \"^data:0\\\\.373$\"\n",
      "features: \"^data:0\\\\.374$\"\n",
      "features: \"^data:0\\\\.375$\"\n",
      "features: \"^data:0\\\\.376$\"\n",
      "features: \"^data:0\\\\.377$\"\n",
      "features: \"^data:0\\\\.378$\"\n",
      "features: \"^data:0\\\\.379$\"\n",
      "features: \"^data:0\\\\.38$\"\n",
      "features: \"^data:0\\\\.380$\"\n",
      "features: \"^data:0\\\\.381$\"\n",
      "features: \"^data:0\\\\.382$\"\n",
      "features: \"^data:0\\\\.383$\"\n",
      "features: \"^data:0\\\\.384$\"\n",
      "features: \"^data:0\\\\.385$\"\n",
      "features: \"^data:0\\\\.386$\"\n",
      "features: \"^data:0\\\\.387$\"\n",
      "features: \"^data:0\\\\.388$\"\n",
      "features: \"^data:0\\\\.389$\"\n",
      "features: \"^data:0\\\\.39$\"\n",
      "features: \"^data:0\\\\.390$\"\n",
      "features: \"^data:0\\\\.391$\"\n",
      "features: \"^data:0\\\\.392$\"\n",
      "features: \"^data:0\\\\.393$\"\n",
      "features: \"^data:0\\\\.394$\"\n",
      "features: \"^data:0\\\\.395$\"\n",
      "features: \"^data:0\\\\.396$\"\n",
      "features: \"^data:0\\\\.397$\"\n",
      "features: \"^data:0\\\\.398$\"\n",
      "features: \"^data:0\\\\.399$\"\n",
      "features: \"^data:0\\\\.4$\"\n",
      "features: \"^data:0\\\\.40$\"\n",
      "features: \"^data:0\\\\.400$\"\n",
      "features: \"^data:0\\\\.401$\"\n",
      "features: \"^data:0\\\\.402$\"\n",
      "features: \"^data:0\\\\.403$\"\n",
      "features: \"^data:0\\\\.404$\"\n",
      "features: \"^data:0\\\\.405$\"\n",
      "features: \"^data:0\\\\.406$\"\n",
      "features: \"^data:0\\\\.407$\"\n",
      "features: \"^data:0\\\\.408$\"\n",
      "features: \"^data:0\\\\.409$\"\n",
      "features: \"^data:0\\\\.41$\"\n",
      "features: \"^data:0\\\\.410$\"\n",
      "features: \"^data:0\\\\.411$\"\n",
      "features: \"^data:0\\\\.412$\"\n",
      "features: \"^data:0\\\\.413$\"\n",
      "features: \"^data:0\\\\.414$\"\n",
      "features: \"^data:0\\\\.415$\"\n",
      "features: \"^data:0\\\\.416$\"\n",
      "features: \"^data:0\\\\.417$\"\n",
      "features: \"^data:0\\\\.418$\"\n",
      "features: \"^data:0\\\\.419$\"\n",
      "features: \"^data:0\\\\.42$\"\n",
      "features: \"^data:0\\\\.420$\"\n",
      "features: \"^data:0\\\\.421$\"\n",
      "features: \"^data:0\\\\.422$\"\n",
      "features: \"^data:0\\\\.423$\"\n",
      "features: \"^data:0\\\\.424$\"\n",
      "features: \"^data:0\\\\.425$\"\n",
      "features: \"^data:0\\\\.426$\"\n",
      "features: \"^data:0\\\\.427$\"\n",
      "features: \"^data:0\\\\.428$\"\n",
      "features: \"^data:0\\\\.429$\"\n",
      "features: \"^data:0\\\\.43$\"\n",
      "features: \"^data:0\\\\.430$\"\n",
      "features: \"^data:0\\\\.431$\"\n",
      "features: \"^data:0\\\\.432$\"\n",
      "features: \"^data:0\\\\.433$\"\n",
      "features: \"^data:0\\\\.434$\"\n",
      "features: \"^data:0\\\\.435$\"\n",
      "features: \"^data:0\\\\.436$\"\n",
      "features: \"^data:0\\\\.437$\"\n",
      "features: \"^data:0\\\\.438$\"\n",
      "features: \"^data:0\\\\.439$\"\n",
      "features: \"^data:0\\\\.44$\"\n",
      "features: \"^data:0\\\\.440$\"\n",
      "features: \"^data:0\\\\.441$\"\n",
      "features: \"^data:0\\\\.442$\"\n",
      "features: \"^data:0\\\\.443$\"\n",
      "features: \"^data:0\\\\.444$\"\n",
      "features: \"^data:0\\\\.445$\"\n",
      "features: \"^data:0\\\\.446$\"\n",
      "features: \"^data:0\\\\.447$\"\n",
      "features: \"^data:0\\\\.448$\"\n",
      "features: \"^data:0\\\\.449$\"\n",
      "features: \"^data:0\\\\.45$\"\n",
      "features: \"^data:0\\\\.450$\"\n",
      "features: \"^data:0\\\\.451$\"\n",
      "features: \"^data:0\\\\.452$\"\n",
      "features: \"^data:0\\\\.453$\"\n",
      "features: \"^data:0\\\\.454$\"\n",
      "features: \"^data:0\\\\.455$\"\n",
      "features: \"^data:0\\\\.456$\"\n",
      "features: \"^data:0\\\\.457$\"\n",
      "features: \"^data:0\\\\.458$\"\n",
      "features: \"^data:0\\\\.459$\"\n",
      "features: \"^data:0\\\\.46$\"\n",
      "features: \"^data:0\\\\.460$\"\n",
      "features: \"^data:0\\\\.461$\"\n",
      "features: \"^data:0\\\\.462$\"\n",
      "features: \"^data:0\\\\.463$\"\n",
      "features: \"^data:0\\\\.464$\"\n",
      "features: \"^data:0\\\\.465$\"\n",
      "features: \"^data:0\\\\.466$\"\n",
      "features: \"^data:0\\\\.467$\"\n",
      "features: \"^data:0\\\\.468$\"\n",
      "features: \"^data:0\\\\.469$\"\n",
      "features: \"^data:0\\\\.47$\"\n",
      "features: \"^data:0\\\\.470$\"\n",
      "features: \"^data:0\\\\.471$\"\n",
      "features: \"^data:0\\\\.472$\"\n",
      "features: \"^data:0\\\\.473$\"\n",
      "features: \"^data:0\\\\.474$\"\n",
      "features: \"^data:0\\\\.475$\"\n",
      "features: \"^data:0\\\\.476$\"\n",
      "features: \"^data:0\\\\.477$\"\n",
      "features: \"^data:0\\\\.478$\"\n",
      "features: \"^data:0\\\\.479$\"\n",
      "features: \"^data:0\\\\.48$\"\n",
      "features: \"^data:0\\\\.480$\"\n",
      "features: \"^data:0\\\\.481$\"\n",
      "features: \"^data:0\\\\.482$\"\n",
      "features: \"^data:0\\\\.483$\"\n",
      "features: \"^data:0\\\\.484$\"\n",
      "features: \"^data:0\\\\.485$\"\n",
      "features: \"^data:0\\\\.486$\"\n",
      "features: \"^data:0\\\\.487$\"\n",
      "features: \"^data:0\\\\.488$\"\n",
      "features: \"^data:0\\\\.489$\"\n",
      "features: \"^data:0\\\\.49$\"\n",
      "features: \"^data:0\\\\.490$\"\n",
      "features: \"^data:0\\\\.491$\"\n",
      "features: \"^data:0\\\\.492$\"\n",
      "features: \"^data:0\\\\.493$\"\n",
      "features: \"^data:0\\\\.494$\"\n",
      "features: \"^data:0\\\\.495$\"\n",
      "features: \"^data:0\\\\.496$\"\n",
      "features: \"^data:0\\\\.497$\"\n",
      "features: \"^data:0\\\\.498$\"\n",
      "features: \"^data:0\\\\.499$\"\n",
      "features: \"^data:0\\\\.5$\"\n",
      "features: \"^data:0\\\\.50$\"\n",
      "features: \"^data:0\\\\.500$\"\n",
      "features: \"^data:0\\\\.501$\"\n",
      "features: \"^data:0\\\\.502$\"\n",
      "features: \"^data:0\\\\.503$\"\n",
      "features: \"^data:0\\\\.504$\"\n",
      "features: \"^data:0\\\\.505$\"\n",
      "features: \"^data:0\\\\.506$\"\n",
      "features: \"^data:0\\\\.507$\"\n",
      "features: \"^data:0\\\\.508$\"\n",
      "features: \"^data:0\\\\.509$\"\n",
      "features: \"^data:0\\\\.51$\"\n",
      "features: \"^data:0\\\\.510$\"\n",
      "features: \"^data:0\\\\.511$\"\n",
      "features: \"^data:0\\\\.512$\"\n",
      "features: \"^data:0\\\\.513$\"\n",
      "features: \"^data:0\\\\.514$\"\n",
      "features: \"^data:0\\\\.515$\"\n",
      "features: \"^data:0\\\\.516$\"\n",
      "features: \"^data:0\\\\.517$\"\n",
      "features: \"^data:0\\\\.518$\"\n",
      "features: \"^data:0\\\\.519$\"\n",
      "features: \"^data:0\\\\.52$\"\n",
      "features: \"^data:0\\\\.520$\"\n",
      "features: \"^data:0\\\\.521$\"\n",
      "features: \"^data:0\\\\.522$\"\n",
      "features: \"^data:0\\\\.523$\"\n",
      "features: \"^data:0\\\\.524$\"\n",
      "features: \"^data:0\\\\.525$\"\n",
      "features: \"^data:0\\\\.526$\"\n",
      "features: \"^data:0\\\\.527$\"\n",
      "features: \"^data:0\\\\.528$\"\n",
      "features: \"^data:0\\\\.529$\"\n",
      "features: \"^data:0\\\\.53$\"\n",
      "features: \"^data:0\\\\.530$\"\n",
      "features: \"^data:0\\\\.531$\"\n",
      "features: \"^data:0\\\\.532$\"\n",
      "features: \"^data:0\\\\.533$\"\n",
      "features: \"^data:0\\\\.534$\"\n",
      "features: \"^data:0\\\\.535$\"\n",
      "features: \"^data:0\\\\.536$\"\n",
      "features: \"^data:0\\\\.537$\"\n",
      "features: \"^data:0\\\\.538$\"\n",
      "features: \"^data:0\\\\.539$\"\n",
      "features: \"^data:0\\\\.54$\"\n",
      "features: \"^data:0\\\\.540$\"\n",
      "features: \"^data:0\\\\.541$\"\n",
      "features: \"^data:0\\\\.542$\"\n",
      "features: \"^data:0\\\\.543$\"\n",
      "features: \"^data:0\\\\.544$\"\n",
      "features: \"^data:0\\\\.545$\"\n",
      "features: \"^data:0\\\\.546$\"\n",
      "features: \"^data:0\\\\.547$\"\n",
      "features: \"^data:0\\\\.548$\"\n",
      "features: \"^data:0\\\\.549$\"\n",
      "features: \"^data:0\\\\.55$\"\n",
      "features: \"^data:0\\\\.550$\"\n",
      "features: \"^data:0\\\\.551$\"\n",
      "features: \"^data:0\\\\.552$\"\n",
      "features: \"^data:0\\\\.553$\"\n",
      "features: \"^data:0\\\\.554$\"\n",
      "features: \"^data:0\\\\.555$\"\n",
      "features: \"^data:0\\\\.556$\"\n",
      "features: \"^data:0\\\\.557$\"\n",
      "features: \"^data:0\\\\.558$\"\n",
      "features: \"^data:0\\\\.559$\"\n",
      "features: \"^data:0\\\\.56$\"\n",
      "features: \"^data:0\\\\.560$\"\n",
      "features: \"^data:0\\\\.561$\"\n",
      "features: \"^data:0\\\\.562$\"\n",
      "features: \"^data:0\\\\.563$\"\n",
      "features: \"^data:0\\\\.564$\"\n",
      "features: \"^data:0\\\\.565$\"\n",
      "features: \"^data:0\\\\.566$\"\n",
      "features: \"^data:0\\\\.567$\"\n",
      "features: \"^data:0\\\\.568$\"\n",
      "features: \"^data:0\\\\.569$\"\n",
      "features: \"^data:0\\\\.57$\"\n",
      "features: \"^data:0\\\\.570$\"\n",
      "features: \"^data:0\\\\.571$\"\n",
      "features: \"^data:0\\\\.572$\"\n",
      "features: \"^data:0\\\\.573$\"\n",
      "features: \"^data:0\\\\.574$\"\n",
      "features: \"^data:0\\\\.575$\"\n",
      "features: \"^data:0\\\\.576$\"\n",
      "features: \"^data:0\\\\.577$\"\n",
      "features: \"^data:0\\\\.578$\"\n",
      "features: \"^data:0\\\\.579$\"\n",
      "features: \"^data:0\\\\.58$\"\n",
      "features: \"^data:0\\\\.580$\"\n",
      "features: \"^data:0\\\\.581$\"\n",
      "features: \"^data:0\\\\.582$\"\n",
      "features: \"^data:0\\\\.583$\"\n",
      "features: \"^data:0\\\\.584$\"\n",
      "features: \"^data:0\\\\.585$\"\n",
      "features: \"^data:0\\\\.586$\"\n",
      "features: \"^data:0\\\\.587$\"\n",
      "features: \"^data:0\\\\.588$\"\n",
      "features: \"^data:0\\\\.589$\"\n",
      "features: \"^data:0\\\\.59$\"\n",
      "features: \"^data:0\\\\.590$\"\n",
      "features: \"^data:0\\\\.591$\"\n",
      "features: \"^data:0\\\\.592$\"\n",
      "features: \"^data:0\\\\.593$\"\n",
      "features: \"^data:0\\\\.594$\"\n",
      "features: \"^data:0\\\\.595$\"\n",
      "features: \"^data:0\\\\.596$\"\n",
      "features: \"^data:0\\\\.597$\"\n",
      "features: \"^data:0\\\\.598$\"\n",
      "features: \"^data:0\\\\.599$\"\n",
      "features: \"^data:0\\\\.6$\"\n",
      "features: \"^data:0\\\\.60$\"\n",
      "features: \"^data:0\\\\.600$\"\n",
      "features: \"^data:0\\\\.601$\"\n",
      "features: \"^data:0\\\\.602$\"\n",
      "features: \"^data:0\\\\.603$\"\n",
      "features: \"^data:0\\\\.604$\"\n",
      "features: \"^data:0\\\\.605$\"\n",
      "features: \"^data:0\\\\.606$\"\n",
      "features: \"^data:0\\\\.607$\"\n",
      "features: \"^data:0\\\\.608$\"\n",
      "features: \"^data:0\\\\.609$\"\n",
      "features: \"^data:0\\\\.61$\"\n",
      "features: \"^data:0\\\\.610$\"\n",
      "features: \"^data:0\\\\.611$\"\n",
      "features: \"^data:0\\\\.612$\"\n",
      "features: \"^data:0\\\\.613$\"\n",
      "features: \"^data:0\\\\.614$\"\n",
      "features: \"^data:0\\\\.615$\"\n",
      "features: \"^data:0\\\\.616$\"\n",
      "features: \"^data:0\\\\.617$\"\n",
      "features: \"^data:0\\\\.618$\"\n",
      "features: \"^data:0\\\\.619$\"\n",
      "features: \"^data:0\\\\.62$\"\n",
      "features: \"^data:0\\\\.620$\"\n",
      "features: \"^data:0\\\\.621$\"\n",
      "features: \"^data:0\\\\.622$\"\n",
      "features: \"^data:0\\\\.623$\"\n",
      "features: \"^data:0\\\\.624$\"\n",
      "features: \"^data:0\\\\.625$\"\n",
      "features: \"^data:0\\\\.626$\"\n",
      "features: \"^data:0\\\\.627$\"\n",
      "features: \"^data:0\\\\.628$\"\n",
      "features: \"^data:0\\\\.629$\"\n",
      "features: \"^data:0\\\\.63$\"\n",
      "features: \"^data:0\\\\.630$\"\n",
      "features: \"^data:0\\\\.631$\"\n",
      "features: \"^data:0\\\\.632$\"\n",
      "features: \"^data:0\\\\.633$\"\n",
      "features: \"^data:0\\\\.634$\"\n",
      "features: \"^data:0\\\\.635$\"\n",
      "features: \"^data:0\\\\.636$\"\n",
      "features: \"^data:0\\\\.637$\"\n",
      "features: \"^data:0\\\\.638$\"\n",
      "features: \"^data:0\\\\.639$\"\n",
      "features: \"^data:0\\\\.64$\"\n",
      "features: \"^data:0\\\\.640$\"\n",
      "features: \"^data:0\\\\.641$\"\n",
      "features: \"^data:0\\\\.642$\"\n",
      "features: \"^data:0\\\\.643$\"\n",
      "features: \"^data:0\\\\.644$\"\n",
      "features: \"^data:0\\\\.645$\"\n",
      "features: \"^data:0\\\\.646$\"\n",
      "features: \"^data:0\\\\.647$\"\n",
      "features: \"^data:0\\\\.648$\"\n",
      "features: \"^data:0\\\\.649$\"\n",
      "features: \"^data:0\\\\.65$\"\n",
      "features: \"^data:0\\\\.650$\"\n",
      "features: \"^data:0\\\\.651$\"\n",
      "features: \"^data:0\\\\.652$\"\n",
      "features: \"^data:0\\\\.653$\"\n",
      "features: \"^data:0\\\\.654$\"\n",
      "features: \"^data:0\\\\.655$\"\n",
      "features: \"^data:0\\\\.656$\"\n",
      "features: \"^data:0\\\\.657$\"\n",
      "features: \"^data:0\\\\.658$\"\n",
      "features: \"^data:0\\\\.659$\"\n",
      "features: \"^data:0\\\\.66$\"\n",
      "features: \"^data:0\\\\.660$\"\n",
      "features: \"^data:0\\\\.661$\"\n",
      "features: \"^data:0\\\\.662$\"\n",
      "features: \"^data:0\\\\.663$\"\n",
      "features: \"^data:0\\\\.664$\"\n",
      "features: \"^data:0\\\\.665$\"\n",
      "features: \"^data:0\\\\.666$\"\n",
      "features: \"^data:0\\\\.667$\"\n",
      "features: \"^data:0\\\\.668$\"\n",
      "features: \"^data:0\\\\.669$\"\n",
      "features: \"^data:0\\\\.67$\"\n",
      "features: \"^data:0\\\\.670$\"\n",
      "features: \"^data:0\\\\.671$\"\n",
      "features: \"^data:0\\\\.672$\"\n",
      "features: \"^data:0\\\\.673$\"\n",
      "features: \"^data:0\\\\.674$\"\n",
      "features: \"^data:0\\\\.675$\"\n",
      "features: \"^data:0\\\\.676$\"\n",
      "features: \"^data:0\\\\.677$\"\n",
      "features: \"^data:0\\\\.678$\"\n",
      "features: \"^data:0\\\\.679$\"\n",
      "features: \"^data:0\\\\.68$\"\n",
      "features: \"^data:0\\\\.680$\"\n",
      "features: \"^data:0\\\\.681$\"\n",
      "features: \"^data:0\\\\.682$\"\n",
      "features: \"^data:0\\\\.683$\"\n",
      "features: \"^data:0\\\\.684$\"\n",
      "features: \"^data:0\\\\.685$\"\n",
      "features: \"^data:0\\\\.686$\"\n",
      "features: \"^data:0\\\\.687$\"\n",
      "features: \"^data:0\\\\.688$\"\n",
      "features: \"^data:0\\\\.689$\"\n",
      "features: \"^data:0\\\\.69$\"\n",
      "features: \"^data:0\\\\.690$\"\n",
      "features: \"^data:0\\\\.691$\"\n",
      "features: \"^data:0\\\\.692$\"\n",
      "features: \"^data:0\\\\.693$\"\n",
      "features: \"^data:0\\\\.694$\"\n",
      "features: \"^data:0\\\\.695$\"\n",
      "features: \"^data:0\\\\.696$\"\n",
      "features: \"^data:0\\\\.697$\"\n",
      "features: \"^data:0\\\\.698$\"\n",
      "features: \"^data:0\\\\.699$\"\n",
      "features: \"^data:0\\\\.7$\"\n",
      "features: \"^data:0\\\\.70$\"\n",
      "features: \"^data:0\\\\.700$\"\n",
      "features: \"^data:0\\\\.701$\"\n",
      "features: \"^data:0\\\\.702$\"\n",
      "features: \"^data:0\\\\.703$\"\n",
      "features: \"^data:0\\\\.704$\"\n",
      "features: \"^data:0\\\\.705$\"\n",
      "features: \"^data:0\\\\.706$\"\n",
      "features: \"^data:0\\\\.707$\"\n",
      "features: \"^data:0\\\\.708$\"\n",
      "features: \"^data:0\\\\.709$\"\n",
      "features: \"^data:0\\\\.71$\"\n",
      "features: \"^data:0\\\\.710$\"\n",
      "features: \"^data:0\\\\.711$\"\n",
      "features: \"^data:0\\\\.712$\"\n",
      "features: \"^data:0\\\\.713$\"\n",
      "features: \"^data:0\\\\.714$\"\n",
      "features: \"^data:0\\\\.715$\"\n",
      "features: \"^data:0\\\\.716$\"\n",
      "features: \"^data:0\\\\.717$\"\n",
      "features: \"^data:0\\\\.718$\"\n",
      "features: \"^data:0\\\\.719$\"\n",
      "features: \"^data:0\\\\.72$\"\n",
      "features: \"^data:0\\\\.720$\"\n",
      "features: \"^data:0\\\\.721$\"\n",
      "features: \"^data:0\\\\.722$\"\n",
      "features: \"^data:0\\\\.723$\"\n",
      "features: \"^data:0\\\\.724$\"\n",
      "features: \"^data:0\\\\.725$\"\n",
      "features: \"^data:0\\\\.726$\"\n",
      "features: \"^data:0\\\\.727$\"\n",
      "features: \"^data:0\\\\.728$\"\n",
      "features: \"^data:0\\\\.729$\"\n",
      "features: \"^data:0\\\\.73$\"\n",
      "features: \"^data:0\\\\.730$\"\n",
      "features: \"^data:0\\\\.731$\"\n",
      "features: \"^data:0\\\\.732$\"\n",
      "features: \"^data:0\\\\.733$\"\n",
      "features: \"^data:0\\\\.734$\"\n",
      "features: \"^data:0\\\\.735$\"\n",
      "features: \"^data:0\\\\.736$\"\n",
      "features: \"^data:0\\\\.737$\"\n",
      "features: \"^data:0\\\\.738$\"\n",
      "features: \"^data:0\\\\.739$\"\n",
      "features: \"^data:0\\\\.74$\"\n",
      "features: \"^data:0\\\\.740$\"\n",
      "features: \"^data:0\\\\.741$\"\n",
      "features: \"^data:0\\\\.742$\"\n",
      "features: \"^data:0\\\\.743$\"\n",
      "features: \"^data:0\\\\.744$\"\n",
      "features: \"^data:0\\\\.745$\"\n",
      "features: \"^data:0\\\\.746$\"\n",
      "features: \"^data:0\\\\.747$\"\n",
      "features: \"^data:0\\\\.748$\"\n",
      "features: \"^data:0\\\\.749$\"\n",
      "features: \"^data:0\\\\.75$\"\n",
      "features: \"^data:0\\\\.750$\"\n",
      "features: \"^data:0\\\\.751$\"\n",
      "features: \"^data:0\\\\.752$\"\n",
      "features: \"^data:0\\\\.753$\"\n",
      "features: \"^data:0\\\\.754$\"\n",
      "features: \"^data:0\\\\.755$\"\n",
      "features: \"^data:0\\\\.756$\"\n",
      "features: \"^data:0\\\\.757$\"\n",
      "features: \"^data:0\\\\.758$\"\n",
      "features: \"^data:0\\\\.759$\"\n",
      "features: \"^data:0\\\\.76$\"\n",
      "features: \"^data:0\\\\.760$\"\n",
      "features: \"^data:0\\\\.761$\"\n",
      "features: \"^data:0\\\\.762$\"\n",
      "features: \"^data:0\\\\.763$\"\n",
      "features: \"^data:0\\\\.764$\"\n",
      "features: \"^data:0\\\\.765$\"\n",
      "features: \"^data:0\\\\.766$\"\n",
      "features: \"^data:0\\\\.767$\"\n",
      "features: \"^data:0\\\\.77$\"\n",
      "features: \"^data:0\\\\.78$\"\n",
      "features: \"^data:0\\\\.79$\"\n",
      "features: \"^data:0\\\\.8$\"\n",
      "features: \"^data:0\\\\.80$\"\n",
      "features: \"^data:0\\\\.81$\"\n",
      "features: \"^data:0\\\\.82$\"\n",
      "features: \"^data:0\\\\.83$\"\n",
      "features: \"^data:0\\\\.84$\"\n",
      "features: \"^data:0\\\\.85$\"\n",
      "features: \"^data:0\\\\.86$\"\n",
      "features: \"^data:0\\\\.87$\"\n",
      "features: \"^data:0\\\\.88$\"\n",
      "features: \"^data:0\\\\.89$\"\n",
      "features: \"^data:0\\\\.9$\"\n",
      "features: \"^data:0\\\\.90$\"\n",
      "features: \"^data:0\\\\.91$\"\n",
      "features: \"^data:0\\\\.92$\"\n",
      "features: \"^data:0\\\\.93$\"\n",
      "features: \"^data:0\\\\.94$\"\n",
      "features: \"^data:0\\\\.95$\"\n",
      "features: \"^data:0\\\\.96$\"\n",
      "features: \"^data:0\\\\.97$\"\n",
      "features: \"^data:0\\\\.98$\"\n",
      "features: \"^data:0\\\\.99$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: REGRESSION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  binary_focal_loss_options {\n",
      "    misprediction_exponent: 2\n",
      "    positive_sample_coefficient: 0.5\n",
      "  }\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "[INFO 23-05-23 13:42:17.6157 EEST kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/ys/l39bprrn1mv8cskyrqsspgvr0000gn/T/tmp27txgrib/working_cache\"\n",
      "num_threads: 10\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 23-05-23 13:42:17.6163 EEST kernel.cc:889] Train model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 23-05-23 13:42:17.6400 EEST gradient_boosted_trees.cc:453] Default loss set to SQUARED_ERROR\n",
      "[INFO 23-05-23 13:42:17.6403 EEST gradient_boosted_trees.cc:1079] Training gradient boosted tree on 77085 example(s) and 768 feature(s).\n",
      "[INFO 23-05-23 13:42:17.8319 EEST gradient_boosted_trees.cc:1122] 69379 examples used for training and 7706 examples used for validation\n",
      "[INFO 23-05-23 13:42:20.2362 EEST gradient_boosted_trees.cc:1521] \tnum-trees:1 train-loss:2.052113 train-rmse:2.052113 valid-loss:2.058561 valid-rmse:2.058561\n",
      "[INFO 23-05-23 13:42:22.2112 EEST gradient_boosted_trees.cc:1523] \tnum-trees:2 train-loss:2.049326 train-rmse:2.049326 valid-loss:2.057321 valid-rmse:2.057321\n",
      "[INFO 23-05-23 13:42:52.4562 EEST gradient_boosted_trees.cc:1523] \tnum-trees:17 train-loss:2.016318 train-rmse:2.016318 valid-loss:2.048898 valid-rmse:2.048898\n",
      "[INFO 23-05-23 13:43:24.3181 EEST gradient_boosted_trees.cc:1523] \tnum-trees:33 train-loss:1.989606 train-rmse:1.989606 valid-loss:2.045664 valid-rmse:2.045664\n",
      "[INFO 23-05-23 13:43:55.5219 EEST gradient_boosted_trees.cc:1523] \tnum-trees:47 train-loss:1.970665 train-rmse:1.970665 valid-loss:2.043444 valid-rmse:2.043444\n",
      "[INFO 23-05-23 13:44:25.5860 EEST gradient_boosted_trees.cc:1523] \tnum-trees:61 train-loss:1.952859 train-rmse:1.952859 valid-loss:2.041817 valid-rmse:2.041817\n",
      "[INFO 23-05-23 13:44:56.1352 EEST gradient_boosted_trees.cc:1523] \tnum-trees:75 train-loss:1.936672 train-rmse:1.936672 valid-loss:2.040737 valid-rmse:2.040737\n",
      "[INFO 23-05-23 13:45:27.0833 EEST gradient_boosted_trees.cc:1523] \tnum-trees:90 train-loss:1.920814 train-rmse:1.920814 valid-loss:2.040192 valid-rmse:2.040192\n",
      "[INFO 23-05-23 13:45:47.7274 EEST gradient_boosted_trees.cc:1521] \tnum-trees:100 train-loss:1.910716 train-rmse:1.910716 valid-loss:2.039829 valid-rmse:2.039829\n",
      "[INFO 23-05-23 13:45:47.7277 EEST gradient_boosted_trees.cc:1573] Create final snapshot of the model at iteration 100\n",
      "[INFO 23-05-23 13:45:47.7319 EEST gradient_boosted_trees.cc:247] Truncates the model to 100 tree(s) i.e. 100  iteration(s).\n",
      "[INFO 23-05-23 13:45:47.7319 EEST gradient_boosted_trees.cc:310] Final model num-trees:100 valid-loss:2.039829 valid-rmse:2.039829\n",
      "[INFO 23-05-23 13:45:47.7400 EEST kernel.cc:926] Export model in log directory: /var/folders/ys/l39bprrn1mv8cskyrqsspgvr0000gn/T/tmp27txgrib with prefix 185483d0fafb4c34\n",
      "[INFO 23-05-23 13:45:47.7428 EEST kernel.cc:944] Save model in resources\n",
      "[INFO 23-05-23 13:45:47.7552 EEST abstract_model.cc:849] Model self evaluation:\n",
      "Number of predictions (with weights): 1\n",
      "Task: REGRESSION\n",
      "Loss (SQUARED_ERROR): 2.03983\n",
      "\n",
      "RMSE: 1.42823\n",
      "Default RMSE: : 0\n",
      "\n",
      "[INFO 23-05-23 13:45:47.7647 EEST kernel.cc:1242] Loading model from path /var/folders/ys/l39bprrn1mv8cskyrqsspgvr0000gn/T/tmp27txgrib/model/ with prefix 185483d0fafb4c34\n",
      "[INFO 23-05-23 13:45:47.7763 EEST abstract_model.cc:1312] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO 23-05-23 13:45:47.7765 EEST kernel.cc:1074] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:03:30.614402\n",
      "Compiling model...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x5651c49d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x5651c49d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x5651c49d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x56513d4e0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_1 = tfdf.keras.RandomForestModel(num_trees=100, name='lon', task = tfdf.keras.Task.REGRESSION, verbose=2)\n",
    "\n",
    "model_1 = tfdf.keras.GradientBoostedTreesModel(num_trees=100, name='lon', task = tfdf.keras.Task.REGRESSION, verbose=2)\n",
    "\n",
    "model_1.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 135ms/step - loss: 0.0000e+00 - mae: 1.6025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 1.602547526359558]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.compile(metrics=[\"mae\"])\n",
    "evaluation = model_1.evaluate(test_ds)\n",
    "\n",
    "evaluation"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPs4/LEGd7QOPVQERX7vIrS",
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
