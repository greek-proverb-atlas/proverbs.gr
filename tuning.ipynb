{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DGbsqg9v68OG"
      ],
      "authorship_tag": "ABX9TyN74z/i9FLtFwY3Q7mP0gU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipavlopoulos/paremia/blob/main/tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ay87HyvYwtKZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import ast\n",
        "\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "corpus_path = \"data/balanced_corpus.csv\"\n",
        "if not Path(corpus_path).exists():\n",
        "  corpus_path = 'https://raw.githubusercontent.com/ipavlopoulos/paremia/main/data/balanced_corpus.csv'\n",
        "balanced_corpus = pd.read_csv(corpus_path, index_col=0)"
      ],
      "metadata": {
        "id": "92KvnvpZwwbT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(balanced_corpus, test_size=0.05, random_state=2023)\n",
        "train, dev = train_test_split(train, test_size=test.shape[0], random_state=2023)"
      ],
      "metadata": {
        "id": "GpYdXWo1xION"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # small-scale sandbox\n",
        "tuning_set = train.sample(1000, random_state=2023)"
      ],
      "metadata": {
        "id": "M2A3UXGT67QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tuning the ExtraTrees"
      ],
      "metadata": {
        "id": "DGbsqg9v68OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning extratrees\n",
        "xtra = Pipeline([('vect', TfidfVectorizer()), ('clf', ExtraTreesRegressor())])\n",
        "grid_param = [\n",
        "                {\n",
        "                    \"vect\": [TfidfVectorizer()],\n",
        "                    \"vect__analyzer\": [\"word\", \"char\"],\n",
        "                    \"vect__lowercase\": [True],\n",
        "                    \"vect__max_df\": [0.5],\n",
        "                    \"vect__min_df\": [2, 10],\n",
        "                    \"vect__ngram_range\": [(1,1), (1,2), (2,5)],\n",
        "                    \"clf\": [ExtraTreesRegressor()],\n",
        "                    \"clf__n_estimators\": [10, 100], # this is redundant\n",
        "                 },\n",
        "              ]\n",
        "\n",
        "gsc = GridSearchCV(estimator=xtra, param_grid=grid_param, scoring='r2', cv=3)\n",
        "tuning_result = gsc.fit(tuning_set.text.values, tuning_set[[\"lat\", \"lon\"]].values)\n",
        "print(\"Best: %f using %s\" % (tuning_result.best_score_, tuning_result.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITtvsWiAwxwt",
        "outputId": "033891fc-d301-4884-8d33-19ec49d43bd7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.061708 using {'clf': ExtraTreesRegressor(), 'clf__n_estimators': 100, 'vect': TfidfVectorizer(analyzer='char', max_df=0.5, min_df=10, ngram_range=(1, 2)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 10, 'vect__ngram_range': (1, 2)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning the best result on all the texts\n",
        "xtra_tuned = Pipeline([('vect', tuning_result.best_params_[\"vect\"]), ('clf', tuning_result.best_params_[\"clf\"])])\n",
        "xtra_tuned.fit(train.text.values, train[[\"lat\", \"lon\"]].values)\n",
        "predicted_coords = xtra_tuned.predict(test.text.values)\n",
        "print(f\"MAE of lat and lon: {mean_absolute_error(test.lat.values, predicted_coords[:, 0]):.2f} & {mean_absolute_error(test.lon.values, predicted_coords[:, 1]):.2f}\")\n",
        "print(f\"MSE of lat and lon: {mean_squared_error(test.lat.values, predicted_coords[:, 0]):.2f} & {mean_squared_error(test.lon.values, predicted_coords[:, 1]):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWTS6mcAxLee",
        "outputId": "94e91678-a7b9-4f94-a39e-eff203cf463d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE of lat and lon: 1.22 & 1.74\n",
            "MSE of lat and lon: 2.48 & 5.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tuning the Forest"
      ],
      "metadata": {
        "id": "7Uy-8hAz5_Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning extratrees\n",
        "forest = Pipeline([('vect', TfidfVectorizer()), ('clf', RandomForestRegressor())])\n",
        "grid_param = [\n",
        "                {\n",
        "                    \"vect\": [TfidfVectorizer()],\n",
        "                    \"vect__analyzer\": [\"word\", \"char\"],\n",
        "                    \"vect__lowercase\": [True],\n",
        "                    \"vect__max_df\": [0.5],\n",
        "                    \"vect__min_df\": [2, 10],\n",
        "                    \"vect__ngram_range\": [(1,1), (1,2), (2,5)],\n",
        "                    \"clf\": [RandomForestRegressor()],\n",
        "                    \"clf__n_estimators\": [10, 100],\n",
        "                 },\n",
        "              ]\n",
        "\n",
        "gsc = GridSearchCV(estimator=forest, param_grid=grid_param, scoring='r2', cv=3)\n",
        "tuning_result = gsc.fit(tuning_set.text.values, tuning_set[[\"lat\", \"lon\"]].values)\n",
        "print(\"Best: %f using %s\" % (tuning_result.best_score_, tuning_result.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4dS-UO8zclA",
        "outputId": "66c438e9-7aa8-4ed1-98c7-a7f6372a2675"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.109010 using {'clf': RandomForestRegressor(), 'clf__n_estimators': 100, 'vect': TfidfVectorizer(analyzer='char', max_df=0.5, min_df=2, ngram_range=(2, 5)), 'vect__analyzer': 'char', 'vect__lowercase': True, 'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (2, 5)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning the best result on all the texts\n",
        "forest_tuned = Pipeline([('vect', tuning_result.best_params_[\"vect\"]), ('clf', tuning_result.best_params_[\"clf\"])])\n",
        "forest_tuned.fit(train.text.values, train[[\"lat\", \"lon\"]].values)\n",
        "forest_coords = forest_tuned.predict(test.text.values)\n",
        "print(f\"MAE of lat and lon: {mean_absolute_error(test.lat.values, forest_coords[:, 0]):.2f} & {mean_absolute_error(test.lon.values, forest_coords[:, 1]):.2f}\")\n",
        "print(f\"MSE of lat and lon: {mean_squared_error(test.lat.values, forest_coords[:, 0]):.2f} & {mean_squared_error(test.lon.values, forest_coords[:, 1]):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bljFNU_L6pDW",
        "outputId": "53ac64e6-ac85-43a5-9497-990a58d2562d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE of lat and lon: 1.22 & 1.69\n",
            "MSE of lat and lon: 2.45 & 5.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classification assessment"
      ],
      "metadata": {
        "id": "EBSgZZTT8zn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopy.distance\n",
        "def degeocode(geocoded_areas, predictions, target_col=\"category\"):\n",
        "    classes = []\n",
        "    # find the nearest geocoded area to the prediction in 2d \n",
        "    for p in predictions:\n",
        "        dists = geocoded_areas.apply(lambda r: geopy.distance.geodesic( (r.lat, r.lon), (p[0], p[1])).km, axis=1)\n",
        "        classes.append(geocoded_areas.iloc[dists.argmin()][target_col])\n",
        "    return classes\n",
        "\n",
        "def km_distance(geocodes, gold_locs, pred_ll, target_col=\"category\"):\n",
        "    dists = []\n",
        "    for g, p in zip(gold_locs, pred_ll):\n",
        "        gold_lat, gold_lon = geocodes[geocodes[target_col]==g][[\"lat\", \"lon\"]].values[0]\n",
        "        dists.append(geopy.distance.geodesic( (gold_lat, gold_lon), (p[0], p[1])).km)\n",
        "    return pd.Series(dists)"
      ],
      "metadata": {
        "id": "vPpM47Y4619F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interpreting the results in terms of predicted distance\n",
        "dist = km_distance(geocodes=_train.drop_duplicates(\"category\"), gold_locs=_train.category.values, pred_ll=xtra_preds)\n",
        "print(f\"W/XtraTrees, {25}% of the predicted places fall within {dist.quantile(0.25):.2f}kms\")\n",
        "print(f\"(NOTE: {len(set(df_test.category.unique())-set(df_test.category.unique()).intersection((_train.category.unique())))} areas out of the {len(set(df_test.category.unique()))} were not in the train)\")"
      ],
      "metadata": {
        "id": "GhiQiL4z9G-y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}