{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxxFvI4TbAKf"
   },
   "source": [
    "# Geographical classification of Greek proverbs\n",
    "\n",
    "* Using a collection of proverbs from the [Hellenic Folklore Research Centre](http://www.kentrolaografias.gr/) of the Academy of Athens\n",
    "* Employing language modelling and text classification to geolocate proverbs whose information is not known.\n",
    "* Experimenting with 5 different train/test splits for statistical significance.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dQm9rqoXb9v8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'paremia'...\n",
      "remote: Enumerating objects: 445, done.\u001b[K\n",
      "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
      "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
      "remote: Total 445 (delta 30), reused 8 (delta 3), pack-reused 382 (from 1)\u001b[K\n",
      "Receiving objects: 100% (445/445), 23.19 MiB | 2.89 MiB/s, done.\n",
      "Resolving deltas: 100% (235/235), done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "!git clone https://github.com/ipavlopoulos/paremia.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT8WZYricW2D"
   },
   "source": [
    "## Authorship analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_name = {\n",
    "    'Ρούμελη': 'Roumeli', \n",
    "    'Κοζάνη': 'Kozani', \n",
    "    'Κως': 'Kos', \n",
    "    'Αδριανούπολη': 'Adrian.', \n",
    "    'Νάουσα': 'Naousa', \n",
    "    'Σέρρες': 'Serres', \n",
    "    'Σίφνος': 'Sifnos', \n",
    "    'Ήπειρος': 'Epirus', \n",
    "    'Αιτωλία': 'Etolia', \n",
    "    'Αμοργός': 'Amorgos', \n",
    "    'Ανατολική Θράκη': 'East Thrace', \n",
    "    'Αρκαδία': 'Arcadia', \n",
    "    'Αχαΐα': 'Achaia', \n",
    "    'Επτάνησος': 'Eptanisos', \n",
    "    'Εύβοια': 'Eyvoia', \n",
    "    'Θεσπρωτία': 'Thesprotia', \n",
    "    'Θράκη': 'Thrace', \n",
    "    'Ιωάννινα': 'Ioannina', \n",
    "    'Κάρπαθος': 'Karpathos', \n",
    "    'Κεφαλληνία': 'Kefalinia', \n",
    "    'Κρήτη': 'Crete', \n",
    "    'Κύπρος': 'Cyprus', \n",
    "    'Λέσβος': 'Lesvos', \n",
    "    'Λακωνία': 'Laconia', \n",
    "    'Μακεδονία': 'Maced.', \n",
    "    'Μικρά Ασία': 'Asia Minor', \n",
    "    'Νάξος': 'Naxos', \n",
    "    'Πόντος': 'Pontos', \n",
    "    'Ρόδος': 'Rodos', \n",
    "    'Σκύρος': 'Skyros'\n",
    "}\n",
    "regions = [\n",
    "    'Πόντος', \n",
    "    'Κύπρος', \n",
    "    'Κάρπαθος', \n",
    "    'Θεσπρωτία', \n",
    "    'Αμοργός', \n",
    "    'Σκύρος', \n",
    "    'Μικρά Ασία', \n",
    "    'Λέσβος', \n",
    "    'Μακεδονία', \n",
    "    'Λακωνία', \n",
    "    'Εύβοια', \n",
    "    'Επτάνησος', \n",
    "    'Αρκαδία', \n",
    "    'Νάξος', \n",
    "    'Κρήτη', \n",
    "    'Αχαΐα', \n",
    "    'Θράκη', \n",
    "    'Ιωάννινα', \n",
    "    'Αιτωλία', \n",
    "    'Κεφαλληνία', \n",
    "    'Ανατολική Θράκη', \n",
    "    'Ρόδος', \n",
    "    'Ήπειρος'\n",
    "]\n",
    "\n",
    "class LinguisticOddity:\n",
    "    \n",
    "    def __init__(self, train, regions):\n",
    "        # building the local language models\n",
    "        self.models = {}\n",
    "        self.regions = regions\n",
    "        if self.regions == None:\n",
    "            self.regions = train.area.unique()\n",
    "        # creating a dictionary of language models, one per location\n",
    "        for area in self.regions:\n",
    "            texts = train[train.area==area].text.str.lower().values\n",
    "            self.models[loc_name[area]] = LM(gram=\"CHAR\").train(\" \\n \".join(texts))\n",
    "\n",
    "    def ling_dist(self, proverb):\n",
    "        '''\n",
    "        Compute the bits per character (BPC) for a given proverb using many local language models\n",
    "        Args:\n",
    "            proverb (str): a text\n",
    "        Returns:\n",
    "            string: the location whose model predicts best the text \n",
    "            pd.DataFrame: BPC per location    \n",
    "        '''\n",
    "        entropy = {loc:[self.models[loc_name[loc]].cross_entropy(proverb.lower())] for loc in self.regions}\n",
    "        likelier = loc_name[min(entropy, key=entropy.get)]\n",
    "        return likelier, pd.DataFrame(entropy)\n",
    "\n",
    "    def predict(self, texts):\n",
    "        return [self.ling_dist(text)[0] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2noxDr3mca4G"
   },
   "outputs": [],
   "source": [
    "from lm.markov.models import LM\n",
    "\n",
    "f_ones = []\n",
    "for i in range(2,6):\n",
    "    balanced_corpus = pd.read_csv(f\"data/balanced_corpus_{i}.csv\",\n",
    "                                  index_col=0).reset_index()\n",
    "    train, test = train_test_split(balanced_corpus, test_size=0.05, random_state=2023)\n",
    "    train, dev = train_test_split(train, test_size=test.shape[0], random_state=2023)\n",
    "\n",
    "    lo = LinguisticOddity(train=train, regions=regions)\n",
    "    preds = lo.predict(test.text.values)\n",
    "    gold = test.area.apply(lambda x: loc_name[x]).values\n",
    "    f_ones.append(f1_score(gold, preds, zero_division=0, average=None, labels=[loc_name[r] for r in regions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f_ones_pd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m:\u001b[43mf_ones\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m)}, index\u001b[38;5;241m=\u001b[39m[loc_name[r] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m regions])\n\u001b[1;32m      2\u001b[0m f_ones_pd\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbox(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m);\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "f_ones_pd = pd.DataFrame({f'r{i}':f_ones[i] for i in range(4)}, index=[loc_name[r] for r in regions])\n",
    "f_ones_pd.T.plot.box(rot=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrA3eHTRc9qT"
   },
   "source": [
    "## Benchmarking standard text classifiers, on top of chanracter n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15kPTs9tc5_G",
    "outputId": "a94bd6bc-41bf-41d3-9bbe-b36dc857ab17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 81402\n",
      "n-gram: \"ία\" \t(tfidf: 0.21)\n",
      "n-gram: \"αρ\" \t(tfidf: 0.12)\n",
      "n-gram: \"αρο\" \t(tfidf: 0.21)\n",
      "n-gram: \"αροι\" \t(tfidf: 0.37)\n",
      "n-gram: \"ιμ\" \t(tfidf: 0.19)\n",
      "n-gram: \"ιμί\" \t(tfidf: 0.33)\n",
      "n-gram: \"ιμία\" \t(tfidf: 0.38)\n",
      "n-gram: \"μί\" \t(tfidf: 0.21)\n",
      "n-gram: \"μία\" \t(tfidf: 0.30)\n",
      "n-gram: \"οι\" \t(tfidf: 0.13)\n",
      "n-gram: \"οιμ\" \t(tfidf: 0.28)\n",
      "n-gram: \"πα\" \t(tfidf: 0.11)\n",
      "n-gram: \"παρ\" \t(tfidf: 0.18)\n",
      "n-gram: \"παρο\" \t(tfidf: 0.36)\n",
      "n-gram: \"ρο\" \t(tfidf: 0.12)\n",
      "n-gram: \"ροι\" \t(tfidf: 0.26)\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(2,5), # token sequences\n",
    "                       analyzer=\"char\", # tokens are characters\n",
    "                       max_df=0.5, # ignore tokens present in more than 50% of the texts\n",
    "                       min_df=2, # ignore tokens not present in at least two documents \n",
    "                       lowercase=True)\n",
    "vect.fit(train.text.values)\n",
    "print('Vocabulary:', len(vect.vocabulary_))\n",
    "rep_t = vect.transform(['παροιμία'])\n",
    "for i, feat in enumerate(rep_t.toarray()[0]):\n",
    "    if feat>0:\n",
    "        print(f'n-gram: \"{vect.get_feature_names_out()[i]}\" \\t(tfidf: {feat:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m f_scores \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msv\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnn\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[1;32m      2\u001b[0m models \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msv\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m6\u001b[39m)):\n\u001b[1;32m      5\u001b[0m     balanced_corpus \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/ssig/balanced_corpus_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      6\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m train_test_split(balanced_corpus, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2023\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "f_scores = {'lr':[], 'rf':[], 'sv':[], 'nn':[]}\n",
    "models = {'lr':None, 'rf':None, 'sv':None, 'nn':None}\n",
    "\n",
    "for i in tqdm(range(2,6)):\n",
    "    balanced_corpus = pd.read_csv(f\"data/ssig/balanced_corpus_{i}.csv\", index_col=0).reset_index()\n",
    "    train, test = train_test_split(balanced_corpus, test_size=0.05, random_state=2023)\n",
    "    train, dev = train_test_split(train, test_size=test.shape[0], random_state=2023)\n",
    "    vect = TfidfVectorizer(ngram_range=(2,5), analyzer=\"char\", max_df=0.5, min_df=2, lowercase=True)\n",
    "    vect.fit(train.text.values)\n",
    "\n",
    "    # logistic regression\n",
    "    lr = Pipeline([('vect', vect), ('ref', LogisticRegression())])\n",
    "    lr.fit(train.text, train.area)\n",
    "    models['lr']=lr\n",
    "\n",
    "    # linear svc\n",
    "    sv_best_params = {'C': 0.31193366798166167, 'penalty': 'l2', 'loss': 'hinge'}\n",
    "    sv = Pipeline([('vect', vect), ('clf', LinearSVC(**sv_best_params, max_iter=5000))]) \n",
    "    sv.fit(train.text, train.area)\n",
    "    models['sv']=sv\n",
    "    \n",
    "    # knn\n",
    "    nn_best_params = {'n_neighbors': 50, 'weights': 'distance', 'p': 2}\n",
    "    nn = Pipeline([('vect', vect), ('clf', KNeighborsClassifier(**nn_best_params))]) \n",
    "    nn.fit(train.text, train.area)\n",
    "    models['nn'] = nn\n",
    "    \n",
    "    # forest\n",
    "    rf_best_params = {'n_estimators': 329, 'max_depth': 32, 'min_samples_split': 8, 'min_samples_leaf': 1}\n",
    "    rf = Pipeline([('vect', vect), ('clf', RandomForestClassifier(**rf_best_params))]) \n",
    "    rf.fit(train.text, train.area)\n",
    "    models['rf'] = rf\n",
    "    \n",
    "    for model_name in models:\n",
    "          m = models[model_name]\n",
    "          f_scores[model_name].append(\n",
    "              f1_score(test.area, # gold\n",
    "                       m.predict(test.text), # predictions\n",
    "                       zero_division=0, # some areas will be misclassified\n",
    "                       average=None, # f1 per area\n",
    "                       labels=regions) # we want the regions ranked\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>rf</th>\n",
       "      <th>sv</th>\n",
       "      <th>nn</th>\n",
       "      <th>aa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pontos</th>\n",
       "      <td>0.542525</td>\n",
       "      <td>0.379641</td>\n",
       "      <td>0.518012</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.585397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cyprus</th>\n",
       "      <td>0.768220</td>\n",
       "      <td>0.626412</td>\n",
       "      <td>0.631518</td>\n",
       "      <td>0.612578</td>\n",
       "      <td>0.679686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Karpathos</th>\n",
       "      <td>0.426470</td>\n",
       "      <td>0.431911</td>\n",
       "      <td>0.506692</td>\n",
       "      <td>0.340325</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thesprotia</th>\n",
       "      <td>0.219591</td>\n",
       "      <td>0.202919</td>\n",
       "      <td>0.208175</td>\n",
       "      <td>0.172148</td>\n",
       "      <td>0.192402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amorgos</th>\n",
       "      <td>0.276146</td>\n",
       "      <td>0.232643</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.207697</td>\n",
       "      <td>0.242283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skyros</th>\n",
       "      <td>0.650055</td>\n",
       "      <td>0.546794</td>\n",
       "      <td>0.595670</td>\n",
       "      <td>0.533122</td>\n",
       "      <td>0.376965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asia Minor</th>\n",
       "      <td>0.115054</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.100338</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.088554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lesvos</th>\n",
       "      <td>0.401241</td>\n",
       "      <td>0.332299</td>\n",
       "      <td>0.401580</td>\n",
       "      <td>0.303468</td>\n",
       "      <td>0.331981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maced.</th>\n",
       "      <td>0.162360</td>\n",
       "      <td>0.112195</td>\n",
       "      <td>0.266617</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.252642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laconia</th>\n",
       "      <td>0.112811</td>\n",
       "      <td>0.079313</td>\n",
       "      <td>0.136482</td>\n",
       "      <td>0.058349</td>\n",
       "      <td>0.142211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eyvoia</th>\n",
       "      <td>0.161965</td>\n",
       "      <td>0.052427</td>\n",
       "      <td>0.140491</td>\n",
       "      <td>0.094655</td>\n",
       "      <td>0.126468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eptanisos</th>\n",
       "      <td>0.336118</td>\n",
       "      <td>0.245189</td>\n",
       "      <td>0.394355</td>\n",
       "      <td>0.340597</td>\n",
       "      <td>0.312375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arcadia</th>\n",
       "      <td>0.120551</td>\n",
       "      <td>0.096445</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.055601</td>\n",
       "      <td>0.107630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naxos</th>\n",
       "      <td>0.273774</td>\n",
       "      <td>0.190706</td>\n",
       "      <td>0.271309</td>\n",
       "      <td>0.150260</td>\n",
       "      <td>0.230972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crete</th>\n",
       "      <td>0.297679</td>\n",
       "      <td>0.288542</td>\n",
       "      <td>0.292686</td>\n",
       "      <td>0.241675</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Achaia</th>\n",
       "      <td>0.265557</td>\n",
       "      <td>0.322094</td>\n",
       "      <td>0.304976</td>\n",
       "      <td>0.207808</td>\n",
       "      <td>0.196429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thrace</th>\n",
       "      <td>0.125098</td>\n",
       "      <td>0.170440</td>\n",
       "      <td>0.191132</td>\n",
       "      <td>0.149999</td>\n",
       "      <td>0.130489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ioannina</th>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.145975</td>\n",
       "      <td>0.154159</td>\n",
       "      <td>0.112121</td>\n",
       "      <td>0.182776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Etolia</th>\n",
       "      <td>0.429926</td>\n",
       "      <td>0.323626</td>\n",
       "      <td>0.435365</td>\n",
       "      <td>0.337348</td>\n",
       "      <td>0.350474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kefalinia</th>\n",
       "      <td>0.158940</td>\n",
       "      <td>0.158706</td>\n",
       "      <td>0.229083</td>\n",
       "      <td>0.148263</td>\n",
       "      <td>0.199419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East Thrace</th>\n",
       "      <td>0.185784</td>\n",
       "      <td>0.161526</td>\n",
       "      <td>0.214223</td>\n",
       "      <td>0.163346</td>\n",
       "      <td>0.167403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodos</th>\n",
       "      <td>0.383890</td>\n",
       "      <td>0.298712</td>\n",
       "      <td>0.383204</td>\n",
       "      <td>0.300258</td>\n",
       "      <td>0.377694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epirus</th>\n",
       "      <td>0.042484</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.077260</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.065666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lr        rf        sv        nn        aa\n",
       "Pontos       0.542525  0.379641  0.518012  0.470900  0.585397\n",
       "Cyprus       0.768220  0.626412  0.631518  0.612578  0.679686\n",
       "Karpathos    0.426470  0.431911  0.506692  0.340325  0.476200\n",
       "Thesprotia   0.219591  0.202919  0.208175  0.172148  0.192402\n",
       "Amorgos      0.276146  0.232643  0.299345  0.207697  0.242283\n",
       "Skyros       0.650055  0.546794  0.595670  0.533122  0.376965\n",
       "Asia Minor   0.115054  0.028571  0.100338  0.079167  0.088554\n",
       "Lesvos       0.401241  0.332299  0.401580  0.303468  0.331981\n",
       "Maced.       0.162360  0.112195  0.266617  0.173200  0.252642\n",
       "Laconia      0.112811  0.079313  0.136482  0.058349  0.142211\n",
       "Eyvoia       0.161965  0.052427  0.140491  0.094655  0.126468\n",
       "Eptanisos    0.336118  0.245189  0.394355  0.340597  0.312375\n",
       "Arcadia      0.120551  0.096445  0.080884  0.055601  0.107630\n",
       "Naxos        0.273774  0.190706  0.271309  0.150260  0.230972\n",
       "Crete        0.297679  0.288542  0.292686  0.241675  0.254189\n",
       "Achaia       0.265557  0.322094  0.304976  0.207808  0.196429\n",
       "Thrace       0.125098  0.170440  0.191132  0.149999  0.130489\n",
       "Ioannina     0.205652  0.145975  0.154159  0.112121  0.182776\n",
       "Etolia       0.429926  0.323626  0.435365  0.337348  0.350474\n",
       "Kefalinia    0.158940  0.158706  0.229083  0.148263  0.199419\n",
       "East Thrace  0.185784  0.161526  0.214223  0.163346  0.167403\n",
       "Rodos        0.383890  0.298712  0.383204  0.300258  0.377694\n",
       "Epirus       0.042484  0.075000  0.077260  0.063158  0.065666"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({m: np.array(f_scores[m]).mean(0) for m in models}, index=[loc_name[r] for r in regions])\n",
    "results['aa'] = f_ones_pd.mean(1)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
